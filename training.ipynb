{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from rich.pretty import pprint\n",
    "from torcheeg.datasets import DREAMERDataset\n",
    "from torcheeg.datasets.constants.emotion_recognition.dreamer import DREAMER_CHANNEL_LOCATION_DICT\n",
    "from torcheeg import transforms\n",
    "from torch import nn\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"./DREAMER.mat\"\n",
    "base_path = \"./\"\n",
    "\n",
    "toTensor = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target folder already exists, if you need to regenerate the database IO, please delete the path ./dreamer8sec_unnormalized.\n"
     ]
    }
   ],
   "source": [
    "dataset = DREAMERDataset(\n",
    "    io_path=base_path + 'dreamer8sec_unnormalized',\n",
    "    mat_path=dataset_path,\n",
    "    offline_transform=transforms.Compose([\n",
    "        transforms.BaselineRemoval(),\n",
    "        # transforms.MeanStdNormalize(),\n",
    "        transforms.To2d()\n",
    "    ]),\n",
    "    # online_transform=transforms.ToTensor(),\n",
    "    label_transform=transforms.Compose(\n",
    "        [transforms.Select('valence'),\n",
    "         transforms.Binary(3.0)]),\n",
    "    chunk_size=976,\n",
    "    baseline_chunk_size=976,\n",
    "    num_baseline=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_feature(eeg, sr, n_channels = 14):\n",
    "    WinLength = int(0.5*sr) # 500 points (0.5 sec, 500 ms)\n",
    "    step = int(0.025*sr) # 25 points (or 25 ms)\n",
    "    final_features = None\n",
    "    for i in range(n_channels):\n",
    "        eeg_single = eeg[i].squeeze()\n",
    "        myparams = dict(nperseg = WinLength, noverlap = WinLength-step, return_onesided=True, mode='magnitude')\n",
    "        f, nseg, Sxx = signal.spectrogram(x = eeg_single, fs = sr, **myparams)\n",
    "        if(isinstance(final_features, np.ndarray)):\n",
    "            final_features = np.concatenate((final_features, Sxx), axis=0)\n",
    "        else:\n",
    "            final_features = Sxx\n",
    "    return final_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = nn.Conv2d(1, 1, 3, stride=3)\n",
    "abc1 = nn.Conv2d(1, 1, 5, stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(462, 305)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = get_tf_feature(dataset[0][0][0], 128)\n",
    "dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 154, 101])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = dat.astype(\"float32\")\n",
    "dat2 = dat.reshape(1, dat.shape[0], dat.shape[1])\n",
    "d = torch.from_numpy(dat2)\n",
    "c = abc(d)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "abcd = nn.Flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 150, 97])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc1(c).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv2D_1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 1, 3, stride=3),\n",
    "            nn.Conv2d(1, 1, 5, stride=1),\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(14550, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2D_1(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (conv2D_1): Sequential(\n",
      "    (0): Conv2d(1, 1, kernel_size=(3, 3), stride=(3, 3))\n",
      "    (1): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1))\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=14550, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=512, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = torch.rand(1, 28, 28, device=device)\n",
    "# logits = model(X)\n",
    "# pred_probab = nn.Softmax(dim=1)(logits)\n",
    "# y_pred = pred_probab.argmax(1)\n",
    "# print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data_to_tensor(data):\n",
    "    data = data.astype(\"float32\")\n",
    "    data = data.reshape(1, dat.shape[0], dat.shape[1])\n",
    "    return torch.from_numpy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataset,  model, loss_fn, optimizer):\n",
    "    size = len(dataset)\n",
    "    for i in range(size):\n",
    "        # Compute prediction and loss\n",
    "        X, y = dataset[i][0][0], dataset[i][1]\n",
    "        X = get_tf_feature(X, sr=128)\n",
    "        X = convert_data_to_tensor(X)\n",
    "        if y == 0:\n",
    "            y = [0]\n",
    "        else:\n",
    "            y = [1]\n",
    "        y = torch.tensor(y)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            loss, current = loss.item(), i + 1\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10476,\n",
       " 1824,\n",
       " 409,\n",
       " 4506,\n",
       " 4012,\n",
       " 3657,\n",
       " 2286,\n",
       " 1679,\n",
       " 8935,\n",
       " 1424,\n",
       " 9674,\n",
       " 6912,\n",
       " 520,\n",
       " 488,\n",
       " 1535,\n",
       " 3582,\n",
       " 3811,\n",
       " 8279,\n",
       " 9863,\n",
       " 434,\n",
       " 9195,\n",
       " 3257,\n",
       " 10647,\n",
       " 8928,\n",
       " 6873,\n",
       " 3611,\n",
       " 7359,\n",
       " 9654,\n",
       " 4557,\n",
       " 106,\n",
       " 2615,\n",
       " 6924,\n",
       " 5574,\n",
       " 4552,\n",
       " 2547,\n",
       " 3527,\n",
       " 5514,\n",
       " 1674,\n",
       " 1519,\n",
       " 6224,\n",
       " 1584,\n",
       " 5881,\n",
       " 5635,\n",
       " 9891,\n",
       " 4333,\n",
       " 711,\n",
       " 7527,\n",
       " 8785,\n",
       " 2045,\n",
       " 6201,\n",
       " 1291,\n",
       " 9044,\n",
       " 4803,\n",
       " 10299,\n",
       " 10133,\n",
       " 5925,\n",
       " 9459,\n",
       " 3150,\n",
       " 1139,\n",
       " 750,\n",
       " 10834,\n",
       " 3733,\n",
       " 4741,\n",
       " 1307,\n",
       " 3814,\n",
       " 1654,\n",
       " 6227,\n",
       " 4554,\n",
       " 7428,\n",
       " 10415,\n",
       " 5977,\n",
       " 2664,\n",
       " 6065,\n",
       " 5820,\n",
       " 3432,\n",
       " 10980,\n",
       " 4374,\n",
       " 10617,\n",
       " 1169,\n",
       " 9980,\n",
       " 10403,\n",
       " 2803,\n",
       " 8751,\n",
       " 4010,\n",
       " 2677,\n",
       " 7573,\n",
       " 6216,\n",
       " 4422,\n",
       " 10485,\n",
       " 9125,\n",
       " 3598,\n",
       " 5313,\n",
       " 916,\n",
       " 3752,\n",
       " 525,\n",
       " 5168,\n",
       " 6572,\n",
       " 4386,\n",
       " 1084,\n",
       " 3456,\n",
       " 9292,\n",
       " 5155,\n",
       " 3483,\n",
       " 10738,\n",
       " 8179,\n",
       " 6482,\n",
       " 10532,\n",
       " 7517,\n",
       " 2340,\n",
       " 4339,\n",
       " 2287,\n",
       " 4040,\n",
       " 9197,\n",
       " 8830,\n",
       " 4304,\n",
       " 9577,\n",
       " 7019,\n",
       " 9560,\n",
       " 6543,\n",
       " 5930,\n",
       " 3593,\n",
       " 2266,\n",
       " 8348,\n",
       " 8085,\n",
       " 1489,\n",
       " 771,\n",
       " 1796,\n",
       " 2504,\n",
       " 10280,\n",
       " 2621,\n",
       " 6916,\n",
       " 9771,\n",
       " 1040,\n",
       " 6304,\n",
       " 6252,\n",
       " 9763,\n",
       " 7668,\n",
       " 8669,\n",
       " 4119,\n",
       " 9064,\n",
       " 188,\n",
       " 1876,\n",
       " 8797,\n",
       " 4371,\n",
       " 10501,\n",
       " 5573,\n",
       " 1827,\n",
       " 4808,\n",
       " 7123,\n",
       " 2591,\n",
       " 7433,\n",
       " 53,\n",
       " 4315,\n",
       " 8201,\n",
       " 2927,\n",
       " 8317,\n",
       " 1743,\n",
       " 10244,\n",
       " 4889,\n",
       " 10468,\n",
       " 9977,\n",
       " 3258,\n",
       " 6126,\n",
       " 2646,\n",
       " 8837,\n",
       " 8689,\n",
       " 9,\n",
       " 9813,\n",
       " 5310,\n",
       " 8005,\n",
       " 319,\n",
       " 1832,\n",
       " 5947,\n",
       " 5038,\n",
       " 3923,\n",
       " 949,\n",
       " 3946,\n",
       " 9295,\n",
       " 1290,\n",
       " 1403,\n",
       " 7962,\n",
       " 1133,\n",
       " 8727,\n",
       " 2060,\n",
       " 2103,\n",
       " 10809,\n",
       " 7787,\n",
       " 9007,\n",
       " 2705,\n",
       " 4342,\n",
       " 8645,\n",
       " 9938,\n",
       " 6932,\n",
       " 3470,\n",
       " 8835,\n",
       " 3295,\n",
       " 5107,\n",
       " 6537,\n",
       " 6118,\n",
       " 7177,\n",
       " 8479,\n",
       " 7397,\n",
       " 1982,\n",
       " 4061,\n",
       " 3681,\n",
       " 1049,\n",
       " 5539,\n",
       " 344,\n",
       " 9638,\n",
       " 9075,\n",
       " 3770,\n",
       " 9641,\n",
       " 3608,\n",
       " 117,\n",
       " 1163,\n",
       " 10339,\n",
       " 964,\n",
       " 3750,\n",
       " 1104,\n",
       " 514,\n",
       " 5413,\n",
       " 1160,\n",
       " 8423,\n",
       " 3899,\n",
       " 4562,\n",
       " 10960,\n",
       " 7953,\n",
       " 3510,\n",
       " 8834,\n",
       " 2167,\n",
       " 9355,\n",
       " 9440,\n",
       " 7744,\n",
       " 3981,\n",
       " 7749,\n",
       " 6669,\n",
       " 3119,\n",
       " 1545,\n",
       " 1588,\n",
       " 10796,\n",
       " 7062,\n",
       " 5804,\n",
       " 6939,\n",
       " 6735,\n",
       " 7651,\n",
       " 887,\n",
       " 10706,\n",
       " 10587,\n",
       " 1612,\n",
       " 993,\n",
       " 6596,\n",
       " 5559,\n",
       " 1790,\n",
       " 4073,\n",
       " 3139,\n",
       " 3116,\n",
       " 8786,\n",
       " 7350,\n",
       " 2296,\n",
       " 3006,\n",
       " 4563,\n",
       " 7579,\n",
       " 4092,\n",
       " 1235,\n",
       " 7260,\n",
       " 9016,\n",
       " 1604,\n",
       " 828,\n",
       " 10684,\n",
       " 8856,\n",
       " 241,\n",
       " 1528,\n",
       " 3872,\n",
       " 2724,\n",
       " 6658,\n",
       " 7956,\n",
       " 7886,\n",
       " 3502,\n",
       " 6570,\n",
       " 960,\n",
       " 2697,\n",
       " 6209,\n",
       " 35,\n",
       " 6396,\n",
       " 4345,\n",
       " 7454,\n",
       " 4673,\n",
       " 6930,\n",
       " 9105,\n",
       " 10844,\n",
       " 7973,\n",
       " 2536,\n",
       " 3111,\n",
       " 4861,\n",
       " 3566,\n",
       " 958,\n",
       " 9489,\n",
       " 8883,\n",
       " 998,\n",
       " 5138,\n",
       " 936,\n",
       " 821,\n",
       " 9571,\n",
       " 7811,\n",
       " 8238,\n",
       " 8701,\n",
       " 2579,\n",
       " 931,\n",
       " 8320,\n",
       " 1312,\n",
       " 3044,\n",
       " 1122,\n",
       " 9749,\n",
       " 1113,\n",
       " 3853,\n",
       " 6615,\n",
       " 1964,\n",
       " 9333,\n",
       " 4033,\n",
       " 9485,\n",
       " 9740,\n",
       " 651,\n",
       " 10147,\n",
       " 1343,\n",
       " 6868,\n",
       " 10770,\n",
       " 9562,\n",
       " 9260,\n",
       " 8565,\n",
       " 5183,\n",
       " 4272,\n",
       " 3346,\n",
       " 10972,\n",
       " 5147,\n",
       " 3910,\n",
       " 4351,\n",
       " 6484,\n",
       " 2144,\n",
       " 10575,\n",
       " 4915,\n",
       " 7491,\n",
       " 5180,\n",
       " 1188,\n",
       " 152,\n",
       " 7508,\n",
       " 10177,\n",
       " 9224,\n",
       " 1638,\n",
       " 1200,\n",
       " 8808,\n",
       " 3492,\n",
       " 8288,\n",
       " 2170,\n",
       " 5718,\n",
       " 1127,\n",
       " 4002,\n",
       " 6054,\n",
       " 4669,\n",
       " 2584,\n",
       " 7179,\n",
       " 8900,\n",
       " 4956,\n",
       " 10021,\n",
       " 10714,\n",
       " 8666,\n",
       " 128,\n",
       " 10942,\n",
       " 9086,\n",
       " 4905,\n",
       " 10868,\n",
       " 1697,\n",
       " 2200,\n",
       " 1891,\n",
       " 1753,\n",
       " 2546,\n",
       " 4462,\n",
       " 4616,\n",
       " 9909,\n",
       " 3450,\n",
       " 5617,\n",
       " 3335,\n",
       " 10391,\n",
       " 4325,\n",
       " 8280,\n",
       " 8004,\n",
       " 4114,\n",
       " 832,\n",
       " 1512,\n",
       " 10392,\n",
       " 4533,\n",
       " 722,\n",
       " 58,\n",
       " 5464,\n",
       " 2143,\n",
       " 10438,\n",
       " 4291,\n",
       " 2647,\n",
       " 7239,\n",
       " 9038,\n",
       " 7007,\n",
       " 9189,\n",
       " 158,\n",
       " 1232,\n",
       " 2442,\n",
       " 8938,\n",
       " 590,\n",
       " 6049,\n",
       " 9543,\n",
       " 9052,\n",
       " 2426,\n",
       " 7041,\n",
       " 2088,\n",
       " 685,\n",
       " 5050,\n",
       " 5974,\n",
       " 653,\n",
       " 5862,\n",
       " 3441,\n",
       " 4088,\n",
       " 10927,\n",
       " 1684,\n",
       " 5794,\n",
       " 9173,\n",
       " 10168,\n",
       " 2532,\n",
       " 3878,\n",
       " 2662,\n",
       " 2900,\n",
       " 6755,\n",
       " 406,\n",
       " 2938,\n",
       " 5442,\n",
       " 6745,\n",
       " 10975,\n",
       " 4065,\n",
       " 2608,\n",
       " 1771,\n",
       " 6267,\n",
       " 634,\n",
       " 7711,\n",
       " 3644,\n",
       " 3269,\n",
       " 7541,\n",
       " 5728,\n",
       " 5000,\n",
       " 3728,\n",
       " 3652,\n",
       " 387,\n",
       " 10813,\n",
       " 3164,\n",
       " 6528,\n",
       " 5378,\n",
       " 4564,\n",
       " 1137,\n",
       " 4573,\n",
       " 5753,\n",
       " 10510,\n",
       " 8346,\n",
       " 6548,\n",
       " 5425,\n",
       " 452,\n",
       " 1889,\n",
       " 4279,\n",
       " 2925,\n",
       " 9512,\n",
       " 4349,\n",
       " 626,\n",
       " 1776,\n",
       " 9774,\n",
       " 7119,\n",
       " 5663,\n",
       " 5139,\n",
       " 7149,\n",
       " 9932,\n",
       " 8379,\n",
       " 1894,\n",
       " 6311,\n",
       " 9446,\n",
       " 3114,\n",
       " 4173,\n",
       " 727,\n",
       " 7144,\n",
       " 27,\n",
       " 8518,\n",
       " 8821,\n",
       " 10987,\n",
       " 3228,\n",
       " 5967,\n",
       " 7066,\n",
       " 1146,\n",
       " 10882,\n",
       " 5409,\n",
       " 10209,\n",
       " 5143,\n",
       " 2041,\n",
       " 4920,\n",
       " 8308,\n",
       " 5067,\n",
       " 10926,\n",
       " 6691,\n",
       " 5344,\n",
       " 6592,\n",
       " 4844,\n",
       " 9083,\n",
       " 2085,\n",
       " 3143,\n",
       " 6888,\n",
       " 10894,\n",
       " 6211,\n",
       " 2851,\n",
       " 10084,\n",
       " 9324,\n",
       " 4930,\n",
       " 6653,\n",
       " 8977,\n",
       " 6,\n",
       " 4978,\n",
       " 4700,\n",
       " 3443,\n",
       " 7043,\n",
       " 9502,\n",
       " 9939,\n",
       " 10726,\n",
       " 5279,\n",
       " 7618,\n",
       " 7238,\n",
       " 7244,\n",
       " 3501,\n",
       " 8375,\n",
       " 7752,\n",
       " 2780,\n",
       " 10794,\n",
       " 1389,\n",
       " 4649,\n",
       " 8445,\n",
       " 10876,\n",
       " 10370,\n",
       " 10145,\n",
       " 5491,\n",
       " 1530,\n",
       " 3848,\n",
       " 5085,\n",
       " 3680,\n",
       " 3262,\n",
       " 2414,\n",
       " 400,\n",
       " 757,\n",
       " 4011,\n",
       " 7784,\n",
       " 10015,\n",
       " 1193,\n",
       " 7461,\n",
       " 6790,\n",
       " 10318,\n",
       " 9431,\n",
       " 3185,\n",
       " 6291,\n",
       " 8099,\n",
       " 6547,\n",
       " 3997,\n",
       " 2417,\n",
       " 10748,\n",
       " 90,\n",
       " 1746,\n",
       " 6965,\n",
       " 3585,\n",
       " 2881,\n",
       " 8486,\n",
       " 7611,\n",
       " 822,\n",
       " 9132,\n",
       " 4082,\n",
       " 1988,\n",
       " 7478,\n",
       " 2184,\n",
       " 7612,\n",
       " 10937,\n",
       " 8702,\n",
       " 9157,\n",
       " 9755,\n",
       " 5198,\n",
       " 7251,\n",
       " 10037,\n",
       " 8270,\n",
       " 6991,\n",
       " 8976,\n",
       " 7305,\n",
       " 2607,\n",
       " 7777,\n",
       " 7373,\n",
       " 4246,\n",
       " 4050,\n",
       " 10447,\n",
       " 4543,\n",
       " 8540,\n",
       " 7939,\n",
       " 10268,\n",
       " 3919,\n",
       " 4499,\n",
       " 7206,\n",
       " 1269,\n",
       " 4681,\n",
       " 3841,\n",
       " 4451,\n",
       " 5502,\n",
       " 5238,\n",
       " 8849,\n",
       " 1320,\n",
       " 2267,\n",
       " 2471,\n",
       " 3788,\n",
       " 6275,\n",
       " 2503,\n",
       " 3505,\n",
       " 1052,\n",
       " 6797,\n",
       " 6678,\n",
       " 5421,\n",
       " 8890,\n",
       " 7633,\n",
       " 6812,\n",
       " 1020,\n",
       " 3388,\n",
       " 6883,\n",
       " 6381,\n",
       " 9569,\n",
       " 320,\n",
       " 9432,\n",
       " 6232,\n",
       " 7814,\n",
       " 96,\n",
       " 5763,\n",
       " 4892,\n",
       " 6389,\n",
       " 6865,\n",
       " 8818,\n",
       " 8947,\n",
       " 9883,\n",
       " 3613,\n",
       " 7999,\n",
       " 3595,\n",
       " 4471,\n",
       " 7140,\n",
       " 475,\n",
       " 6371,\n",
       " 5507,\n",
       " 10958,\n",
       " 6624,\n",
       " 2704,\n",
       " 7657,\n",
       " 2091,\n",
       " 10195,\n",
       " 441,\n",
       " 6455,\n",
       " 9697,\n",
       " 9246,\n",
       " 10862,\n",
       " 444,\n",
       " 1375,\n",
       " 10530,\n",
       " 7022,\n",
       " 2223,\n",
       " 7564,\n",
       " 2977,\n",
       " 823,\n",
       " 4262,\n",
       " 5363,\n",
       " 3467,\n",
       " 7449,\n",
       " 5355,\n",
       " 5529,\n",
       " 4558,\n",
       " 6906,\n",
       " 4133,\n",
       " 1341,\n",
       " 7705,\n",
       " 317,\n",
       " 853,\n",
       " 5733,\n",
       " 3673,\n",
       " 10651,\n",
       " 1124,\n",
       " 10678,\n",
       " 659,\n",
       " 508,\n",
       " 4051,\n",
       " 3266,\n",
       " 333,\n",
       " 10179,\n",
       " 2496,\n",
       " 3908,\n",
       " 2068,\n",
       " 7758,\n",
       " 10968,\n",
       " 1874,\n",
       " 9240,\n",
       " 3571,\n",
       " 7619,\n",
       " 4198,\n",
       " 6043,\n",
       " 2749,\n",
       " 9926,\n",
       " 9949,\n",
       " 2683,\n",
       " 5096,\n",
       " 9481,\n",
       " 420,\n",
       " 5111,\n",
       " 9433,\n",
       " 6149,\n",
       " 6498,\n",
       " 3249,\n",
       " 1245,\n",
       " 9700,\n",
       " 10276,\n",
       " 3978,\n",
       " 1669,\n",
       " 4941,\n",
       " 9837,\n",
       " 1983,\n",
       " 9272,\n",
       " 672,\n",
       " 5688,\n",
       " 8728,\n",
       " 7018,\n",
       " 10838,\n",
       " 6071,\n",
       " 1129,\n",
       " 8289,\n",
       " 10609,\n",
       " 5590,\n",
       " 207,\n",
       " 6882,\n",
       " 8031,\n",
       " 1729,\n",
       " 7102,\n",
       " 5934,\n",
       " 10413,\n",
       " 7532,\n",
       " 2506,\n",
       " 7135,\n",
       " 2885,\n",
       " 8548,\n",
       " 10657,\n",
       " 4425,\n",
       " 10091,\n",
       " 8817,\n",
       " 7921,\n",
       " 7616,\n",
       " 7136,\n",
       " 9707,\n",
       " 4397,\n",
       " 5280,\n",
       " 4022,\n",
       " 1419,\n",
       " 4569,\n",
       " 7385,\n",
       " 3995,\n",
       " 7613,\n",
       " 9336,\n",
       " 9999,\n",
       " 10947,\n",
       " 5511,\n",
       " 470,\n",
       " 8098,\n",
       " 5325,\n",
       " 2979,\n",
       " 7988,\n",
       " 3475,\n",
       " 5813,\n",
       " 4232,\n",
       " 5576,\n",
       " 4581,\n",
       " 9767,\n",
       " 4526,\n",
       " 9106,\n",
       " 166,\n",
       " 8464,\n",
       " 3130,\n",
       " 1402,\n",
       " 3954,\n",
       " 9096,\n",
       " 3937,\n",
       " 7800,\n",
       " 10582,\n",
       " 8041,\n",
       " 7342,\n",
       " 282,\n",
       " 1524,\n",
       " 4820,\n",
       " 3630,\n",
       " 6625,\n",
       " 3986,\n",
       " 5016,\n",
       " 10878,\n",
       " 9528,\n",
       " 6046,\n",
       " 7753,\n",
       " 9068,\n",
       " 8698,\n",
       " 5632,\n",
       " 6971,\n",
       " 9017,\n",
       " 5419,\n",
       " 5764,\n",
       " 7434,\n",
       " 4438,\n",
       " 5023,\n",
       " 4118,\n",
       " 3777,\n",
       " 1976,\n",
       " 3155,\n",
       " 5169,\n",
       " 1958,\n",
       " 8779,\n",
       " 3033,\n",
       " 3138,\n",
       " 3545,\n",
       " 7933,\n",
       " 4530,\n",
       " 9659,\n",
       " 8595,\n",
       " 9777,\n",
       " 4636,\n",
       " 1647,\n",
       " 3180,\n",
       " 4853,\n",
       " 3727,\n",
       " 5912,\n",
       " 2939,\n",
       " 4952,\n",
       " 231,\n",
       " 2073,\n",
       " 4494,\n",
       " 745,\n",
       " 893,\n",
       " 9066,\n",
       " 4786,\n",
       " 10450,\n",
       " 8042,\n",
       " 1680,\n",
       " 200,\n",
       " 9405,\n",
       " 4658,\n",
       " 7690,\n",
       " 7843,\n",
       " 7216,\n",
       " 5582,\n",
       " 3020,\n",
       " 841,\n",
       " 4136,\n",
       " 7827,\n",
       " 1869,\n",
       " 1070,\n",
       " 6565,\n",
       " 8056,\n",
       " 1213,\n",
       " 9453,\n",
       " 10312,\n",
       " 878,\n",
       " 2485,\n",
       " 2444,\n",
       " 9221,\n",
       " 1395,\n",
       " 4066,\n",
       " 1940,\n",
       " 9143,\n",
       " 6818,\n",
       " 9933,\n",
       " 9766,\n",
       " 10132,\n",
       " 3697,\n",
       " 8561,\n",
       " 7381,\n",
       " 7253,\n",
       " 4871,\n",
       " 9642,\n",
       " 7025,\n",
       " 5003,\n",
       " 9316,\n",
       " 10174,\n",
       " 986,\n",
       " 9988,\n",
       " 1625,\n",
       " 3404,\n",
       " 10248,\n",
       " 3457,\n",
       " 4335,\n",
       " 10820,\n",
       " 1330,\n",
       " 2573,\n",
       " 3929,\n",
       " 2847,\n",
       " 9043,\n",
       " 1229,\n",
       " 2564,\n",
       " 43,\n",
       " 6693,\n",
       " 9729,\n",
       " 7699,\n",
       " 4771,\n",
       " 534,\n",
       " 3792,\n",
       " 4720,\n",
       " 4632,\n",
       " 7438,\n",
       " 1166,\n",
       " 3824,\n",
       " 4334,\n",
       " 10240,\n",
       " 9663,\n",
       " 10832,\n",
       " 3241,\n",
       " 1880,\n",
       " 8922,\n",
       " 3683,\n",
       " 10610,\n",
       " 2441,\n",
       " 4352,\n",
       " 2330,\n",
       " 977,\n",
       " 2718,\n",
       " 5039,\n",
       " 9325,\n",
       " 4728,\n",
       " 7195,\n",
       " 2037,\n",
       " 7679,\n",
       " 4982,\n",
       " 6594,\n",
       " 4460,\n",
       " 8199,\n",
       " 8847,\n",
       " 8090,\n",
       " 7172,\n",
       " 1317,\n",
       " 9798,\n",
       " 7078,\n",
       " 4102,\n",
       " 423,\n",
       " 1496,\n",
       " 9424,\n",
       " 9619,\n",
       " 339,\n",
       " 4415,\n",
       " 9441,\n",
       " 2870,\n",
       " 7708,\n",
       " 8502,\n",
       " 10674,\n",
       " 7245,\n",
       " 2973,\n",
       " 9590,\n",
       " 7141,\n",
       " 10400,\n",
       " 1494,\n",
       " 7700,\n",
       " 5700,\n",
       " 6690,\n",
       " 5460,\n",
       " 5260,\n",
       " 10979,\n",
       " 1713,\n",
       " 2634,\n",
       " 5403,\n",
       " 6744,\n",
       " 8117,\n",
       " 4722,\n",
       " 10855,\n",
       " 6561,\n",
       " 9012,\n",
       " 601,\n",
       " 7451,\n",
       " 1442,\n",
       " 5153,\n",
       " 4135,\n",
       " 5296,\n",
       " 1899,\n",
       " 6622,\n",
       " 8431,\n",
       " 18,\n",
       " 10775,\n",
       " 8889,\n",
       " 7569,\n",
       " 6770,\n",
       " 888,\n",
       " 3073,\n",
       " 8494,\n",
       " 5927,\n",
       " 10201,\n",
       " 8167,\n",
       " 10246,\n",
       " 7242,\n",
       " 845,\n",
       " 4375,\n",
       " 8998,\n",
       " 2146,\n",
       " 4719,\n",
       " 7178,\n",
       " 7941]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(42)\n",
    "\n",
    "sample_size = 1000\n",
    "l = random.sample(range(0, 11000), sample_size)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataset, model, loss_fn):\n",
    "    size = len(dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "    sample_size = 1000\n",
    "    # l = random.sample(range(0, 11000), 1)\n",
    "    with torch.no_grad():\n",
    "        for i in l:\n",
    "            X, y = dataset[i][0][0], dataset[i][1]\n",
    "            X = get_tf_feature(X, sr=128)\n",
    "            X = convert_data_to_tensor(X)\n",
    "            if y == 0:\n",
    "                y = [0]\n",
    "            else:\n",
    "                y = [1]\n",
    "            y = torch.tensor(y)\n",
    "            \n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= sample_size\n",
    "    correct /= sample_size\n",
    "\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.015926  [    1/11040]\n",
      "loss: 0.103227  [  101/11040]\n",
      "loss: 0.000000  [  201/11040]\n",
      "loss: 0.245797  [  301/11040]\n",
      "loss: 0.592975  [  401/11040]\n",
      "loss: 0.100824  [  501/11040]\n",
      "loss: 0.023340  [  601/11040]\n",
      "loss: 0.000293  [  701/11040]\n",
      "loss: 0.097830  [  801/11040]\n",
      "loss: 0.000253  [  901/11040]\n",
      "loss: 0.081287  [ 1001/11040]\n",
      "loss: 0.302080  [ 1101/11040]\n",
      "loss: 0.176189  [ 1201/11040]\n",
      "loss: 0.188418  [ 1301/11040]\n",
      "loss: 1.205439  [ 1401/11040]\n",
      "loss: 0.009578  [ 1501/11040]\n",
      "loss: 0.016469  [ 1601/11040]\n",
      "loss: 0.451299  [ 1701/11040]\n",
      "loss: 0.775532  [ 1801/11040]\n",
      "loss: 0.121244  [ 1901/11040]\n",
      "loss: 0.048656  [ 2001/11040]\n",
      "loss: 0.079172  [ 2101/11040]\n",
      "loss: 0.410055  [ 2201/11040]\n",
      "loss: 0.333061  [ 2301/11040]\n",
      "loss: 0.396655  [ 2401/11040]\n",
      "loss: 1.163746  [ 2501/11040]\n",
      "loss: 1.085184  [ 2601/11040]\n",
      "loss: 0.425549  [ 2701/11040]\n",
      "loss: 0.404562  [ 2801/11040]\n",
      "loss: 0.407916  [ 2901/11040]\n",
      "loss: 0.408503  [ 3001/11040]\n",
      "loss: 0.952876  [ 3101/11040]\n",
      "loss: 0.471283  [ 3201/11040]\n",
      "loss: 0.569170  [ 3301/11040]\n",
      "loss: 0.702127  [ 3401/11040]\n",
      "loss: 0.386305  [ 3501/11040]\n",
      "loss: 0.883943  [ 3601/11040]\n",
      "loss: 0.353507  [ 3701/11040]\n",
      "loss: 1.195348  [ 3801/11040]\n",
      "loss: 0.343929  [ 3901/11040]\n",
      "loss: 0.369869  [ 4001/11040]\n",
      "loss: 0.454251  [ 4101/11040]\n",
      "loss: 0.185057  [ 4201/11040]\n",
      "loss: 0.321034  [ 4301/11040]\n",
      "loss: 0.030405  [ 4401/11040]\n",
      "loss: 0.809395  [ 4501/11040]\n",
      "loss: 0.003924  [ 4601/11040]\n",
      "loss: 0.207114  [ 4701/11040]\n",
      "loss: 0.509773  [ 4801/11040]\n",
      "loss: 0.034501  [ 4901/11040]\n",
      "loss: 0.129723  [ 5001/11040]\n",
      "loss: 0.056546  [ 5101/11040]\n",
      "loss: 0.200445  [ 5201/11040]\n",
      "loss: 0.085922  [ 5301/11040]\n",
      "loss: 0.129080  [ 5401/11040]\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(dataset, model, loss_fn, optimizer)\n",
    "    test_loop(dataset, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
