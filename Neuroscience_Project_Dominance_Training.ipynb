{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQQ2QmmVMyJa",
        "outputId": "e7e4f1a5-5707-44d2-f40d-03b66bd8d3cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torcheeg\n",
            "  Downloading torcheeg-1.0.11.tar.gz (161 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.1/161.1 KB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.9/dist-packages (from torcheeg) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.21.5 in /usr/local/lib/python3.9/dist-packages (from torcheeg) (1.22.4)\n",
            "Requirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.9/dist-packages (from torcheeg) (1.4.4)\n",
            "Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.9/dist-packages (from torcheeg) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.9/dist-packages (from torcheeg) (1.2.2)\n",
            "Collecting lmdb>=1.3.0\n",
            "  Downloading lmdb-1.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (298 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.5/298.5 KB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops>=0.4.1\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 KB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mne>=1.0.3\n",
            "  Downloading mne-1.3.1-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xmltodict>=0.13.0\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: networkx>=2.6.3 in /usr/local/lib/python3.9/dist-packages (from torcheeg) (3.0)\n",
            "Requirement already satisfied: PyWavelets>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from torcheeg) (1.4.1)\n",
            "Collecting spectrum>=0.8.1\n",
            "  Downloading spectrum-0.8.1.tar.gz (230 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.8/230.8 KB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchmetrics>=0.8.2\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 KB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mne_connectivity>=0.4.0\n",
            "  Downloading mne_connectivity-0.5.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 KB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.9/dist-packages (from mne>=1.0.3->torcheeg) (1.6.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from mne>=1.0.3->torcheeg) (4.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from mne>=1.0.3->torcheeg) (23.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from mne>=1.0.3->torcheeg) (3.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from mne>=1.0.3->torcheeg) (3.7.1)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.9/dist-packages (from mne_connectivity>=0.4.0->torcheeg) (2022.12.0)\n",
            "Collecting netCDF4\n",
            "  Downloading netCDF4-1.6.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.3.5->torcheeg) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.3.5->torcheeg) (2022.7.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.2->torcheeg) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.2->torcheeg) (1.1.1)\n",
            "Collecting easydev\n",
            "  Downloading easydev-0.12.1.tar.gz (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 KB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from torchmetrics>=0.8.2->torcheeg) (2.0.0+cu118)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from pooch>=1.5->mne>=1.0.3->torcheeg) (2.27.1)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from pooch>=1.5->mne>=1.0.3->torcheeg) (1.4.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas>=1.3.5->torcheeg) (1.16.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics>=0.8.2->torcheeg) (2.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics>=0.8.2->torcheeg) (1.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics>=0.8.2->torcheeg) (3.10.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics>=0.8.2->torcheeg) (4.5.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics>=0.8.2->torcheeg) (16.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics>=0.8.2->torcheeg) (3.25.2)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.9/dist-packages (from easydev->spectrum>=0.8.1->torcheeg) (4.8.0)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->mne>=1.0.3->torcheeg) (2.1.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne>=1.0.3->torcheeg) (4.39.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne>=1.0.3->torcheeg) (1.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne>=1.0.3->torcheeg) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne>=1.0.3->torcheeg) (0.11.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne>=1.0.3->torcheeg) (5.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne>=1.0.3->torcheeg) (3.0.9)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne>=1.0.3->torcheeg) (8.4.0)\n",
            "Collecting cftime\n",
            "  Downloading cftime-1.6.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->mne>=1.0.3->torcheeg) (3.15.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.5->mne>=1.0.3->torcheeg) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.5->mne>=1.0.3->torcheeg) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.5->mne>=1.0.3->torcheeg) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.5->mne>=1.0.3->torcheeg) (2.0.12)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/dist-packages (from pexpect->easydev->spectrum>=0.8.1->torcheeg) (0.7.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.8.1->torchmetrics>=0.8.2->torcheeg) (1.3.0)\n",
            "Building wheels for collected packages: torcheeg, spectrum, easydev\n",
            "  Building wheel for torcheeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torcheeg: filename=torcheeg-1.0.11-py3-none-any.whl size=345121 sha256=42596c7b00c2bc3cbe39c0cb939f717e1aabc12f9b25e9422396b92fcba59845\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/3c/00/36d7085ce0082ba53038595f6a7a010bbf7b5703227a6b16e5\n",
            "  Building wheel for spectrum (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spectrum: filename=spectrum-0.8.1-cp39-cp39-linux_x86_64.whl size=237784 sha256=3d31e63f42059fa43d8a8dbe75c951937b6a61539a515f5256602fee20f41219\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/03/05/e7ced8d2ae677d5c887dafb37619e6f0f978b2f5e60b5cd8e9\n",
            "  Building wheel for easydev (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for easydev: filename=easydev-0.12.1-py3-none-any.whl size=64214 sha256=0aafc5571d3374d5c3d93ffd9e17a103df9abe1969c2688ca8dd8c3cbe641f88\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/61/14/9e079fd8b2ae87fdff1df1c8757e33652854b4f3149e944ff6\n",
            "Successfully built torcheeg spectrum easydev\n",
            "Installing collected packages: lmdb, xmltodict, einops, colorlog, colorama, cftime, netCDF4, easydev, spectrum, mne, mne_connectivity, torchmetrics, torcheeg\n",
            "Successfully installed cftime-1.6.2 colorama-0.4.6 colorlog-6.7.0 easydev-0.12.1 einops-0.6.0 lmdb-1.4.1 mne-1.3.1 mne_connectivity-0.5.0 netCDF4-1.6.3 spectrum-0.8.1 torcheeg-1.0.11 torchmetrics-0.11.4 xmltodict-0.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torcheeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MwikNtDMjis"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import signal\n",
        "from rich.pretty import pprint\n",
        "from torcheeg.datasets import DREAMERDataset\n",
        "from torcheeg.datasets.constants.emotion_recognition.dreamer import DREAMER_CHANNEL_LOCATION_DICT\n",
        "from torcheeg import transforms\n",
        "from torch import nn\n",
        "import torch\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "He4HfZ9INBqd",
        "outputId": "f642f9ac-82a3-407c-cb89-29942aa13509"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROctHay3Mjiv"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"/content/drive/MyDrive/Neuroscience/DREAMER.mat\"\n",
        "base_path = \"/content/drive/MyDrive/Neuroscience/Dominance/\"\n",
        "\n",
        "# dataset_path = \"/content/drive/MyDrive/Neuroscience/DREAMER.mat\"\n",
        "# base_path = \"/content/drive/MyDrive/Neuroscience/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeS8rzjgMjiv",
        "outputId": "4d707189-ed7b-4964-c5ea-033c34fcae86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[DREAMER]:   0%|          | 0/23 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The current io_size is not enough, and double the LMDB map size to 20971520 automatically.\n",
            "The current io_size is not enough, and double the LMDB map size to 41943040 automatically.\n",
            "The current io_size is not enough, and double the LMDB map size to 83886080 automatically.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[DREAMER]:   4%|▍         | 1/23 [00:04<01:40,  4.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The current io_size is not enough, and double the LMDB map size to 167772160 automatically.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[DREAMER]:  13%|█▎        | 3/23 [00:14<01:37,  4.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The current io_size is not enough, and double the LMDB map size to 335544320 automatically.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[DREAMER]:  26%|██▌       | 6/23 [00:29<01:22,  4.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The current io_size is not enough, and double the LMDB map size to 671088640 automatically.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[DREAMER]:  52%|█████▏    | 12/23 [00:58<00:53,  4.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The current io_size is not enough, and double the LMDB map size to 1342177280 automatically.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[DREAMER]: 100%|██████████| 23/23 [01:53<00:00,  4.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please wait for the writing process to complete...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "dataset = DREAMERDataset(\n",
        "    io_path=base_path + 'dreamer8sec',\n",
        "    mat_path=dataset_path,\n",
        "    offline_transform=transforms.Compose([\n",
        "        transforms.BaselineRemoval(),\n",
        "        transforms.MeanStdNormalize(),\n",
        "        transforms.To2d()\n",
        "    ]),\n",
        "    # online_transform=transforms.ToTensor(),\n",
        "    label_transform=transforms.Compose(\n",
        "        [transforms.Select('dominance'),\n",
        "         transforms.Binary(3.0)]),\n",
        "    chunk_size=976,\n",
        "    baseline_chunk_size=976,\n",
        "    num_baseline=8\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYg8kdfcMjix"
      },
      "outputs": [],
      "source": [
        "def get_tf_feature(eeg, sr, n_channels = 14):\n",
        "    WinLength = int(0.5*sr) # 500 points (0.5 sec, 500 ms)\n",
        "    step = int(0.025*sr) # 25 points (or 25 ms)\n",
        "    final_features = None\n",
        "    for i in range(n_channels):\n",
        "        eeg_single = eeg[i].squeeze()\n",
        "        myparams = dict(nperseg = WinLength, noverlap = WinLength-step, return_onesided=True, mode='magnitude')\n",
        "        f, nseg, Sxx = signal.spectrogram(x = eeg_single, fs = sr, **myparams)\n",
        "        if(isinstance(final_features, np.ndarray)):\n",
        "            final_features = np.concatenate((final_features, Sxx), axis=0)\n",
        "        else:\n",
        "            final_features = Sxx\n",
        "    return final_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxRp3C3nMjiy",
        "outputId": "51716853-ede0-4dde-8a89-23f22ef5e8a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# device = \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1a8bHcFMjiy"
      },
      "outputs": [],
      "source": [
        "def convert_data_to_tensor(data):\n",
        "    data = data.astype(\"float32\")\n",
        "    data = data.reshape(1, data.shape[0], data.shape[1])\n",
        "    return torch.from_numpy(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_xdabRlMjiz"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv2D_1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 1024, 11, stride=3),\n",
        "            nn.Conv2d(1024, 512, 7, stride=3),\n",
        "            nn.Conv2d(512, 128, 7, stride=3),\n",
        "        )\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            # nn.Linear(14550, 2048),\n",
        "            # nn.ReLU(),\n",
        "            nn.Linear(17280, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv2D_1(x)\n",
        "        # x = self.flatten(x)\n",
        "        x = x.view(1, -1)\n",
        "        # print(x.shape)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQi1-d9WMjiz"
      },
      "outputs": [],
      "source": [
        "random.seed(42)\n",
        "\n",
        "test_size = 2000\n",
        "test_index = random.sample(range(0, 11000), test_size)\n",
        "train_index = []\n",
        "\n",
        "for i in range(11040):\n",
        "    if i not in test_index:\n",
        "        train_index.append(i)\n",
        "random.shuffle(train_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2H8L58PHMjiz"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataset,  model, loss_fn, optimizer):\n",
        "    # size = len(dataset)\n",
        "    model.train()\n",
        "    sample_size = len(train_index)\n",
        "    j=0\n",
        "    correct = 0\n",
        "    for i in train_index:\n",
        "        # Compute prediction and loss\n",
        "        # print(i)\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        X, y = dataset[i][0][0], dataset[i][1]\n",
        "        X = get_tf_feature(X, sr=128)\n",
        "        X = convert_data_to_tensor(X)\n",
        "        if y == 0:\n",
        "            y = [0]\n",
        "        else:\n",
        "            y = [1]\n",
        "        y = torch.tensor(y)\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        pred = model(X)\n",
        "        # print(y.shape, pred.shape)\n",
        "        loss = loss_fn(pred, y)\n",
        "        \n",
        "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if j % 100 == 0:\n",
        "            loss, current = loss.item(), j + 1\n",
        "            print(f\"loss: {loss}  [{current:>5d}/{sample_size:>5d}]\")\n",
        "            # if j%1000 == 0:\n",
        "              # torch.save(model.state_dict(), \"eeg_model_1000.pth\")\n",
        "        j=j+1\n",
        "    correct /= sample_size\n",
        "    str = (f\"Train Accuracy: {(100*correct):>0.1f}\\n\")\n",
        "    print(str)\n",
        "    with open(base_path + \"log.txt\", \"a\") as f:\n",
        "        f.write(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0Yj50GzMji0"
      },
      "outputs": [],
      "source": [
        "\n",
        "val_error = 999999999.9\n",
        "best_model_parameter = None\n",
        "\n",
        "def test_loop(dataset, model, loss_fn):\n",
        "    global val_error\n",
        "    global best_model_parameter\n",
        "    # size = len(dataset)\n",
        "    test_loss, correct = 0, 0\n",
        "    sample_size = len(test_index)\n",
        "    # l = random.sample(range(0, 11000), 1)\n",
        "    # j=0\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for i in test_index:\n",
        "            X, y = dataset[i][0][0], dataset[i][1]\n",
        "            X = get_tf_feature(X, sr=128)\n",
        "            X = convert_data_to_tensor(X)\n",
        "            if y == 0:\n",
        "                y = [0]\n",
        "            else:\n",
        "                y = [1]\n",
        "            y = torch.tensor(y)\n",
        "            \n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= sample_size\n",
        "    correct /= sample_size\n",
        "\n",
        "    if val_error > test_loss:\n",
        "        val_error = test_loss\n",
        "        best_model_parameter = model.state_dict()\n",
        "\n",
        "    str = (f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    print(str)\n",
        "    with open(base_path + \"log.txt\", \"a\") as f:\n",
        "        f.write(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9Rdio0rMji1"
      },
      "outputs": [],
      "source": [
        "learning_rate = 3e-6"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_epoch = -1\n",
        "model = NeuralNetwork().to(device)\n",
        "if last_epoch >= 0:\n",
        "  model.load_state_dict(torch.load(base_path + f'eeg_model_{last_epoch}.pth', map_location=torch.device('cpu')))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZT3mi6dj5Dn5",
        "outputId": "3d353224-6268-432a-fb86-b9d3c5476c79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNetwork(\n",
              "  (conv2D_1): Sequential(\n",
              "    (0): Conv2d(1, 1024, kernel_size=(11, 11), stride=(3, 3))\n",
              "    (1): Conv2d(1024, 512, kernel_size=(7, 7), stride=(3, 3))\n",
              "    (2): Conv2d(512, 128, kernel_size=(7, 7), stride=(3, 3))\n",
              "  )\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (linear_relu_stack): Sequential(\n",
              "    (0): Linear(in_features=17280, out_features=1024, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=512, out_features=128, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=128, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBQGnn7TMji1",
        "outputId": "2fdd9010-f4b7-41f5-d19e-9a4ee7b513b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "\n",
            "loss: 0.6294053792953491  [    1/ 9040]\n",
            "loss: 0.29805564880371094  [  101/ 9040]\n",
            "loss: 1.13163161277771  [  201/ 9040]\n",
            "loss: 0.16692158579826355  [  301/ 9040]\n",
            "loss: 0.2309475541114807  [  401/ 9040]\n",
            "loss: 0.2986757159233093  [  501/ 9040]\n",
            "loss: 0.23922599852085114  [  601/ 9040]\n",
            "loss: 0.21948754787445068  [  701/ 9040]\n",
            "loss: 0.25264763832092285  [  801/ 9040]\n",
            "loss: 0.17561659216880798  [  901/ 9040]\n",
            "loss: 0.31783661246299744  [ 1001/ 9040]\n",
            "loss: 0.12202856689691544  [ 1101/ 9040]\n",
            "loss: 1.1746553182601929  [ 1201/ 9040]\n",
            "loss: 2.1508231163024902  [ 1301/ 9040]\n",
            "loss: 1.9563382863998413  [ 1401/ 9040]\n",
            "loss: 0.21818006038665771  [ 1501/ 9040]\n",
            "loss: 0.19849808514118195  [ 1601/ 9040]\n",
            "loss: 0.34767940640449524  [ 1701/ 9040]\n",
            "loss: 0.24475155770778656  [ 1801/ 9040]\n",
            "loss: 0.16371048986911774  [ 1901/ 9040]\n",
            "loss: 0.37707409262657166  [ 2001/ 9040]\n",
            "loss: 0.1633293628692627  [ 2101/ 9040]\n",
            "loss: 0.282116174697876  [ 2201/ 9040]\n",
            "loss: 0.29929763078689575  [ 2301/ 9040]\n",
            "loss: 0.1674489676952362  [ 2401/ 9040]\n",
            "loss: 0.3132462203502655  [ 2501/ 9040]\n",
            "loss: 0.3183821141719818  [ 2601/ 9040]\n",
            "loss: 0.21543675661087036  [ 2701/ 9040]\n",
            "loss: 0.11489378660917282  [ 2801/ 9040]\n",
            "loss: 0.18746662139892578  [ 2901/ 9040]\n",
            "loss: 0.20667685568332672  [ 3001/ 9040]\n",
            "loss: 0.19514894485473633  [ 3101/ 9040]\n",
            "loss: 0.289018839597702  [ 3201/ 9040]\n",
            "loss: 0.2883016765117645  [ 3301/ 9040]\n",
            "loss: 0.21033479273319244  [ 3401/ 9040]\n",
            "loss: 0.1745494306087494  [ 3501/ 9040]\n",
            "loss: 0.18868742883205414  [ 3601/ 9040]\n",
            "loss: 0.2461734414100647  [ 3701/ 9040]\n",
            "loss: 0.20784230530261993  [ 3801/ 9040]\n",
            "loss: 0.2167719155550003  [ 3901/ 9040]\n",
            "loss: 0.20513570308685303  [ 4001/ 9040]\n",
            "loss: 0.31593024730682373  [ 4101/ 9040]\n",
            "loss: 0.23686739802360535  [ 4201/ 9040]\n",
            "loss: 0.15591087937355042  [ 4301/ 9040]\n",
            "loss: 0.19404293596744537  [ 4401/ 9040]\n",
            "loss: 0.19323858618736267  [ 4501/ 9040]\n",
            "loss: 0.3739434778690338  [ 4601/ 9040]\n",
            "loss: 0.21957875788211823  [ 4701/ 9040]\n",
            "loss: 0.19618280231952667  [ 4801/ 9040]\n",
            "loss: 1.4804447889328003  [ 4901/ 9040]\n",
            "loss: 0.18218807876110077  [ 5001/ 9040]\n",
            "loss: 0.221877321600914  [ 5101/ 9040]\n",
            "loss: 1.795893669128418  [ 5201/ 9040]\n",
            "loss: 0.2521815001964569  [ 5301/ 9040]\n",
            "loss: 0.2832045257091522  [ 5401/ 9040]\n",
            "loss: 1.7672837972640991  [ 5501/ 9040]\n",
            "loss: 0.18218737840652466  [ 5601/ 9040]\n",
            "loss: 0.41219648718833923  [ 5701/ 9040]\n",
            "loss: 0.36482882499694824  [ 5801/ 9040]\n",
            "loss: 0.20724394917488098  [ 5901/ 9040]\n",
            "loss: 0.26119667291641235  [ 6001/ 9040]\n",
            "loss: 0.25470197200775146  [ 6101/ 9040]\n",
            "loss: 0.25037631392478943  [ 6201/ 9040]\n",
            "loss: 0.3468398153781891  [ 6301/ 9040]\n",
            "loss: 1.679189682006836  [ 6401/ 9040]\n",
            "loss: 0.28078773617744446  [ 6501/ 9040]\n",
            "loss: 2.33709716796875  [ 6601/ 9040]\n",
            "loss: 0.2525995075702667  [ 6701/ 9040]\n",
            "loss: 0.14778847992420197  [ 6801/ 9040]\n",
            "loss: 0.23564782738685608  [ 6901/ 9040]\n",
            "loss: 0.11202260106801987  [ 7001/ 9040]\n",
            "loss: 0.3308338522911072  [ 7101/ 9040]\n",
            "loss: 0.26338836550712585  [ 7201/ 9040]\n",
            "loss: 0.3760784864425659  [ 7301/ 9040]\n",
            "loss: 0.25529715418815613  [ 7401/ 9040]\n",
            "loss: 0.12239695340394974  [ 7501/ 9040]\n",
            "loss: 1.1898078918457031  [ 7601/ 9040]\n",
            "loss: 0.2253899872303009  [ 7701/ 9040]\n",
            "loss: 0.4892294406890869  [ 7801/ 9040]\n",
            "loss: 1.9256447553634644  [ 7901/ 9040]\n",
            "loss: 0.26735907793045044  [ 8001/ 9040]\n",
            "loss: 0.1734379231929779  [ 8101/ 9040]\n",
            "loss: 0.09609309583902359  [ 8201/ 9040]\n",
            "loss: 0.21803244948387146  [ 8301/ 9040]\n",
            "loss: 0.2795362174510956  [ 8401/ 9040]\n",
            "loss: 1.204560399055481  [ 8501/ 9040]\n",
            "loss: 0.3380752503871918  [ 8601/ 9040]\n",
            "loss: 0.39355242252349854  [ 8701/ 9040]\n",
            "loss: 0.20081990957260132  [ 8801/ 9040]\n",
            "loss: 0.6522451043128967  [ 8901/ 9040]\n",
            "loss: 1.6237750053405762  [ 9001/ 9040]\n",
            "Train Accuracy: 79.7\n",
            "\n",
            "Test Error: \n",
            " Accuracy: 80.3%, Avg loss: 0.500151 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "\n",
            "loss: 1.2089763879776  [    1/ 9040]\n",
            "loss: 0.19639705121517181  [  101/ 9040]\n",
            "loss: 1.0997881889343262  [  201/ 9040]\n",
            "loss: 0.158443883061409  [  301/ 9040]\n",
            "loss: 0.13175882399082184  [  401/ 9040]\n",
            "loss: 0.24685083329677582  [  501/ 9040]\n",
            "loss: 0.13594263792037964  [  601/ 9040]\n",
            "loss: 0.24076266586780548  [  701/ 9040]\n",
            "loss: 0.27402743697166443  [  801/ 9040]\n",
            "loss: 0.19355258345603943  [  901/ 9040]\n",
            "loss: 0.3656249940395355  [ 1001/ 9040]\n",
            "loss: 0.15237687528133392  [ 1101/ 9040]\n",
            "loss: 1.0682812929153442  [ 1201/ 9040]\n",
            "loss: 1.5237466096878052  [ 1301/ 9040]\n",
            "loss: 1.8163639307022095  [ 1401/ 9040]\n",
            "loss: 0.35451430082321167  [ 1501/ 9040]\n",
            "loss: 0.11863207817077637  [ 1601/ 9040]\n",
            "loss: 0.4176642596721649  [ 1701/ 9040]\n",
            "loss: 0.1941801756620407  [ 1801/ 9040]\n",
            "loss: 0.10988111793994904  [ 1901/ 9040]\n",
            "loss: 0.2861059606075287  [ 2001/ 9040]\n",
            "loss: 0.17264790832996368  [ 2101/ 9040]\n",
            "loss: 0.16792507469654083  [ 2201/ 9040]\n",
            "loss: 0.2052925080060959  [ 2301/ 9040]\n",
            "loss: 0.025113163515925407  [ 2401/ 9040]\n",
            "loss: 0.3195244073867798  [ 2501/ 9040]\n",
            "loss: 0.10581310838460922  [ 2601/ 9040]\n",
            "loss: 0.017554156482219696  [ 2701/ 9040]\n",
            "loss: 0.16856472194194794  [ 2801/ 9040]\n",
            "loss: 0.3744029700756073  [ 2901/ 9040]\n",
            "loss: 0.0018529404187574983  [ 3001/ 9040]\n",
            "loss: 0.10229191929101944  [ 3101/ 9040]\n",
            "loss: 0.19380952417850494  [ 3201/ 9040]\n",
            "loss: 0.35435113310813904  [ 3301/ 9040]\n",
            "loss: 0.18598385155200958  [ 3401/ 9040]\n",
            "loss: 0.08986575156450272  [ 3501/ 9040]\n",
            "loss: 0.13123151659965515  [ 3601/ 9040]\n",
            "loss: 0.24651148915290833  [ 3701/ 9040]\n",
            "loss: 0.29644834995269775  [ 3801/ 9040]\n",
            "loss: 0.21412396430969238  [ 3901/ 9040]\n",
            "loss: 0.3531303107738495  [ 4001/ 9040]\n",
            "loss: 0.21098053455352783  [ 4101/ 9040]\n",
            "loss: 0.29701319336891174  [ 4201/ 9040]\n",
            "loss: 0.17493540048599243  [ 4301/ 9040]\n",
            "loss: 0.3541373014450073  [ 4401/ 9040]\n",
            "loss: 0.3249782621860504  [ 4501/ 9040]\n",
            "loss: 0.04393162578344345  [ 4601/ 9040]\n",
            "loss: 0.1780216246843338  [ 4701/ 9040]\n",
            "loss: 0.23929449915885925  [ 4801/ 9040]\n",
            "loss: 0.9792289733886719  [ 4901/ 9040]\n",
            "loss: 0.003288221312686801  [ 5001/ 9040]\n",
            "loss: 0.18495692312717438  [ 5101/ 9040]\n",
            "loss: 2.3760335445404053  [ 5201/ 9040]\n",
            "loss: 0.04744453355669975  [ 5301/ 9040]\n",
            "loss: 0.1930403709411621  [ 5401/ 9040]\n",
            "loss: 0.9922600984573364  [ 5501/ 9040]\n",
            "loss: 0.05683349072933197  [ 5601/ 9040]\n",
            "loss: 0.2135954201221466  [ 5701/ 9040]\n",
            "loss: 0.29718315601348877  [ 5801/ 9040]\n",
            "loss: 0.06336989998817444  [ 5901/ 9040]\n",
            "loss: 0.18795235455036163  [ 6001/ 9040]\n",
            "loss: 0.0007678897818550467  [ 6101/ 9040]\n",
            "loss: 0.23035918176174164  [ 6201/ 9040]\n",
            "loss: 0.22658705711364746  [ 6301/ 9040]\n",
            "loss: 1.8163988590240479  [ 6401/ 9040]\n",
            "loss: 0.17515774071216583  [ 6501/ 9040]\n",
            "loss: 2.615154504776001  [ 6601/ 9040]\n",
            "loss: 0.07730220258235931  [ 6701/ 9040]\n",
            "loss: 0.12703903019428253  [ 6801/ 9040]\n",
            "loss: 0.19314159452915192  [ 6901/ 9040]\n",
            "loss: 0.03953297808766365  [ 7001/ 9040]\n",
            "loss: 0.39593908190727234  [ 7101/ 9040]\n",
            "loss: 0.20043013989925385  [ 7201/ 9040]\n",
            "loss: 0.2691652178764343  [ 7301/ 9040]\n",
            "loss: 0.2398647964000702  [ 7401/ 9040]\n",
            "loss: 0.04458478093147278  [ 7501/ 9040]\n",
            "loss: 0.9426809549331665  [ 7601/ 9040]\n",
            "loss: 0.3981657326221466  [ 7701/ 9040]\n",
            "loss: 0.562403678894043  [ 7801/ 9040]\n",
            "loss: 2.7256863117218018  [ 7901/ 9040]\n",
            "loss: 0.17590607702732086  [ 8001/ 9040]\n",
            "loss: 0.12804503738880157  [ 8101/ 9040]\n",
            "loss: 0.10442757606506348  [ 8201/ 9040]\n",
            "loss: 0.17026148736476898  [ 8301/ 9040]\n",
            "loss: 0.27258172631263733  [ 8401/ 9040]\n",
            "loss: 1.0632129907608032  [ 8501/ 9040]\n",
            "loss: 0.24487315118312836  [ 8601/ 9040]\n",
            "loss: 0.3245505094528198  [ 8701/ 9040]\n",
            "loss: 0.08589278906583786  [ 8801/ 9040]\n",
            "loss: 0.7576011419296265  [ 8901/ 9040]\n",
            "loss: 1.037295937538147  [ 9001/ 9040]\n",
            "Train Accuracy: 80.9\n",
            "\n",
            "Test Error: \n",
            " Accuracy: 80.2%, Avg loss: 0.449031 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "\n",
            "loss: 0.8004300594329834  [    1/ 9040]\n",
            "loss: 0.2418770045042038  [  101/ 9040]\n",
            "loss: 0.40616747736930847  [  201/ 9040]\n",
            "loss: 0.19687318801879883  [  301/ 9040]\n",
            "loss: 0.10583466291427612  [  401/ 9040]\n",
            "loss: 0.21543243527412415  [  501/ 9040]\n",
            "loss: 0.03461778908967972  [  601/ 9040]\n",
            "loss: 0.25158241391181946  [  701/ 9040]\n",
            "loss: 0.20361579954624176  [  801/ 9040]\n",
            "loss: 0.3692890405654907  [  901/ 9040]\n",
            "loss: 0.26018840074539185  [ 1001/ 9040]\n",
            "loss: 0.037233754992485046  [ 1101/ 9040]\n",
            "loss: 0.8257497549057007  [ 1201/ 9040]\n",
            "loss: 0.9024243354797363  [ 1301/ 9040]\n",
            "loss: 1.9617794752120972  [ 1401/ 9040]\n",
            "loss: 0.11316380649805069  [ 1501/ 9040]\n",
            "loss: 0.06891261786222458  [ 1601/ 9040]\n",
            "loss: 0.6202581524848938  [ 1701/ 9040]\n",
            "loss: 0.10371168702840805  [ 1801/ 9040]\n",
            "loss: 0.06326225399971008  [ 1901/ 9040]\n",
            "loss: 0.1348540186882019  [ 2001/ 9040]\n",
            "loss: 0.11350344121456146  [ 2101/ 9040]\n",
            "loss: 0.052203550934791565  [ 2201/ 9040]\n",
            "loss: 0.09374798834323883  [ 2301/ 9040]\n",
            "loss: 0.006639562547206879  [ 2401/ 9040]\n",
            "loss: 0.2124730944633484  [ 2501/ 9040]\n",
            "loss: 0.047652557492256165  [ 2601/ 9040]\n",
            "loss: 0.0006878394051454961  [ 2701/ 9040]\n",
            "loss: 0.2218482941389084  [ 2801/ 9040]\n",
            "loss: 0.35617774724960327  [ 2901/ 9040]\n",
            "loss: 3.099393507000059e-05  [ 3001/ 9040]\n",
            "loss: 0.08539698272943497  [ 3101/ 9040]\n",
            "loss: 0.21968719363212585  [ 3201/ 9040]\n",
            "loss: 0.527543306350708  [ 3301/ 9040]\n",
            "loss: 0.04879068583250046  [ 3401/ 9040]\n",
            "loss: 0.010795170441269875  [ 3501/ 9040]\n",
            "loss: 0.22996239364147186  [ 3601/ 9040]\n",
            "loss: 0.14464183151721954  [ 3701/ 9040]\n",
            "loss: 0.14488565921783447  [ 3801/ 9040]\n",
            "loss: 0.11064853519201279  [ 3901/ 9040]\n",
            "loss: 0.4838687777519226  [ 4001/ 9040]\n",
            "loss: 0.2277839332818985  [ 4101/ 9040]\n",
            "loss: 0.3302100896835327  [ 4201/ 9040]\n",
            "loss: 0.10370222479104996  [ 4301/ 9040]\n",
            "loss: 0.23220708966255188  [ 4401/ 9040]\n",
            "loss: 0.3420202136039734  [ 4501/ 9040]\n",
            "loss: 0.004200920462608337  [ 4601/ 9040]\n",
            "loss: 0.1788240522146225  [ 4701/ 9040]\n",
            "loss: 0.18517665565013885  [ 4801/ 9040]\n",
            "loss: 1.163157343864441  [ 4901/ 9040]\n",
            "loss: 0.0026959760580211878  [ 5001/ 9040]\n",
            "loss: 0.19821105897426605  [ 5101/ 9040]\n",
            "loss: 2.3024559020996094  [ 5201/ 9040]\n",
            "loss: 0.005293519701808691  [ 5301/ 9040]\n",
            "loss: 0.04975025728344917  [ 5401/ 9040]\n",
            "loss: 1.116278886795044  [ 5501/ 9040]\n",
            "loss: 0.008146983571350574  [ 5601/ 9040]\n",
            "loss: 0.24185922741889954  [ 5701/ 9040]\n",
            "loss: 0.2062259316444397  [ 5801/ 9040]\n",
            "loss: 0.016359955072402954  [ 5901/ 9040]\n",
            "loss: 0.1604594886302948  [ 6001/ 9040]\n",
            "loss: 0.00041976699139922857  [ 6101/ 9040]\n",
            "loss: 0.09663655608892441  [ 6201/ 9040]\n",
            "loss: 0.09342220425605774  [ 6301/ 9040]\n",
            "loss: 1.658847451210022  [ 6401/ 9040]\n",
            "loss: 0.08255541324615479  [ 6501/ 9040]\n",
            "loss: 2.3207054138183594  [ 6601/ 9040]\n",
            "loss: 0.020880170166492462  [ 6701/ 9040]\n",
            "loss: 0.18823692202568054  [ 6801/ 9040]\n",
            "loss: 0.12395983934402466  [ 6901/ 9040]\n",
            "loss: 0.020131198689341545  [ 7001/ 9040]\n",
            "loss: 0.40430548787117004  [ 7101/ 9040]\n",
            "loss: 0.15573225915431976  [ 7201/ 9040]\n",
            "loss: 0.06709112226963043  [ 7301/ 9040]\n",
            "loss: 0.21979399025440216  [ 7401/ 9040]\n",
            "loss: 0.04786655679345131  [ 7501/ 9040]\n",
            "loss: 0.9386051893234253  [ 7601/ 9040]\n",
            "loss: 0.5512277483940125  [ 7701/ 9040]\n",
            "loss: 0.4022248387336731  [ 7801/ 9040]\n",
            "loss: 3.567753791809082  [ 7901/ 9040]\n",
            "loss: 0.09992626309394836  [ 8001/ 9040]\n",
            "loss: 0.09789132326841354  [ 8101/ 9040]\n",
            "loss: 0.04300585016608238  [ 8201/ 9040]\n",
            "loss: 0.12103760242462158  [ 8301/ 9040]\n",
            "loss: 0.21651236712932587  [ 8401/ 9040]\n",
            "loss: 1.2620431184768677  [ 8501/ 9040]\n",
            "loss: 0.33238187432289124  [ 8601/ 9040]\n",
            "loss: 0.4042474925518036  [ 8701/ 9040]\n",
            "loss: 0.023205729201436043  [ 8801/ 9040]\n",
            "loss: 1.075884461402893  [ 8901/ 9040]\n",
            "loss: 0.9669709205627441  [ 9001/ 9040]\n",
            "Train Accuracy: 82.7\n",
            "\n",
            "Test Error: \n",
            " Accuracy: 81.9%, Avg loss: 0.385926 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "\n",
            "loss: 0.498390793800354  [    1/ 9040]\n",
            "loss: 0.1340777575969696  [  101/ 9040]\n",
            "loss: 0.14878298342227936  [  201/ 9040]\n",
            "loss: 0.4601499140262604  [  301/ 9040]\n",
            "loss: 0.17916123569011688  [  401/ 9040]\n",
            "loss: 0.18301187455654144  [  501/ 9040]\n",
            "loss: 0.006284238304942846  [  601/ 9040]\n",
            "loss: 0.20114068686962128  [  701/ 9040]\n",
            "loss: 0.1512155383825302  [  801/ 9040]\n",
            "loss: 0.3946920335292816  [  901/ 9040]\n",
            "loss: 0.16394071280956268  [ 1001/ 9040]\n",
            "loss: 0.009404524229466915  [ 1101/ 9040]\n",
            "loss: 0.4691295325756073  [ 1201/ 9040]\n",
            "loss: 0.5442078113555908  [ 1301/ 9040]\n",
            "loss: 1.7831662893295288  [ 1401/ 9040]\n",
            "loss: 0.05523939058184624  [ 1501/ 9040]\n",
            "loss: 0.032140545547008514  [ 1601/ 9040]\n",
            "loss: 0.3525020480155945  [ 1701/ 9040]\n",
            "loss: 0.05717715620994568  [ 1801/ 9040]\n",
            "loss: 0.025025157257914543  [ 1901/ 9040]\n",
            "loss: 0.10073152929544449  [ 2001/ 9040]\n",
            "loss: 0.11136993020772934  [ 2101/ 9040]\n",
            "loss: 0.020494600757956505  [ 2201/ 9040]\n",
            "loss: 0.07819799333810806  [ 2301/ 9040]\n",
            "loss: 0.0006283930852077901  [ 2401/ 9040]\n",
            "loss: 0.18297713994979858  [ 2501/ 9040]\n",
            "loss: 0.011480458080768585  [ 2601/ 9040]\n",
            "loss: 3.135155202471651e-05  [ 2701/ 9040]\n",
            "loss: 0.08749964088201523  [ 2801/ 9040]\n",
            "loss: 0.17520956695079803  [ 2901/ 9040]\n",
            "loss: 7.867782187531702e-06  [ 3001/ 9040]\n",
            "loss: 0.09234312921762466  [ 3101/ 9040]\n",
            "loss: 0.13526177406311035  [ 3201/ 9040]\n",
            "loss: 0.5713140964508057  [ 3301/ 9040]\n",
            "loss: 0.006332096178084612  [ 3401/ 9040]\n",
            "loss: 0.0009380945703014731  [ 3501/ 9040]\n",
            "loss: 0.2868128716945648  [ 3601/ 9040]\n",
            "loss: 0.09459175914525986  [ 3701/ 9040]\n",
            "loss: 0.15487922728061676  [ 3801/ 9040]\n",
            "loss: 0.04599478840827942  [ 3901/ 9040]\n",
            "loss: 0.44649314880371094  [ 4001/ 9040]\n",
            "loss: 0.2678222954273224  [ 4101/ 9040]\n",
            "loss: 0.24818891286849976  [ 4201/ 9040]\n",
            "loss: 0.025412121787667274  [ 4301/ 9040]\n",
            "loss: 0.09288927167654037  [ 4401/ 9040]\n",
            "loss: 0.17261973023414612  [ 4501/ 9040]\n",
            "loss: 0.0006500753224827349  [ 4601/ 9040]\n",
            "loss: 0.17123620212078094  [ 4701/ 9040]\n",
            "loss: 0.15040592849254608  [ 4801/ 9040]\n",
            "loss: 0.7176805734634399  [ 4901/ 9040]\n",
            "loss: 0.002466614358127117  [ 5001/ 9040]\n",
            "loss: 0.22496284544467926  [ 5101/ 9040]\n",
            "loss: 1.8044939041137695  [ 5201/ 9040]\n",
            "loss: 0.0002002515539061278  [ 5301/ 9040]\n",
            "loss: 0.005843816325068474  [ 5401/ 9040]\n",
            "loss: 0.45341920852661133  [ 5501/ 9040]\n",
            "loss: 0.0005858612130396068  [ 5601/ 9040]\n",
            "loss: 0.26975515484809875  [ 5701/ 9040]\n",
            "loss: 0.11477125436067581  [ 5801/ 9040]\n",
            "loss: 0.006552164442837238  [ 5901/ 9040]\n",
            "loss: 0.10827990621328354  [ 6001/ 9040]\n",
            "loss: 0.0009633429581299424  [ 6101/ 9040]\n",
            "loss: 0.04228070005774498  [ 6201/ 9040]\n",
            "loss: 0.03706547990441322  [ 6301/ 9040]\n",
            "loss: 1.3898591995239258  [ 6401/ 9040]\n",
            "loss: 0.0380772165954113  [ 6501/ 9040]\n",
            "loss: 1.3795714378356934  [ 6601/ 9040]\n",
            "loss: 0.0027215369045734406  [ 6701/ 9040]\n",
            "loss: 0.2157316654920578  [ 6801/ 9040]\n",
            "loss: 0.07833843678236008  [ 6901/ 9040]\n",
            "loss: 0.005875222384929657  [ 7001/ 9040]\n",
            "loss: 0.2693774104118347  [ 7101/ 9040]\n",
            "loss: 0.22214092314243317  [ 7201/ 9040]\n",
            "loss: 0.01230623573064804  [ 7301/ 9040]\n",
            "loss: 0.16792547702789307  [ 7401/ 9040]\n",
            "loss: 0.043694868683815  [ 7501/ 9040]\n",
            "loss: 0.6799761652946472  [ 7601/ 9040]\n",
            "loss: 0.4927928149700165  [ 7701/ 9040]\n",
            "loss: 0.1456843912601471  [ 7801/ 9040]\n",
            "loss: 3.9638259410858154  [ 7901/ 9040]\n",
            "loss: 0.05077553540468216  [ 8001/ 9040]\n",
            "loss: 0.13704389333724976  [ 8101/ 9040]\n",
            "loss: 0.00845495704561472  [ 8201/ 9040]\n",
            "loss: 0.06022680550813675  [ 8301/ 9040]\n",
            "loss: 0.15165650844573975  [ 8401/ 9040]\n",
            "loss: 0.8650275468826294  [ 8501/ 9040]\n",
            "loss: 0.16361919045448303  [ 8601/ 9040]\n",
            "loss: 0.43250057101249695  [ 8701/ 9040]\n",
            "loss: 0.007884925231337547  [ 8801/ 9040]\n",
            "loss: 1.2058298587799072  [ 8901/ 9040]\n",
            "loss: 0.5910616517066956  [ 9001/ 9040]\n",
            "Train Accuracy: 85.6\n",
            "\n",
            "Test Error: \n",
            " Accuracy: 85.2%, Avg loss: 0.334136 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "\n",
            "loss: 0.1789577156305313  [    1/ 9040]\n",
            "loss: 0.034330904483795166  [  101/ 9040]\n",
            "loss: 0.05229462683200836  [  201/ 9040]\n",
            "loss: 0.7170746326446533  [  301/ 9040]\n",
            "loss: 0.06582631915807724  [  401/ 9040]\n",
            "loss: 0.12820559740066528  [  501/ 9040]\n",
            "loss: 0.0004017737810499966  [  601/ 9040]\n",
            "loss: 0.08480960130691528  [  701/ 9040]\n",
            "loss: 0.1676458716392517  [  801/ 9040]\n",
            "loss: 0.3167774975299835  [  901/ 9040]\n",
            "loss: 0.1090407446026802  [ 1001/ 9040]\n",
            "loss: 0.0018653151346370578  [ 1101/ 9040]\n",
            "loss: 0.18637017905712128  [ 1201/ 9040]\n",
            "loss: 0.5319734811782837  [ 1301/ 9040]\n",
            "loss: 0.9128944873809814  [ 1401/ 9040]\n",
            "loss: 0.07765953242778778  [ 1501/ 9040]\n",
            "loss: 0.022911587730050087  [ 1601/ 9040]\n",
            "loss: 0.11340244859457016  [ 1701/ 9040]\n",
            "loss: 0.020860090851783752  [ 1801/ 9040]\n",
            "loss: 0.00752211594954133  [ 1901/ 9040]\n",
            "loss: 0.09105699509382248  [ 2001/ 9040]\n",
            "loss: 0.12287528067827225  [ 2101/ 9040]\n",
            "loss: 0.005962916649878025  [ 2201/ 9040]\n",
            "loss: 0.07568284869194031  [ 2301/ 9040]\n",
            "loss: 2.5629668016335927e-05  [ 2401/ 9040]\n",
            "loss: 0.14261958003044128  [ 2501/ 9040]\n",
            "loss: 0.0029369338881224394  [ 2601/ 9040]\n",
            "loss: 1.311301275563892e-06  [ 2701/ 9040]\n",
            "loss: 0.030878812074661255  [ 2801/ 9040]\n",
            "loss: 0.06367475539445877  [ 2901/ 9040]\n",
            "loss: 5.960462772236497e-07  [ 3001/ 9040]\n",
            "loss: 0.1719452142715454  [ 3101/ 9040]\n",
            "loss: 0.04249231517314911  [ 3201/ 9040]\n",
            "loss: 0.49725645780563354  [ 3301/ 9040]\n",
            "loss: 0.00037877538125030696  [ 3401/ 9040]\n",
            "loss: 8.034383063204587e-05  [ 3501/ 9040]\n",
            "loss: 0.2388383448123932  [ 3601/ 9040]\n",
            "loss: 0.09496063739061356  [ 3701/ 9040]\n",
            "loss: 0.2957790791988373  [ 3801/ 9040]\n",
            "loss: 0.012907057069242  [ 3901/ 9040]\n",
            "loss: 0.2937343120574951  [ 4001/ 9040]\n",
            "loss: 0.13778544962406158  [ 4101/ 9040]\n",
            "loss: 0.16901513934135437  [ 4201/ 9040]\n",
            "loss: 0.002558531705290079  [ 4301/ 9040]\n",
            "loss: 0.02223840542137623  [ 4401/ 9040]\n",
            "loss: 0.048245809972286224  [ 4501/ 9040]\n",
            "loss: 8.356221951544285e-05  [ 4601/ 9040]\n",
            "loss: 0.1579105108976364  [ 4701/ 9040]\n",
            "loss: 0.17734795808792114  [ 4801/ 9040]\n",
            "loss: 0.3918154835700989  [ 4901/ 9040]\n",
            "loss: 0.0006605588714592159  [ 5001/ 9040]\n",
            "loss: 0.1805974394083023  [ 5101/ 9040]\n",
            "loss: 1.239606261253357  [ 5201/ 9040]\n",
            "loss: 1.168244216387393e-05  [ 5301/ 9040]\n",
            "loss: 0.0002828436263371259  [ 5401/ 9040]\n",
            "loss: 0.10253316909074783  [ 5501/ 9040]\n",
            "loss: 6.246371776796877e-05  [ 5601/ 9040]\n",
            "loss: 0.12762175500392914  [ 5701/ 9040]\n",
            "loss: 0.06821013987064362  [ 5801/ 9040]\n",
            "loss: 0.004197240807116032  [ 5901/ 9040]\n",
            "loss: 0.02739759534597397  [ 6001/ 9040]\n",
            "loss: 0.003463699948042631  [ 6101/ 9040]\n",
            "loss: 0.027717437595129013  [ 6201/ 9040]\n",
            "loss: 0.009562875144183636  [ 6301/ 9040]\n",
            "loss: 1.2520692348480225  [ 6401/ 9040]\n",
            "loss: 0.030852342024445534  [ 6501/ 9040]\n",
            "loss: 0.7174485921859741  [ 6601/ 9040]\n",
            "loss: 0.000745137978810817  [ 6701/ 9040]\n",
            "loss: 0.3050366938114166  [ 6801/ 9040]\n",
            "loss: 0.052549149841070175  [ 6901/ 9040]\n",
            "loss: 0.0029332491103559732  [ 7001/ 9040]\n",
            "loss: 0.1617969572544098  [ 7101/ 9040]\n",
            "loss: 0.43012121319770813  [ 7201/ 9040]\n",
            "loss: 0.00569364707916975  [ 7301/ 9040]\n",
            "loss: 0.11511459201574326  [ 7401/ 9040]\n",
            "loss: 0.029677513986825943  [ 7501/ 9040]\n",
            "loss: 0.5761631727218628  [ 7601/ 9040]\n",
            "loss: 0.24730560183525085  [ 7701/ 9040]\n",
            "loss: 0.053712453693151474  [ 7801/ 9040]\n",
            "loss: 3.0253477096557617  [ 7901/ 9040]\n",
            "loss: 0.030302688479423523  [ 8001/ 9040]\n",
            "loss: 0.16147789359092712  [ 8101/ 9040]\n",
            "loss: 0.002003211760893464  [ 8201/ 9040]\n",
            "loss: 0.017396362498402596  [ 8301/ 9040]\n",
            "loss: 0.11872778832912445  [ 8401/ 9040]\n",
            "loss: 0.4883917570114136  [ 8501/ 9040]\n",
            "loss: 0.0834088996052742  [ 8601/ 9040]\n",
            "loss: 0.5864755511283875  [ 8701/ 9040]\n",
            "loss: 0.008851340040564537  [ 8801/ 9040]\n",
            "loss: 1.3659255504608154  [ 8901/ 9040]\n",
            "loss: 0.22104115784168243  [ 9001/ 9040]\n",
            "Train Accuracy: 89.1\n",
            "\n",
            "Test Error: \n",
            " Accuracy: 87.4%, Avg loss: 0.305180 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "\n",
            "loss: 0.04551399499177933  [    1/ 9040]\n",
            "loss: 0.009677046909928322  [  101/ 9040]\n",
            "loss: 0.03146176412701607  [  201/ 9040]\n",
            "loss: 0.5564321279525757  [  301/ 9040]\n",
            "loss: 0.011381696909666061  [  401/ 9040]\n",
            "loss: 0.08099028468132019  [  501/ 9040]\n",
            "loss: 2.3841574147809297e-05  [  601/ 9040]\n",
            "loss: 0.030896957963705063  [  701/ 9040]\n",
            "loss: 0.19325843453407288  [  801/ 9040]\n",
            "loss: 0.23353005945682526  [  901/ 9040]\n",
            "loss: 0.11220632493495941  [ 1001/ 9040]\n",
            "loss: 0.0003057250869460404  [ 1101/ 9040]\n",
            "loss: 0.1047283262014389  [ 1201/ 9040]\n",
            "loss: 0.5369210839271545  [ 1301/ 9040]\n",
            "loss: 0.2445182055234909  [ 1401/ 9040]\n",
            "loss: 0.1570339798927307  [ 1501/ 9040]\n",
            "loss: 0.03183608502149582  [ 1601/ 9040]\n",
            "loss: 0.02670316770672798  [ 1701/ 9040]\n",
            "loss: 0.006690482143312693  [ 1801/ 9040]\n",
            "loss: 0.00195443257689476  [ 1901/ 9040]\n",
            "loss: 0.07150797545909882  [ 2001/ 9040]\n",
            "loss: 0.07363170385360718  [ 2101/ 9040]\n",
            "loss: 0.0025928947143256664  [ 2201/ 9040]\n",
            "loss: 0.07836047559976578  [ 2301/ 9040]\n",
            "loss: 1.5497195136049413e-06  [ 2401/ 9040]\n",
            "loss: 0.13128577172756195  [ 2501/ 9040]\n",
            "loss: 0.0011717366287484765  [ 2601/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 2701/ 9040]\n",
            "loss: 0.009796636179089546  [ 2801/ 9040]\n",
            "loss: 0.02686588279902935  [ 2901/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 3001/ 9040]\n",
            "loss: 0.25050538778305054  [ 3101/ 9040]\n",
            "loss: 0.010093126446008682  [ 3201/ 9040]\n",
            "loss: 0.3731786012649536  [ 3301/ 9040]\n",
            "loss: 3.099393507000059e-05  [ 3401/ 9040]\n",
            "loss: 2.3483953555114567e-05  [ 3501/ 9040]\n",
            "loss: 0.20113961398601532  [ 3601/ 9040]\n",
            "loss: 0.08580756187438965  [ 3701/ 9040]\n",
            "loss: 0.4304843246936798  [ 3801/ 9040]\n",
            "loss: 0.003997075371444225  [ 3901/ 9040]\n",
            "loss: 0.1167570948600769  [ 4001/ 9040]\n",
            "loss: 0.039557844400405884  [ 4101/ 9040]\n",
            "loss: 0.11782986670732498  [ 4201/ 9040]\n",
            "loss: 0.0004592079494614154  [ 4301/ 9040]\n",
            "loss: 0.005634734407067299  [ 4401/ 9040]\n",
            "loss: 0.01642867550253868  [ 4501/ 9040]\n",
            "loss: 1.0013530300057027e-05  [ 4601/ 9040]\n",
            "loss: 0.12011068314313889  [ 4701/ 9040]\n",
            "loss: 0.1774219274520874  [ 4801/ 9040]\n",
            "loss: 0.14058640599250793  [ 4901/ 9040]\n",
            "loss: 0.00016044282529037446  [ 5001/ 9040]\n",
            "loss: 0.09792591631412506  [ 5101/ 9040]\n",
            "loss: 0.8241875171661377  [ 5201/ 9040]\n",
            "loss: 1.0728830375228426e-06  [ 5301/ 9040]\n",
            "loss: 3.4450891689630225e-05  [ 5401/ 9040]\n",
            "loss: 0.03840111941099167  [ 5501/ 9040]\n",
            "loss: 1.0490362910786644e-05  [ 5601/ 9040]\n",
            "loss: 0.05581316724419594  [ 5701/ 9040]\n",
            "loss: 0.03684593737125397  [ 5801/ 9040]\n",
            "loss: 0.0031154451426118612  [ 5901/ 9040]\n",
            "loss: 0.008526468649506569  [ 6001/ 9040]\n",
            "loss: 0.041885919868946075  [ 6101/ 9040]\n",
            "loss: 0.020332014188170433  [ 6201/ 9040]\n",
            "loss: 0.002032121177762747  [ 6301/ 9040]\n",
            "loss: 0.9625294804573059  [ 6401/ 9040]\n",
            "loss: 0.04140554741024971  [ 6501/ 9040]\n",
            "loss: 0.2634037435054779  [ 6601/ 9040]\n",
            "loss: 0.00013350549852475524  [ 6701/ 9040]\n",
            "loss: 0.4053107500076294  [ 6801/ 9040]\n",
            "loss: 0.04974719509482384  [ 6901/ 9040]\n",
            "loss: 0.0008690156391821802  [ 7001/ 9040]\n",
            "loss: 0.0972990170121193  [ 7101/ 9040]\n",
            "loss: 0.393364280462265  [ 7201/ 9040]\n",
            "loss: 0.0037201500963419676  [ 7301/ 9040]\n",
            "loss: 0.07001470029354095  [ 7401/ 9040]\n",
            "loss: 0.018310679122805595  [ 7501/ 9040]\n",
            "loss: 0.5204628109931946  [ 7601/ 9040]\n",
            "loss: 0.06753157079219818  [ 7701/ 9040]\n",
            "loss: 0.028685851022601128  [ 7801/ 9040]\n",
            "loss: 1.7519383430480957  [ 7901/ 9040]\n",
            "loss: 0.017434319481253624  [ 8001/ 9040]\n",
            "loss: 0.13667970895767212  [ 8101/ 9040]\n",
            "loss: 0.0005169962532818317  [ 8201/ 9040]\n",
            "loss: 0.005874985363334417  [ 8301/ 9040]\n",
            "loss: 0.09370891749858856  [ 8401/ 9040]\n",
            "loss: 0.1763325035572052  [ 8501/ 9040]\n",
            "loss: 0.034625276923179626  [ 8601/ 9040]\n",
            "loss: 0.6593289375305176  [ 8701/ 9040]\n",
            "loss: 0.009991630911827087  [ 8801/ 9040]\n",
            "loss: 1.481757640838623  [ 8901/ 9040]\n",
            "loss: 0.05027005821466446  [ 9001/ 9040]\n",
            "Train Accuracy: 91.7\n",
            "\n",
            "Test Error: \n",
            " Accuracy: 88.4%, Avg loss: 0.289433 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "\n",
            "loss: 0.007820818573236465  [    1/ 9040]\n",
            "loss: 0.002654007636010647  [  101/ 9040]\n",
            "loss: 0.02719332091510296  [  201/ 9040]\n",
            "loss: 0.35526373982429504  [  301/ 9040]\n",
            "loss: 0.0018023689044639468  [  401/ 9040]\n",
            "loss: 0.06448369473218918  [  501/ 9040]\n",
            "loss: 1.1920922133867862e-06  [  601/ 9040]\n",
            "loss: 0.01187988556921482  [  701/ 9040]\n",
            "loss: 0.23064404726028442  [  801/ 9040]\n",
            "loss: 0.1844712197780609  [  901/ 9040]\n",
            "loss: 0.11627402901649475  [ 1001/ 9040]\n",
            "loss: 7.271502545336261e-05  [ 1101/ 9040]\n",
            "loss: 0.06626743823289871  [ 1201/ 9040]\n",
            "loss: 0.8629825115203857  [ 1301/ 9040]\n",
            "loss: 0.06560932099819183  [ 1401/ 9040]\n",
            "loss: 0.7558196187019348  [ 1501/ 9040]\n",
            "loss: 0.025176752358675003  [ 1601/ 9040]\n",
            "loss: 0.00632510706782341  [ 1701/ 9040]\n",
            "loss: 0.0016470688860863447  [ 1801/ 9040]\n",
            "loss: 0.0009072478278540075  [ 1901/ 9040]\n",
            "loss: 0.08218719810247421  [ 2001/ 9040]\n",
            "loss: 0.024215172976255417  [ 2101/ 9040]\n",
            "loss: 0.001692292862571776  [ 2201/ 9040]\n",
            "loss: 0.08359071612358093  [ 2301/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 2401/ 9040]\n",
            "loss: 0.11348003149032593  [ 2501/ 9040]\n",
            "loss: 0.0005080600967630744  [ 2601/ 9040]\n",
            "loss: 0.0  [ 2701/ 9040]\n",
            "loss: 0.0024689924903213978  [ 2801/ 9040]\n",
            "loss: 0.011232946068048477  [ 2901/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 3001/ 9040]\n",
            "loss: 0.19847960770130157  [ 3101/ 9040]\n",
            "loss: 0.0021971152164041996  [ 3201/ 9040]\n",
            "loss: 0.14192141592502594  [ 3301/ 9040]\n",
            "loss: 4.887569048150908e-06  [ 3401/ 9040]\n",
            "loss: 1.168244216387393e-05  [ 3501/ 9040]\n",
            "loss: 0.16265930235385895  [ 3601/ 9040]\n",
            "loss: 0.06467647105455399  [ 3701/ 9040]\n",
            "loss: 0.6743668913841248  [ 3801/ 9040]\n",
            "loss: 0.0021112312097102404  [ 3901/ 9040]\n",
            "loss: 0.02056245505809784  [ 4001/ 9040]\n",
            "loss: 0.01056777685880661  [ 4101/ 9040]\n",
            "loss: 0.06370830535888672  [ 4201/ 9040]\n",
            "loss: 0.00010883215873036534  [ 4301/ 9040]\n",
            "loss: 0.0015589953400194645  [ 4401/ 9040]\n",
            "loss: 0.01111777313053608  [ 4501/ 9040]\n",
            "loss: 1.7881377516459906e-06  [ 4601/ 9040]\n",
            "loss: 0.07075401395559311  [ 4701/ 9040]\n",
            "loss: 0.20592336356639862  [ 4801/ 9040]\n",
            "loss: 0.07441449165344238  [ 4901/ 9040]\n",
            "loss: 2.288792165927589e-05  [ 5001/ 9040]\n",
            "loss: 0.05600300058722496  [ 5101/ 9040]\n",
            "loss: 0.4438796639442444  [ 5201/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 5301/ 9040]\n",
            "loss: 8.34461570775602e-06  [ 5401/ 9040]\n",
            "loss: 0.009592393413186073  [ 5501/ 9040]\n",
            "loss: 4.410734163684538e-06  [ 5601/ 9040]\n",
            "loss: 0.01371084526181221  [ 5701/ 9040]\n",
            "loss: 0.026300447061657906  [ 5801/ 9040]\n",
            "loss: 0.004076505079865456  [ 5901/ 9040]\n",
            "loss: 0.004496344830840826  [ 6001/ 9040]\n",
            "loss: 0.22252194583415985  [ 6101/ 9040]\n",
            "loss: 0.010942570865154266  [ 6201/ 9040]\n",
            "loss: 0.00040904260822571814  [ 6301/ 9040]\n",
            "loss: 0.4303232729434967  [ 6401/ 9040]\n",
            "loss: 0.03648969531059265  [ 6501/ 9040]\n",
            "loss: 0.10182183980941772  [ 6601/ 9040]\n",
            "loss: 2.002696055569686e-05  [ 6701/ 9040]\n",
            "loss: 0.6949386596679688  [ 6801/ 9040]\n",
            "loss: 0.040715292096138  [ 6901/ 9040]\n",
            "loss: 0.00025185750564560294  [ 7001/ 9040]\n",
            "loss: 0.09292034059762955  [ 7101/ 9040]\n",
            "loss: 0.24659356474876404  [ 7201/ 9040]\n",
            "loss: 0.0013404440833255649  [ 7301/ 9040]\n",
            "loss: 0.03835534676909447  [ 7401/ 9040]\n",
            "loss: 0.03226601704955101  [ 7501/ 9040]\n",
            "loss: 0.2588505446910858  [ 7601/ 9040]\n",
            "loss: 0.019146859645843506  [ 7701/ 9040]\n",
            "loss: 0.012760416604578495  [ 7801/ 9040]\n",
            "loss: 0.611588180065155  [ 7901/ 9040]\n",
            "loss: 0.01049310714006424  [ 8001/ 9040]\n",
            "loss: 0.06627468764781952  [ 8101/ 9040]\n",
            "loss: 0.00018165845540352166  [ 8201/ 9040]\n",
            "loss: 0.00462521705776453  [ 8301/ 9040]\n",
            "loss: 0.06772409379482269  [ 8401/ 9040]\n",
            "loss: 0.045923516154289246  [ 8501/ 9040]\n",
            "loss: 0.022794023156166077  [ 8601/ 9040]\n",
            "loss: 0.5089988708496094  [ 8701/ 9040]\n",
            "loss: 0.009867933578789234  [ 8801/ 9040]\n",
            "loss: 1.6501659154891968  [ 8901/ 9040]\n",
            "loss: 0.012950245290994644  [ 9001/ 9040]\n",
            "Train Accuracy: 93.8\n",
            "\n",
            "Test Error: \n",
            " Accuracy: 88.9%, Avg loss: 0.286316 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "\n",
            "loss: 0.001589822000823915  [    1/ 9040]\n",
            "loss: 0.0007353700930252671  [  101/ 9040]\n",
            "loss: 0.016886616125702858  [  201/ 9040]\n",
            "loss: 0.35680603981018066  [  301/ 9040]\n",
            "loss: 0.000256982195423916  [  401/ 9040]\n",
            "loss: 0.08361713588237762  [  501/ 9040]\n",
            "loss: 0.0  [  601/ 9040]\n",
            "loss: 0.007393853273242712  [  701/ 9040]\n",
            "loss: 0.26795634627342224  [  801/ 9040]\n",
            "loss: 0.19158935546875  [  901/ 9040]\n",
            "loss: 0.09447614848613739  [ 1001/ 9040]\n",
            "loss: 2.3841574147809297e-05  [ 1101/ 9040]\n",
            "loss: 0.03895276412367821  [ 1201/ 9040]\n",
            "loss: 0.7680853605270386  [ 1301/ 9040]\n",
            "loss: 0.018641162663698196  [ 1401/ 9040]\n",
            "loss: 0.8924317359924316  [ 1501/ 9040]\n",
            "loss: 0.018898196518421173  [ 1601/ 9040]\n",
            "loss: 0.0022077015601098537  [ 1701/ 9040]\n",
            "loss: 0.00036113892565481365  [ 1801/ 9040]\n",
            "loss: 0.0002574589161667973  [ 1901/ 9040]\n",
            "loss: 0.07917658239603043  [ 2001/ 9040]\n",
            "loss: 0.006011026445776224  [ 2101/ 9040]\n",
            "loss: 0.0008871195605024695  [ 2201/ 9040]\n",
            "loss: 0.0715089738368988  [ 2301/ 9040]\n",
            "loss: 0.0  [ 2401/ 9040]\n",
            "loss: 0.07687133550643921  [ 2501/ 9040]\n",
            "loss: 0.0001618731184862554  [ 2601/ 9040]\n",
            "loss: 0.0  [ 2701/ 9040]\n",
            "loss: 0.0008588915807195008  [ 2801/ 9040]\n",
            "loss: 0.008357786573469639  [ 2901/ 9040]\n",
            "loss: 0.0  [ 3001/ 9040]\n",
            "loss: 0.065525583922863  [ 3101/ 9040]\n",
            "loss: 0.0006158839096315205  [ 3201/ 9040]\n",
            "loss: 0.04172574728727341  [ 3301/ 9040]\n",
            "loss: 4.768370445162873e-07  [ 3401/ 9040]\n",
            "loss: 3.576272320060525e-06  [ 3501/ 9040]\n",
            "loss: 0.12301432341337204  [ 3601/ 9040]\n",
            "loss: 0.04392420873045921  [ 3701/ 9040]\n",
            "loss: 1.275193691253662  [ 3801/ 9040]\n",
            "loss: 0.0005435658385977149  [ 3901/ 9040]\n",
            "loss: 0.0034563345834612846  [ 4001/ 9040]\n",
            "loss: 0.0023934785276651382  [ 4101/ 9040]\n",
            "loss: 0.03677883744239807  [ 4201/ 9040]\n",
            "loss: 1.6569954823353328e-05  [ 4301/ 9040]\n",
            "loss: 0.0007190502947196364  [ 4401/ 9040]\n",
            "loss: 0.008879224769771099  [ 4501/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 4601/ 9040]\n",
            "loss: 0.05184922739863396  [ 4701/ 9040]\n",
            "loss: 0.32703351974487305  [ 4801/ 9040]\n",
            "loss: 0.05059955269098282  [ 4901/ 9040]\n",
            "loss: 6.9141146923357155e-06  [ 5001/ 9040]\n",
            "loss: 0.03242956101894379  [ 5101/ 9040]\n",
            "loss: 0.21479736268520355  [ 5201/ 9040]\n",
            "loss: 0.0  [ 5301/ 9040]\n",
            "loss: 2.264974000354414e-06  [ 5401/ 9040]\n",
            "loss: 0.0026812339201569557  [ 5501/ 9040]\n",
            "loss: 7.152555099310121e-07  [ 5601/ 9040]\n",
            "loss: 0.0033404999412596226  [ 5701/ 9040]\n",
            "loss: 0.011591465212404728  [ 5801/ 9040]\n",
            "loss: 0.0034722534473985434  [ 5901/ 9040]\n",
            "loss: 0.001423299196176231  [ 6001/ 9040]\n",
            "loss: 0.03863833099603653  [ 6101/ 9040]\n",
            "loss: 0.007984624244272709  [ 6201/ 9040]\n",
            "loss: 0.00014375607133843005  [ 6301/ 9040]\n",
            "loss: 0.2823565602302551  [ 6401/ 9040]\n",
            "loss: 0.02382553368806839  [ 6501/ 9040]\n",
            "loss: 0.026621801778674126  [ 6601/ 9040]\n",
            "loss: 2.145764938177308e-06  [ 6701/ 9040]\n",
            "loss: 1.1382795572280884  [ 6801/ 9040]\n",
            "loss: 0.02402549237012863  [ 6901/ 9040]\n",
            "loss: 5.23315102327615e-05  [ 7001/ 9040]\n",
            "loss: 0.06100669130682945  [ 7101/ 9040]\n",
            "loss: 0.06006639823317528  [ 7201/ 9040]\n",
            "loss: 0.0002181292074965313  [ 7301/ 9040]\n",
            "loss: 0.020265547558665276  [ 7401/ 9040]\n",
            "loss: 0.03748743236064911  [ 7501/ 9040]\n",
            "loss: 0.14140720665454865  [ 7601/ 9040]\n",
            "loss: 0.004400332923978567  [ 7701/ 9040]\n",
            "loss: 0.005849149543792009  [ 7801/ 9040]\n",
            "loss: 0.14602965116500854  [ 7901/ 9040]\n",
            "loss: 0.007030983921140432  [ 8001/ 9040]\n",
            "loss: 0.03453637287020683  [ 8101/ 9040]\n",
            "loss: 4.9828242481453344e-05  [ 8201/ 9040]\n",
            "loss: 0.0012988949893042445  [ 8301/ 9040]\n",
            "loss: 0.028965560719370842  [ 8401/ 9040]\n",
            "loss: 0.029121771454811096  [ 8501/ 9040]\n",
            "loss: 0.01780596375465393  [ 8601/ 9040]\n",
            "loss: 0.36186087131500244  [ 8701/ 9040]\n",
            "loss: 0.009001508355140686  [ 8801/ 9040]\n",
            "loss: 1.900865912437439  [ 8901/ 9040]\n",
            "loss: 0.002790250116959214  [ 9001/ 9040]\n",
            "Train Accuracy: 95.4\n",
            "\n",
            "Test Error: \n",
            " Accuracy: 89.8%, Avg loss: 0.283391 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "\n",
            "loss: 0.0004135706985834986  [    1/ 9040]\n",
            "loss: 0.00016866691294126213  [  101/ 9040]\n",
            "loss: 0.007846958935260773  [  201/ 9040]\n",
            "loss: 0.3125215768814087  [  301/ 9040]\n",
            "loss: 3.2782016205601394e-05  [  401/ 9040]\n",
            "loss: 0.1354798972606659  [  501/ 9040]\n",
            "loss: 0.0  [  601/ 9040]\n",
            "loss: 0.004171124193817377  [  701/ 9040]\n",
            "loss: 0.44809332489967346  [  801/ 9040]\n",
            "loss: 0.13993719220161438  [  901/ 9040]\n",
            "loss: 0.06101510301232338  [ 1001/ 9040]\n",
            "loss: 7.629365427419543e-06  [ 1101/ 9040]\n",
            "loss: 0.010440375655889511  [ 1201/ 9040]\n",
            "loss: 0.6762902736663818  [ 1301/ 9040]\n",
            "loss: 0.008944444358348846  [ 1401/ 9040]\n",
            "loss: 0.6035061478614807  [ 1501/ 9040]\n",
            "loss: 0.022271398454904556  [ 1601/ 9040]\n",
            "loss: 0.00052426423644647  [ 1701/ 9040]\n",
            "loss: 0.0001380348257953301  [ 1801/ 9040]\n",
            "loss: 8.749579137656838e-05  [ 1901/ 9040]\n",
            "loss: 0.04331514611840248  [ 2001/ 9040]\n",
            "loss: 0.00261310744099319  [ 2101/ 9040]\n",
            "loss: 0.0010332489619031549  [ 2201/ 9040]\n",
            "loss: 0.07411421835422516  [ 2301/ 9040]\n",
            "loss: 0.0  [ 2401/ 9040]\n",
            "loss: 0.07359393686056137  [ 2501/ 9040]\n",
            "loss: 3.766942609217949e-05  [ 2601/ 9040]\n",
            "loss: 0.0  [ 2701/ 9040]\n",
            "loss: 0.00016962042718660086  [ 2801/ 9040]\n",
            "loss: 0.0036219253670424223  [ 2901/ 9040]\n",
            "loss: 0.0  [ 3001/ 9040]\n",
            "loss: 0.010842694900929928  [ 3101/ 9040]\n",
            "loss: 0.00015698630886618048  [ 3201/ 9040]\n",
            "loss: 0.004960017278790474  [ 3301/ 9040]\n",
            "loss: 0.0  [ 3401/ 9040]\n",
            "loss: 9.298280929215252e-06  [ 3501/ 9040]\n",
            "loss: 0.016954127699136734  [ 3601/ 9040]\n",
            "loss: 0.02529403753578663  [ 3701/ 9040]\n",
            "loss: 1.9320440292358398  [ 3801/ 9040]\n",
            "loss: 3.886147169396281e-05  [ 3901/ 9040]\n",
            "loss: 0.00029559535323642194  [ 4001/ 9040]\n",
            "loss: 0.0003543464408721775  [ 4101/ 9040]\n",
            "loss: 0.014813076704740524  [ 4201/ 9040]\n",
            "loss: 3.099436753473128e-06  [ 4301/ 9040]\n",
            "loss: 0.00024434918304905295  [ 4401/ 9040]\n",
            "loss: 0.0068405019119381905  [ 4501/ 9040]\n",
            "loss: 0.0  [ 4601/ 9040]\n",
            "loss: 0.026090141385793686  [ 4701/ 9040]\n",
            "loss: 0.059979841113090515  [ 4801/ 9040]\n",
            "loss: 0.008648558519780636  [ 4901/ 9040]\n",
            "loss: 1.1920922133867862e-06  [ 5001/ 9040]\n",
            "loss: 0.01714925654232502  [ 5101/ 9040]\n",
            "loss: 0.1310548037290573  [ 5201/ 9040]\n",
            "loss: 0.0  [ 5301/ 9040]\n",
            "loss: 9.536738616588991e-07  [ 5401/ 9040]\n",
            "loss: 0.00015746307326480746  [ 5501/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 5601/ 9040]\n",
            "loss: 0.0006752118351869285  [ 5701/ 9040]\n",
            "loss: 0.006158660165965557  [ 5801/ 9040]\n",
            "loss: 0.0010548033751547337  [ 5901/ 9040]\n",
            "loss: 0.0022921499330550432  [ 6001/ 9040]\n",
            "loss: 0.00247077620588243  [ 6101/ 9040]\n",
            "loss: 0.0040996563620865345  [ 6201/ 9040]\n",
            "loss: 4.7801782784517854e-05  [ 6301/ 9040]\n",
            "loss: 0.057416144758462906  [ 6401/ 9040]\n",
            "loss: 0.010007445700466633  [ 6501/ 9040]\n",
            "loss: 0.009359884075820446  [ 6601/ 9040]\n",
            "loss: 2.3841855067985307e-07  [ 6701/ 9040]\n",
            "loss: 0.9248132109642029  [ 6801/ 9040]\n",
            "loss: 0.017069334164261818  [ 6901/ 9040]\n",
            "loss: 1.0609570381348021e-05  [ 7001/ 9040]\n",
            "loss: 0.047343235462903976  [ 7101/ 9040]\n",
            "loss: 0.017674563452601433  [ 7201/ 9040]\n",
            "loss: 3.7788631743751466e-05  [ 7301/ 9040]\n",
            "loss: 0.012280918657779694  [ 7401/ 9040]\n",
            "loss: 0.05616180598735809  [ 7501/ 9040]\n",
            "loss: 0.07302495837211609  [ 7601/ 9040]\n",
            "loss: 0.0003911683743353933  [ 7701/ 9040]\n",
            "loss: 0.0030418813694268465  [ 7801/ 9040]\n",
            "loss: 0.0440770760178566  [ 7901/ 9040]\n",
            "loss: 0.003602920565754175  [ 8001/ 9040]\n",
            "loss: 0.013198627158999443  [ 8101/ 9040]\n",
            "loss: 2.2172682292875834e-05  [ 8201/ 9040]\n",
            "loss: 0.00026806574896909297  [ 8301/ 9040]\n",
            "loss: 0.016108721494674683  [ 8401/ 9040]\n",
            "loss: 0.016350338235497475  [ 8501/ 9040]\n",
            "loss: 0.015131215564906597  [ 8601/ 9040]\n",
            "loss: 0.3118268549442291  [ 8701/ 9040]\n",
            "loss: 0.035546645522117615  [ 8801/ 9040]\n",
            "loss: 1.6697492599487305  [ 8901/ 9040]\n",
            "loss: 0.001190430368296802  [ 9001/ 9040]\n",
            "Train Accuracy: 96.8\n",
            "\n",
            "Test Error: \n",
            " Accuracy: 90.1%, Avg loss: 0.279484 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "\n",
            "loss: 0.00035172473872080445  [    1/ 9040]\n",
            "loss: 1.9192511899746023e-05  [  101/ 9040]\n",
            "loss: 0.0054885647259652615  [  201/ 9040]\n",
            "loss: 0.0807805061340332  [  301/ 9040]\n",
            "loss: 5.006777428206988e-06  [  401/ 9040]\n",
            "loss: 0.1619105190038681  [  501/ 9040]\n",
            "loss: 0.0  [  601/ 9040]\n",
            "loss: 0.006807350553572178  [  701/ 9040]\n",
            "loss: 0.4895899295806885  [  801/ 9040]\n",
            "loss: 0.04547299072146416  [  901/ 9040]\n",
            "loss: 0.035315949469804764  [ 1001/ 9040]\n",
            "loss: 1.6689286894688848e-06  [ 1101/ 9040]\n",
            "loss: 0.0014366315444931388  [ 1201/ 9040]\n",
            "loss: 0.30533865094184875  [ 1301/ 9040]\n",
            "loss: 0.002549495082348585  [ 1401/ 9040]\n",
            "loss: 0.02722475863993168  [ 1501/ 9040]\n",
            "loss: 0.012656837701797485  [ 1601/ 9040]\n",
            "loss: 0.00031120702624320984  [ 1701/ 9040]\n",
            "loss: 0.0001292145170737058  [ 1801/ 9040]\n",
            "loss: 9.142934868577868e-05  [ 1901/ 9040]\n",
            "loss: 0.035951294004917145  [ 2001/ 9040]\n",
            "loss: 0.0017823775997385383  [ 2101/ 9040]\n",
            "loss: 0.00019143179815728217  [ 2201/ 9040]\n",
            "loss: 0.05851050466299057  [ 2301/ 9040]\n",
            "loss: 0.0  [ 2401/ 9040]\n",
            "loss: 0.03264499828219414  [ 2501/ 9040]\n",
            "loss: 2.3841855067985307e-07  [ 2601/ 9040]\n",
            "loss: 0.0  [ 2701/ 9040]\n",
            "loss: 5.0424259825376794e-05  [ 2801/ 9040]\n",
            "loss: 0.0018985120113939047  [ 2901/ 9040]\n",
            "loss: 0.0  [ 3001/ 9040]\n",
            "loss: 0.0005626287311315536  [ 3101/ 9040]\n",
            "loss: 5.280832192511298e-05  [ 3201/ 9040]\n",
            "loss: 0.0005146132898516953  [ 3301/ 9040]\n",
            "loss: 0.0  [ 3401/ 9040]\n",
            "loss: 7.510157047363464e-06  [ 3501/ 9040]\n",
            "loss: 0.005881740245968103  [ 3601/ 9040]\n",
            "loss: 0.01785620115697384  [ 3701/ 9040]\n",
            "loss: 2.3706016540527344  [ 3801/ 9040]\n",
            "loss: 1.1801649634435307e-05  [ 3901/ 9040]\n",
            "loss: 6.97350042173639e-05  [ 4001/ 9040]\n",
            "loss: 6.19869097135961e-05  [ 4101/ 9040]\n",
            "loss: 0.002689318498596549  [ 4201/ 9040]\n",
            "loss: 7.152555099310121e-07  [ 4301/ 9040]\n",
            "loss: 4.8636207793606445e-05  [ 4401/ 9040]\n",
            "loss: 0.004415642935782671  [ 4501/ 9040]\n",
            "loss: 0.0  [ 4601/ 9040]\n",
            "loss: 0.016981203109025955  [ 4701/ 9040]\n",
            "loss: 0.01729162223637104  [ 4801/ 9040]\n",
            "loss: 0.002167615806683898  [ 4901/ 9040]\n",
            "loss: 0.0  [ 5001/ 9040]\n",
            "loss: 0.009013795293867588  [ 5101/ 9040]\n",
            "loss: 0.08734037727117538  [ 5201/ 9040]\n",
            "loss: 0.0  [ 5301/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 5401/ 9040]\n",
            "loss: 3.6954811548639555e-06  [ 5501/ 9040]\n",
            "loss: 0.0  [ 5601/ 9040]\n",
            "loss: 3.373566141817719e-05  [ 5701/ 9040]\n",
            "loss: 0.00583480903878808  [ 5801/ 9040]\n",
            "loss: 0.0002244459028588608  [ 5901/ 9040]\n",
            "loss: 0.000896052282769233  [ 6001/ 9040]\n",
            "loss: 2.2291887944447808e-05  [ 6101/ 9040]\n",
            "loss: 0.0012219827622175217  [ 6201/ 9040]\n",
            "loss: 1.7404405298293568e-05  [ 6301/ 9040]\n",
            "loss: 0.3126128911972046  [ 6401/ 9040]\n",
            "loss: 0.019663522019982338  [ 6501/ 9040]\n",
            "loss: 0.004387514665722847  [ 6601/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 6701/ 9040]\n",
            "loss: 0.856328010559082  [ 6801/ 9040]\n",
            "loss: 0.020069625228643417  [ 6901/ 9040]\n",
            "loss: 2.7418097943154862e-06  [ 7001/ 9040]\n",
            "loss: 0.02441028505563736  [ 7101/ 9040]\n",
            "loss: 0.0026643513701856136  [ 7201/ 9040]\n",
            "loss: 7.033323527139146e-06  [ 7301/ 9040]\n",
            "loss: 0.009022064507007599  [ 7401/ 9040]\n",
            "loss: 7.497983460780233e-05  [ 7501/ 9040]\n",
            "loss: 0.028814423829317093  [ 7601/ 9040]\n",
            "loss: 0.0006542449118569493  [ 7701/ 9040]\n",
            "loss: 0.0010596857173368335  [ 7801/ 9040]\n",
            "loss: 0.01789378933608532  [ 7901/ 9040]\n",
            "loss: 0.00130425242241472  [ 8001/ 9040]\n",
            "loss: 0.030555931851267815  [ 8101/ 9040]\n",
            "loss: 1.966933996300213e-05  [ 8201/ 9040]\n",
            "loss: 3.611976353568025e-05  [ 8301/ 9040]\n",
            "loss: 0.008399398997426033  [ 8401/ 9040]\n",
            "loss: 0.007376576773822308  [ 8501/ 9040]\n",
            "loss: 0.0028008301742374897  [ 8601/ 9040]\n",
            "loss: 0.18256555497646332  [ 8701/ 9040]\n",
            "loss: 0.03432456776499748  [ 8801/ 9040]\n",
            "loss: 1.6396631002426147  [ 8901/ 9040]\n",
            "loss: 0.0009401192655786872  [ 9001/ 9040]\n",
            "Train Accuracy: 97.8\n",
            "\n",
            "Test Error: \n",
            " Accuracy: 90.2%, Avg loss: 0.323100 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "\n",
            "loss: 0.00016926287207752466  [    1/ 9040]\n",
            "loss: 1.156323378381785e-05  [  101/ 9040]\n",
            "loss: 0.00040892345714382827  [  201/ 9040]\n",
            "loss: 0.021691925823688507  [  301/ 9040]\n",
            "loss: 3.099436753473128e-06  [  401/ 9040]\n",
            "loss: 0.14278629422187805  [  501/ 9040]\n",
            "loss: 0.0  [  601/ 9040]\n",
            "loss: 0.0012641304638236761  [  701/ 9040]\n",
            "loss: 0.25087204575538635  [  801/ 9040]\n",
            "loss: 0.033018648624420166  [  901/ 9040]\n",
            "loss: 0.021335143595933914  [ 1001/ 9040]\n",
            "loss: 2.3841855067985307e-07  [ 1101/ 9040]\n",
            "loss: 0.002454246859997511  [ 1201/ 9040]\n",
            "loss: 0.2509983777999878  [ 1301/ 9040]\n",
            "loss: 0.002910427749156952  [ 1401/ 9040]\n",
            "loss: 0.36145293712615967  [ 1501/ 9040]\n",
            "loss: 0.009053489193320274  [ 1601/ 9040]\n",
            "loss: 0.00013040646445006132  [ 1701/ 9040]\n",
            "loss: 3.0278701160568744e-05  [ 1801/ 9040]\n",
            "loss: 1.2636104656849056e-05  [ 1901/ 9040]\n",
            "loss: 0.04700572416186333  [ 2001/ 9040]\n",
            "loss: 0.0002401778765488416  [ 2101/ 9040]\n",
            "loss: 0.010932784527540207  [ 2201/ 9040]\n",
            "loss: 0.037316787987947464  [ 2301/ 9040]\n",
            "loss: 0.0  [ 2401/ 9040]\n",
            "loss: 0.024935049936175346  [ 2501/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 2601/ 9040]\n",
            "loss: 0.0  [ 2701/ 9040]\n",
            "loss: 1.9073468138230965e-06  [ 2801/ 9040]\n",
            "loss: 0.0003271759778726846  [ 2901/ 9040]\n",
            "loss: 0.0  [ 3001/ 9040]\n",
            "loss: 0.0007571690948680043  [ 3101/ 9040]\n",
            "loss: 2.2411095415009186e-05  [ 3201/ 9040]\n",
            "loss: 0.00010787858627736568  [ 3301/ 9040]\n",
            "loss: 0.0  [ 3401/ 9040]\n",
            "loss: 6.794906312279636e-06  [ 3501/ 9040]\n",
            "loss: 0.006625826004892588  [ 3601/ 9040]\n",
            "loss: 0.0021609545219689608  [ 3701/ 9040]\n",
            "loss: 1.9096181392669678  [ 3801/ 9040]\n",
            "loss: 0.00018344627460464835  [ 3901/ 9040]\n",
            "loss: 1.549708758830093e-05  [ 4001/ 9040]\n",
            "loss: 0.00015841660206206143  [ 4101/ 9040]\n",
            "loss: 0.011130976490676403  [ 4201/ 9040]\n",
            "loss: 3.576278118089249e-07  [ 4301/ 9040]\n",
            "loss: 1.1086402082582936e-05  [ 4401/ 9040]\n",
            "loss: 0.0024246361572295427  [ 4501/ 9040]\n",
            "loss: 0.0  [ 4601/ 9040]\n",
            "loss: 0.023730427026748657  [ 4701/ 9040]\n",
            "loss: 0.030094841495156288  [ 4801/ 9040]\n",
            "loss: 0.22008080780506134  [ 4901/ 9040]\n",
            "loss: 0.0  [ 5001/ 9040]\n",
            "loss: 0.004389651119709015  [ 5101/ 9040]\n",
            "loss: 0.060728736221790314  [ 5201/ 9040]\n",
            "loss: 0.0  [ 5301/ 9040]\n",
            "loss: 3.576278118089249e-07  [ 5401/ 9040]\n",
            "loss: 1.0728830375228426e-06  [ 5501/ 9040]\n",
            "loss: 0.0  [ 5601/ 9040]\n",
            "loss: 3.933898824470816e-06  [ 5701/ 9040]\n",
            "loss: 0.004099181387573481  [ 5801/ 9040]\n",
            "loss: 0.0001486429391661659  [ 5901/ 9040]\n",
            "loss: 0.0005165196489542723  [ 6001/ 9040]\n",
            "loss: 1.847726889536716e-05  [ 6101/ 9040]\n",
            "loss: 0.0016584941186010838  [ 6201/ 9040]\n",
            "loss: 8.106198947643861e-06  [ 6301/ 9040]\n",
            "loss: 0.05658681318163872  [ 6401/ 9040]\n",
            "loss: 0.000834355247206986  [ 6501/ 9040]\n",
            "loss: 0.0006062338361516595  [ 6601/ 9040]\n",
            "loss: 0.0  [ 6701/ 9040]\n",
            "loss: 0.32469242811203003  [ 6801/ 9040]\n",
            "loss: 0.0009554826538078487  [ 6901/ 9040]\n",
            "loss: 3.933898824470816e-06  [ 7001/ 9040]\n",
            "loss: 0.0063461922109127045  [ 7101/ 9040]\n",
            "loss: 0.012170106172561646  [ 7201/ 9040]\n",
            "loss: 4.768370445162873e-07  [ 7301/ 9040]\n",
            "loss: 0.003341212635859847  [ 7401/ 9040]\n",
            "loss: 0.27285298705101013  [ 7501/ 9040]\n",
            "loss: 0.04566775634884834  [ 7601/ 9040]\n",
            "loss: 7.486063259420916e-05  [ 7701/ 9040]\n",
            "loss: 5.23315102327615e-05  [ 7801/ 9040]\n",
            "loss: 0.00830328743904829  [ 7901/ 9040]\n",
            "loss: 0.0003890234511345625  [ 8001/ 9040]\n",
            "loss: 0.005614938214421272  [ 8101/ 9040]\n",
            "loss: 4.0531076592742465e-06  [ 8201/ 9040]\n",
            "loss: 7.748573807475623e-06  [ 8301/ 9040]\n",
            "loss: 0.0063107735477387905  [ 8401/ 9040]\n",
            "loss: 0.0020786363165825605  [ 8501/ 9040]\n",
            "loss: 0.0005539313424378633  [ 8601/ 9040]\n",
            "loss: 0.08377841860055923  [ 8701/ 9040]\n",
            "loss: 0.03163779899477959  [ 8801/ 9040]\n",
            "loss: 1.2422535419464111  [ 8901/ 9040]\n",
            "loss: 0.00013314791431184858  [ 9001/ 9040]\n",
            "Train Accuracy: 98.2\n",
            "\n",
            "Test Error: \n",
            " Accuracy: 91.1%, Avg loss: 0.304388 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "\n",
            "loss: 5.2927523938706145e-05  [    1/ 9040]\n",
            "loss: 1.4185804502631072e-05  [  101/ 9040]\n",
            "loss: 0.03158651664853096  [  201/ 9040]\n",
            "loss: 0.01048131100833416  [  301/ 9040]\n",
            "loss: 1.5497195136049413e-06  [  401/ 9040]\n",
            "loss: 0.08185334503650665  [  501/ 9040]\n",
            "loss: 0.0  [  601/ 9040]\n",
            "loss: 0.0016469499096274376  [  701/ 9040]\n",
            "loss: 0.09924005717039108  [  801/ 9040]\n",
            "loss: 0.015570971183478832  [  901/ 9040]\n",
            "loss: 0.02558852545917034  [ 1001/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 1101/ 9040]\n",
            "loss: 0.0025963427033275366  [ 1201/ 9040]\n",
            "loss: 0.06666720658540726  [ 1301/ 9040]\n",
            "loss: 0.0010085977846756577  [ 1401/ 9040]\n",
            "loss: 7.891343557275832e-05  [ 1501/ 9040]\n",
            "loss: 0.005530651658773422  [ 1601/ 9040]\n",
            "loss: 0.0001284993631998077  [ 1701/ 9040]\n",
            "loss: 1.7762025890988298e-05  [ 1801/ 9040]\n",
            "loss: 4.768360213347478e-06  [ 1901/ 9040]\n",
            "loss: 0.0016876515001058578  [ 2001/ 9040]\n",
            "loss: 0.00013481661153491586  [ 2101/ 9040]\n",
            "loss: 0.0  [ 2201/ 9040]\n",
            "loss: 0.09637060016393661  [ 2301/ 9040]\n",
            "loss: 0.0  [ 2401/ 9040]\n",
            "loss: 0.006983751431107521  [ 2501/ 9040]\n",
            "loss: 0.0  [ 2601/ 9040]\n",
            "loss: 0.0  [ 2701/ 9040]\n",
            "loss: 0.0002233732520835474  [ 2801/ 9040]\n",
            "loss: 6.770858453819528e-05  [ 2901/ 9040]\n",
            "loss: 0.0  [ 3001/ 9040]\n",
            "loss: 0.00030298411729745567  [ 3101/ 9040]\n",
            "loss: 7.152555099310121e-07  [ 3201/ 9040]\n",
            "loss: 8.725739462533966e-05  [ 3301/ 9040]\n",
            "loss: 0.0  [ 3401/ 9040]\n",
            "loss: 8.344646857949556e-07  [ 3501/ 9040]\n",
            "loss: 0.001874001114629209  [ 3601/ 9040]\n",
            "loss: 0.001934444298967719  [ 3701/ 9040]\n",
            "loss: 0.4965977668762207  [ 3801/ 9040]\n",
            "loss: 0.0026060924865305424  [ 3901/ 9040]\n",
            "loss: 4.291525328881107e-06  [ 4001/ 9040]\n",
            "loss: 4.076874756719917e-05  [ 4101/ 9040]\n",
            "loss: 0.003170941025018692  [ 4201/ 9040]\n",
            "loss: 0.0  [ 4301/ 9040]\n",
            "loss: 7.152555099310121e-07  [ 4401/ 9040]\n",
            "loss: 0.007721103262156248  [ 4501/ 9040]\n",
            "loss: 0.0  [ 4601/ 9040]\n",
            "loss: 0.03589782118797302  [ 4701/ 9040]\n",
            "loss: 0.3522248864173889  [ 4801/ 9040]\n",
            "loss: 0.0023319926112890244  [ 4901/ 9040]\n",
            "loss: 2.264974000354414e-06  [ 5001/ 9040]\n",
            "loss: 0.0015524489572271705  [ 5101/ 9040]\n",
            "loss: 0.02768184058368206  [ 5201/ 9040]\n",
            "loss: 0.0  [ 5301/ 9040]\n",
            "loss: 0.0  [ 5401/ 9040]\n",
            "loss: 5.960462772236497e-07  [ 5501/ 9040]\n",
            "loss: 0.0  [ 5601/ 9040]\n",
            "loss: 5.483612312673358e-06  [ 5701/ 9040]\n",
            "loss: 0.0016788449138402939  [ 5801/ 9040]\n",
            "loss: 0.00010716341057559475  [ 5901/ 9040]\n",
            "loss: 9.07141511561349e-05  [ 6001/ 9040]\n",
            "loss: 3.135155202471651e-05  [ 6101/ 9040]\n",
            "loss: 2.455681169521995e-05  [ 6201/ 9040]\n",
            "loss: 1.4305012882687151e-05  [ 6301/ 9040]\n",
            "loss: 0.0034430292434990406  [ 6401/ 9040]\n",
            "loss: 0.0006317288498394191  [ 6501/ 9040]\n",
            "loss: 0.00035982808913104236  [ 6601/ 9040]\n",
            "loss: 4.768370445162873e-07  [ 6701/ 9040]\n",
            "loss: 1.4138576984405518  [ 6801/ 9040]\n",
            "loss: 0.0020291469991207123  [ 6901/ 9040]\n",
            "loss: 3.576278118089249e-07  [ 7001/ 9040]\n",
            "loss: 0.00762315234169364  [ 7101/ 9040]\n",
            "loss: 0.023202700540423393  [ 7201/ 9040]\n",
            "loss: 1.1920922133867862e-06  [ 7301/ 9040]\n",
            "loss: 0.0024580522440373898  [ 7401/ 9040]\n",
            "loss: 0.00031931069679558277  [ 7501/ 9040]\n",
            "loss: 0.01696338690817356  [ 7601/ 9040]\n",
            "loss: 0.0005480932886712253  [ 7701/ 9040]\n",
            "loss: 0.000916537712328136  [ 7801/ 9040]\n",
            "loss: 0.004003368318080902  [ 7901/ 9040]\n",
            "loss: 8.737658936297521e-05  [ 8001/ 9040]\n",
            "loss: 0.032391246408224106  [ 8101/ 9040]\n",
            "loss: 1.2993727978027891e-05  [ 8201/ 9040]\n",
            "loss: 4.768370445162873e-07  [ 8301/ 9040]\n",
            "loss: 0.004164832178503275  [ 8401/ 9040]\n",
            "loss: 0.005459399428218603  [ 8501/ 9040]\n",
            "loss: 0.0008101756684482098  [ 8601/ 9040]\n",
            "loss: 0.05196738615632057  [ 8701/ 9040]\n",
            "loss: 0.011485997587442398  [ 8801/ 9040]\n",
            "loss: 1.023979902267456  [ 8901/ 9040]\n",
            "loss: 0.0007453762227669358  [ 9001/ 9040]\n",
            "Train Accuracy: 98.5\n",
            "\n",
            "Test Error: \n",
            " Accuracy: 91.0%, Avg loss: 0.339566 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "\n",
            "loss: 7.1403817855753e-05  [    1/ 9040]\n",
            "loss: 1.883488948806189e-05  [  101/ 9040]\n",
            "loss: 0.0011189873330295086  [  201/ 9040]\n",
            "loss: 0.013929883949458599  [  301/ 9040]\n",
            "loss: 0.0  [  401/ 9040]\n",
            "loss: 0.0393514558672905  [  501/ 9040]\n",
            "loss: 0.0  [  601/ 9040]\n",
            "loss: 0.0009334497735835612  [  701/ 9040]\n",
            "loss: 0.089399054646492  [  801/ 9040]\n",
            "loss: 0.0284518301486969  [  901/ 9040]\n",
            "loss: 0.03586573153734207  [ 1001/ 9040]\n",
            "loss: 2.3841855067985307e-07  [ 1101/ 9040]\n",
            "loss: 0.0008931938209570944  [ 1201/ 9040]\n",
            "loss: 0.1485193520784378  [ 1301/ 9040]\n",
            "loss: 0.001081834896467626  [ 1401/ 9040]\n",
            "loss: 2.622600959512056e-06  [ 1501/ 9040]\n",
            "loss: 0.011188386939466  [ 1601/ 9040]\n",
            "loss: 2.50339189733495e-06  [ 1701/ 9040]\n",
            "loss: 1.1205610462639015e-05  [ 1801/ 9040]\n",
            "loss: 7.152531907195225e-06  [ 1901/ 9040]\n",
            "loss: 0.0004418112221173942  [ 2001/ 9040]\n",
            "loss: 4.6491513785440475e-06  [ 2101/ 9040]\n",
            "loss: 0.0  [ 2201/ 9040]\n",
            "loss: 0.027963917702436447  [ 2301/ 9040]\n",
            "loss: 0.0  [ 2401/ 9040]\n",
            "loss: 0.0019144555553793907  [ 2501/ 9040]\n",
            "loss: 2.3841830625315197e-06  [ 2601/ 9040]\n",
            "loss: 0.0  [ 2701/ 9040]\n",
            "loss: 3.862306402879767e-05  [ 2801/ 9040]\n",
            "loss: 0.0012931802775710821  [ 2901/ 9040]\n",
            "loss: 0.0  [ 3001/ 9040]\n",
            "loss: 0.0051826415583491325  [ 3101/ 9040]\n",
            "loss: 3.576278118089249e-07  [ 3201/ 9040]\n",
            "loss: 1.7165990357170813e-05  [ 3301/ 9040]\n",
            "loss: 0.0  [ 3401/ 9040]\n",
            "loss: 0.0  [ 3501/ 9040]\n",
            "loss: 0.0006194579764269292  [ 3601/ 9040]\n",
            "loss: 0.01619892381131649  [ 3701/ 9040]\n",
            "loss: 0.01874658092856407  [ 3801/ 9040]\n",
            "loss: 4.768370445162873e-07  [ 3901/ 9040]\n",
            "loss: 2.634490556374658e-05  [ 4001/ 9040]\n",
            "loss: 0.00022790218645241112  [ 4101/ 9040]\n",
            "loss: 1.0609570381348021e-05  [ 4201/ 9040]\n",
            "loss: 0.0  [ 4301/ 9040]\n",
            "loss: 0.0  [ 4401/ 9040]\n",
            "loss: 0.0011142243165522814  [ 4501/ 9040]\n",
            "loss: 0.0  [ 4601/ 9040]\n",
            "loss: 0.008456375449895859  [ 4701/ 9040]\n",
            "loss: 2.0508406162261963  [ 4801/ 9040]\n",
            "loss: 0.0004698126285802573  [ 4901/ 9040]\n",
            "loss: 1.2040065485052764e-05  [ 5001/ 9040]\n",
            "loss: 0.0009390473715029657  [ 5101/ 9040]\n",
            "loss: 0.26441463828086853  [ 5201/ 9040]\n",
            "loss: 0.0  [ 5301/ 9040]\n",
            "loss: 0.0  [ 5401/ 9040]\n",
            "loss: 2.3841855067985307e-07  [ 5501/ 9040]\n",
            "loss: 0.0  [ 5601/ 9040]\n",
            "loss: 2.0265558760002023e-06  [ 5701/ 9040]\n",
            "loss: 0.0040769800543785095  [ 5801/ 9040]\n",
            "loss: 2.5033637939486653e-05  [ 5901/ 9040]\n",
            "loss: 0.00015925093612167984  [ 6001/ 9040]\n",
            "loss: 0.00038938093348406255  [ 6101/ 9040]\n",
            "loss: 3.4570634852570947e-06  [ 6201/ 9040]\n",
            "loss: 7.152555099310121e-07  [ 6301/ 9040]\n",
            "loss: 0.0004690977220889181  [ 6401/ 9040]\n",
            "loss: 0.0010493254521861672  [ 6501/ 9040]\n",
            "loss: 0.00012015574611723423  [ 6601/ 9040]\n",
            "loss: 0.0  [ 6701/ 9040]\n",
            "loss: 0.27614858746528625  [ 6801/ 9040]\n",
            "loss: 0.0002037079248111695  [ 6901/ 9040]\n",
            "loss: 1.0728830375228426e-06  [ 7001/ 9040]\n",
            "loss: 0.004079829435795546  [ 7101/ 9040]\n",
            "loss: 0.002495510270819068  [ 7201/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 7301/ 9040]\n",
            "loss: 0.0012032896047458053  [ 7401/ 9040]\n",
            "loss: 0.006876849103718996  [ 7501/ 9040]\n",
            "loss: 0.0066244048066437244  [ 7601/ 9040]\n",
            "loss: 0.00045563330058939755  [ 7701/ 9040]\n",
            "loss: 2.098061486321967e-05  [ 7801/ 9040]\n",
            "loss: 0.011012372560799122  [ 7901/ 9040]\n",
            "loss: 7.510157047363464e-06  [ 8001/ 9040]\n",
            "loss: 0.000259365770034492  [ 8101/ 9040]\n",
            "loss: 0.0  [ 8201/ 9040]\n",
            "loss: 4.768370445162873e-07  [ 8301/ 9040]\n",
            "loss: 0.002244930947199464  [ 8401/ 9040]\n",
            "loss: 0.09314214438199997  [ 8501/ 9040]\n",
            "loss: 0.000654602306894958  [ 8601/ 9040]\n",
            "loss: 0.013120272196829319  [ 8701/ 9040]\n",
            "loss: 0.5003350973129272  [ 8801/ 9040]\n",
            "loss: 0.6369727253913879  [ 8901/ 9040]\n",
            "loss: 1.4305104514278355e-06  [ 9001/ 9040]\n",
            "Train Accuracy: 98.6\n",
            "\n",
            "Test Error: \n",
            " Accuracy: 90.8%, Avg loss: 0.381817 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "\n",
            "loss: 3.0636318115284666e-05  [    1/ 9040]\n",
            "loss: 6.41325386823155e-05  [  101/ 9040]\n",
            "loss: 0.018775010481476784  [  201/ 9040]\n",
            "loss: 0.1779354214668274  [  301/ 9040]\n",
            "loss: 1.5616295058862306e-05  [  401/ 9040]\n",
            "loss: 0.015387274324893951  [  501/ 9040]\n",
            "loss: 0.0  [  601/ 9040]\n",
            "loss: 0.0021054022945463657  [  701/ 9040]\n",
            "loss: 0.012079067528247833  [  801/ 9040]\n",
            "loss: 0.022321412339806557  [  901/ 9040]\n",
            "loss: 0.0032420000061392784  [ 1001/ 9040]\n",
            "loss: 1.1920922133867862e-06  [ 1101/ 9040]\n",
            "loss: 0.0016736084362491965  [ 1201/ 9040]\n",
            "loss: 0.018322734162211418  [ 1301/ 9040]\n",
            "loss: 0.00037508129025809467  [ 1401/ 9040]\n",
            "loss: 7.152555099310121e-07  [ 1501/ 9040]\n",
            "loss: 0.0067454250529408455  [ 1601/ 9040]\n",
            "loss: 1.311301275563892e-06  [ 1701/ 9040]\n",
            "loss: 2.169585604860913e-05  [ 1801/ 9040]\n",
            "loss: 3.814624506048858e-05  [ 1901/ 9040]\n",
            "loss: 0.16915948688983917  [ 2001/ 9040]\n",
            "loss: 5.602820692729438e-06  [ 2101/ 9040]\n",
            "loss: 0.0  [ 2201/ 9040]\n",
            "loss: 0.010919577442109585  [ 2301/ 9040]\n",
            "loss: 0.0  [ 2401/ 9040]\n",
            "loss: 0.0003326578007545322  [ 2501/ 9040]\n",
            "loss: 0.0  [ 2601/ 9040]\n",
            "loss: 0.0  [ 2701/ 9040]\n",
            "loss: 0.0001264730526600033  [ 2801/ 9040]\n",
            "loss: 2.5748875486897305e-05  [ 2901/ 9040]\n",
            "loss: 0.0  [ 3001/ 9040]\n",
            "loss: 0.0002127659390680492  [ 3101/ 9040]\n",
            "loss: 3.576278118089249e-07  [ 3201/ 9040]\n",
            "loss: 1.1920922133867862e-06  [ 3301/ 9040]\n",
            "loss: 0.0  [ 3401/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 3501/ 9040]\n",
            "loss: 0.00032145579461939633  [ 3601/ 9040]\n",
            "loss: 0.0010374169796705246  [ 3701/ 9040]\n",
            "loss: 0.032260362058877945  [ 3801/ 9040]\n",
            "loss: 1.311301275563892e-06  [ 3901/ 9040]\n",
            "loss: 2.3841855067985307e-07  [ 4001/ 9040]\n",
            "loss: 5.364403477869928e-06  [ 4101/ 9040]\n",
            "loss: 0.10304463654756546  [ 4201/ 9040]\n",
            "loss: 0.0  [ 4301/ 9040]\n",
            "loss: 2.3841855067985307e-07  [ 4401/ 9040]\n",
            "loss: 0.0056475368328392506  [ 4501/ 9040]\n",
            "loss: 0.0  [ 4601/ 9040]\n",
            "loss: 0.03160684555768967  [ 4701/ 9040]\n",
            "loss: 0.003415467217564583  [ 4801/ 9040]\n",
            "loss: 2.109982233378105e-05  [ 4901/ 9040]\n",
            "loss: 0.0  [ 5001/ 9040]\n",
            "loss: 0.00047505536349490285  [ 5101/ 9040]\n",
            "loss: 0.03289592266082764  [ 5201/ 9040]\n",
            "loss: 0.0  [ 5301/ 9040]\n",
            "loss: 0.0  [ 5401/ 9040]\n",
            "loss: 0.0  [ 5501/ 9040]\n",
            "loss: 0.0  [ 5601/ 9040]\n",
            "loss: 1.0013530300057027e-05  [ 5701/ 9040]\n",
            "loss: 0.0022594418842345476  [ 5801/ 9040]\n",
            "loss: 2.4437606043647975e-05  [ 5901/ 9040]\n",
            "loss: 6.198863957251888e-06  [ 6001/ 9040]\n",
            "loss: 4.410734163684538e-06  [ 6101/ 9040]\n",
            "loss: 2.145764938177308e-06  [ 6201/ 9040]\n",
            "loss: 8.344646857949556e-07  [ 6301/ 9040]\n",
            "loss: 2.0146166207268834e-05  [ 6401/ 9040]\n",
            "loss: 4.815939246327616e-05  [ 6501/ 9040]\n",
            "loss: 4.708655978902243e-05  [ 6601/ 9040]\n",
            "loss: 0.0  [ 6701/ 9040]\n",
            "loss: 0.007461299654096365  [ 6801/ 9040]\n",
            "loss: 3.0397906812140718e-05  [ 6901/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 7001/ 9040]\n",
            "loss: 0.0011383965611457825  [ 7101/ 9040]\n",
            "loss: 0.017438186332583427  [ 7201/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 7301/ 9040]\n",
            "loss: 0.0004586121649481356  [ 7401/ 9040]\n",
            "loss: 2.109982233378105e-05  [ 7501/ 9040]\n",
            "loss: 0.01531272940337658  [ 7601/ 9040]\n",
            "loss: 0.00038246947224251926  [ 7701/ 9040]\n",
            "loss: 2.3841830625315197e-06  [ 7801/ 9040]\n",
            "loss: 0.004737106617540121  [ 7901/ 9040]\n",
            "loss: 6.9141146923357155e-06  [ 8001/ 9040]\n",
            "loss: 0.0005069877952337265  [ 8101/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 8201/ 9040]\n",
            "loss: 7.152555099310121e-07  [ 8301/ 9040]\n",
            "loss: 0.0037904575001448393  [ 8401/ 9040]\n",
            "loss: 9.643566590966657e-05  [ 8501/ 9040]\n",
            "loss: 0.003288934240117669  [ 8601/ 9040]\n",
            "loss: 0.01809915341436863  [ 8701/ 9040]\n",
            "loss: 0.0011831672163680196  [ 8801/ 9040]\n",
            "loss: 0.7024040222167969  [ 8901/ 9040]\n",
            "loss: 0.0  [ 9001/ 9040]\n",
            "Train Accuracy: 99.0\n",
            "\n",
            "Test Error: \n",
            " Accuracy: 91.5%, Avg loss: 0.379736 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "\n",
            "loss: 9.262132516596466e-05  [    1/ 9040]\n",
            "loss: 1.0728830375228426e-06  [  101/ 9040]\n",
            "loss: 0.0  [  201/ 9040]\n",
            "loss: 0.0001823735801735893  [  301/ 9040]\n",
            "loss: 0.0  [  401/ 9040]\n",
            "loss: 0.015917614102363586  [  501/ 9040]\n",
            "loss: 0.0  [  601/ 9040]\n",
            "loss: 0.0011018402874469757  [  701/ 9040]\n",
            "loss: 0.0031375489197671413  [  801/ 9040]\n",
            "loss: 0.0020748295355588198  [  901/ 9040]\n",
            "loss: 0.0007789676310494542  [ 1001/ 9040]\n",
            "loss: 0.0  [ 1101/ 9040]\n",
            "loss: 0.0007039214833639562  [ 1201/ 9040]\n",
            "loss: 0.0040728249587118626  [ 1301/ 9040]\n",
            "loss: 0.00022659118985757232  [ 1401/ 9040]\n",
            "loss: 0.0  [ 1501/ 9040]\n",
            "loss: 0.006908932700753212  [ 1601/ 9040]\n",
            "loss: 2.264974000354414e-06  [ 1701/ 9040]\n",
            "loss: 1.0013530300057027e-05  [ 1801/ 9040]\n",
            "loss: 1.1920922133867862e-06  [ 1901/ 9040]\n",
            "loss: 0.00035065223346464336  [ 2001/ 9040]\n",
            "loss: 5.8412379075889476e-06  [ 2101/ 9040]\n",
            "loss: 0.0  [ 2201/ 9040]\n",
            "loss: 0.00014757021563127637  [ 2301/ 9040]\n",
            "loss: 0.0  [ 2401/ 9040]\n",
            "loss: 0.00096703483723104  [ 2501/ 9040]\n",
            "loss: 0.0  [ 2601/ 9040]\n",
            "loss: 0.0  [ 2701/ 9040]\n",
            "loss: 2.145764938177308e-06  [ 2801/ 9040]\n",
            "loss: 2.3245540432981215e-05  [ 2901/ 9040]\n",
            "loss: 0.0  [ 3001/ 9040]\n",
            "loss: 0.00023529145983047783  [ 3101/ 9040]\n",
            "loss: 1.1920922133867862e-06  [ 3201/ 9040]\n",
            "loss: 3.933898824470816e-06  [ 3301/ 9040]\n",
            "loss: 0.0  [ 3401/ 9040]\n",
            "loss: 0.0  [ 3501/ 9040]\n",
            "loss: 5.245195097813848e-06  [ 3601/ 9040]\n",
            "loss: 0.0010283663868904114  [ 3701/ 9040]\n",
            "loss: 0.7473034262657166  [ 3801/ 9040]\n",
            "loss: 5.960462772236497e-07  [ 3901/ 9040]\n",
            "loss: 5.006777428206988e-06  [ 4001/ 9040]\n",
            "loss: 7.629365427419543e-06  [ 4101/ 9040]\n",
            "loss: 0.0005395148764364421  [ 4201/ 9040]\n",
            "loss: 0.0  [ 4301/ 9040]\n",
            "loss: 3.576278118089249e-07  [ 4401/ 9040]\n",
            "loss: 0.0007595514762215316  [ 4501/ 9040]\n",
            "loss: 0.0  [ 4601/ 9040]\n",
            "loss: 0.03473224490880966  [ 4701/ 9040]\n",
            "loss: 0.0003233625029679388  [ 4801/ 9040]\n",
            "loss: 9.691245941212401e-05  [ 4901/ 9040]\n",
            "loss: 0.0  [ 5001/ 9040]\n",
            "loss: 0.0004148814477957785  [ 5101/ 9040]\n",
            "loss: 0.0005552418879233301  [ 5201/ 9040]\n",
            "loss: 0.0  [ 5301/ 9040]\n",
            "loss: 0.0  [ 5401/ 9040]\n",
            "loss: 0.0  [ 5501/ 9040]\n",
            "loss: 0.0  [ 5601/ 9040]\n",
            "loss: 4.6132929128361866e-05  [ 5701/ 9040]\n",
            "loss: 0.0033207768574357033  [ 5801/ 9040]\n",
            "loss: 0.0017487009754404426  [ 5901/ 9040]\n",
            "loss: 4.732496745418757e-05  [ 6001/ 9040]\n",
            "loss: 7.152555099310121e-07  [ 6101/ 9040]\n",
            "loss: 3.576278118089249e-07  [ 6201/ 9040]\n",
            "loss: 0.0  [ 6301/ 9040]\n",
            "loss: 1.3232143828645349e-05  [ 6401/ 9040]\n",
            "loss: 0.00026890001026913524  [ 6501/ 9040]\n",
            "loss: 7.962863310240209e-05  [ 6601/ 9040]\n",
            "loss: 0.0  [ 6701/ 9040]\n",
            "loss: 0.04648308828473091  [ 6801/ 9040]\n",
            "loss: 1.5497195136049413e-06  [ 6901/ 9040]\n",
            "loss: 0.0  [ 7001/ 9040]\n",
            "loss: 0.0008369756978936493  [ 7101/ 9040]\n",
            "loss: 0.0016244561411440372  [ 7201/ 9040]\n",
            "loss: 0.0  [ 7301/ 9040]\n",
            "loss: 0.0006456674309447408  [ 7401/ 9040]\n",
            "loss: 1.1920922133867862e-06  [ 7501/ 9040]\n",
            "loss: 0.04878058284521103  [ 7601/ 9040]\n",
            "loss: 0.001669562072493136  [ 7701/ 9040]\n",
            "loss: 1.311301275563892e-06  [ 7801/ 9040]\n",
            "loss: 0.005378300789743662  [ 7901/ 9040]\n",
            "loss: 4.6491513785440475e-06  [ 8001/ 9040]\n",
            "loss: 0.00010787858627736568  [ 8101/ 9040]\n",
            "loss: 0.0  [ 8201/ 9040]\n",
            "loss: 1.0728830375228426e-06  [ 8301/ 9040]\n"
          ]
        }
      ],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "epochs = 100\n",
        "for t in range(epochs):\n",
        "    if t <= last_epoch:\n",
        "      continue\n",
        "    str = (f\"Epoch {t+1}\\n-------------------------------\\n\")\n",
        "    print(str)\n",
        "    with open(base_path + \"log.txt\", \"a\") as f:\n",
        "        f.write(str)\n",
        "    train_loop(dataset, model, loss_fn, optimizer)\n",
        "    test_loop(dataset, model, loss_fn)\n",
        "    torch.save(model.state_dict(), base_path + f\"eeg_model_{t}.pth\")\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49ySsevVMji2"
      },
      "outputs": [],
      "source": [
        "assert best_model_parameter is not None, \"No best model\"\n",
        "best_model = NeuralNetwork().to(device)\n",
        "best_model.load_state_dict(best_model_parameter)\n",
        "torch.save(best_model.state_dict(), \"eeg_model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usegr5dqMji2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HynMGZX3Mji2"
      },
      "outputs": [],
      "source": [
        "!cp ./log.txt ./drive/MyDrive/Neuroscience"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hPFI0QXMji2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}