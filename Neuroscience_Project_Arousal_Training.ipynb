{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQQ2QmmVMyJa",
        "outputId": "5fe28213-a5d8-4fec-89a2-ad42a92de0fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torcheeg\n",
            "  Downloading torcheeg-1.0.11.tar.gz (161 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.1/161.1 KB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.9/dist-packages (from torcheeg) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.21.5 in /usr/local/lib/python3.9/dist-packages (from torcheeg) (1.22.4)\n",
            "Requirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.9/dist-packages (from torcheeg) (1.4.4)\n",
            "Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.9/dist-packages (from torcheeg) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.9/dist-packages (from torcheeg) (1.2.2)\n",
            "Collecting lmdb>=1.3.0\n",
            "  Downloading lmdb-1.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (298 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.5/298.5 KB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops>=0.4.1\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 KB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mne>=1.0.3\n",
            "  Downloading mne-1.3.1-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xmltodict>=0.13.0\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: networkx>=2.6.3 in /usr/local/lib/python3.9/dist-packages (from torcheeg) (3.0)\n",
            "Requirement already satisfied: PyWavelets>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from torcheeg) (1.4.1)\n",
            "Collecting spectrum>=0.8.1\n",
            "  Downloading spectrum-0.8.1.tar.gz (230 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.8/230.8 KB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchmetrics>=0.8.2\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 KB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mne_connectivity>=0.4.0\n",
            "  Downloading mne_connectivity-0.5.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 KB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from mne>=1.0.3->torcheeg) (23.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from mne>=1.0.3->torcheeg) (3.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from mne>=1.0.3->torcheeg) (3.1.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from mne>=1.0.3->torcheeg) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.9/dist-packages (from mne>=1.0.3->torcheeg) (1.6.0)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.9/dist-packages (from mne_connectivity>=0.4.0->torcheeg) (2022.12.0)\n",
            "Collecting netCDF4\n",
            "  Downloading netCDF4-1.6.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.3.5->torcheeg) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.3.5->torcheeg) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.2->torcheeg) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.2->torcheeg) (1.1.1)\n",
            "Collecting easydev\n",
            "  Downloading easydev-0.12.1.tar.gz (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 KB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from torchmetrics>=0.8.2->torcheeg) (2.0.0+cu118)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from pooch>=1.5->mne>=1.0.3->torcheeg) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from pooch>=1.5->mne>=1.0.3->torcheeg) (2.27.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas>=1.3.5->torcheeg) (1.16.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics>=0.8.2->torcheeg) (2.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics>=0.8.2->torcheeg) (1.11.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics>=0.8.2->torcheeg) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics>=0.8.2->torcheeg) (3.10.7)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics>=0.8.2->torcheeg) (16.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics>=0.8.2->torcheeg) (3.25.2)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.9/dist-packages (from easydev->spectrum>=0.8.1->torcheeg) (4.8.0)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->mne>=1.0.3->torcheeg) (2.1.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne>=1.0.3->torcheeg) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne>=1.0.3->torcheeg) (3.0.9)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne>=1.0.3->torcheeg) (5.12.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne>=1.0.3->torcheeg) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne>=1.0.3->torcheeg) (8.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne>=1.0.3->torcheeg) (1.0.7)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne>=1.0.3->torcheeg) (4.39.3)\n",
            "Collecting cftime\n",
            "  Downloading cftime-1.6.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->mne>=1.0.3->torcheeg) (3.15.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.5->mne>=1.0.3->torcheeg) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.5->mne>=1.0.3->torcheeg) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.5->mne>=1.0.3->torcheeg) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.5->mne>=1.0.3->torcheeg) (3.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/dist-packages (from pexpect->easydev->spectrum>=0.8.1->torcheeg) (0.7.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.8.1->torchmetrics>=0.8.2->torcheeg) (1.3.0)\n",
            "Building wheels for collected packages: torcheeg, spectrum, easydev\n",
            "  Building wheel for torcheeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torcheeg: filename=torcheeg-1.0.11-py3-none-any.whl size=345121 sha256=881c54401ce602df74e2813446bc39c441c49984a7681a8464f0f230ee484f22\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/3c/00/36d7085ce0082ba53038595f6a7a010bbf7b5703227a6b16e5\n",
            "  Building wheel for spectrum (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spectrum: filename=spectrum-0.8.1-cp39-cp39-linux_x86_64.whl size=237780 sha256=e791348aa9abc6ed6857a7161948f059265e76b4fa7ab4d26bd459deef9633fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/03/05/e7ced8d2ae677d5c887dafb37619e6f0f978b2f5e60b5cd8e9\n",
            "  Building wheel for easydev (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for easydev: filename=easydev-0.12.1-py3-none-any.whl size=64214 sha256=147a8a6c1bd61e2c064e75b2c46814e7179affbb6fffae928139be7f1b0dd9d3\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/61/14/9e079fd8b2ae87fdff1df1c8757e33652854b4f3149e944ff6\n",
            "Successfully built torcheeg spectrum easydev\n",
            "Installing collected packages: lmdb, xmltodict, einops, colorlog, colorama, cftime, netCDF4, easydev, spectrum, mne, mne_connectivity, torchmetrics, torcheeg\n",
            "Successfully installed cftime-1.6.2 colorama-0.4.6 colorlog-6.7.0 easydev-0.12.1 einops-0.6.0 lmdb-1.4.1 mne-1.3.1 mne_connectivity-0.5.0 netCDF4-1.6.3 spectrum-0.8.1 torcheeg-1.0.11 torchmetrics-0.11.4 xmltodict-0.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torcheeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MwikNtDMjis"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import signal\n",
        "from rich.pretty import pprint\n",
        "from torcheeg.datasets import DREAMERDataset\n",
        "from torcheeg.datasets.constants.emotion_recognition.dreamer import DREAMER_CHANNEL_LOCATION_DICT\n",
        "from torcheeg import transforms\n",
        "from torch import nn\n",
        "import torch\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "He4HfZ9INBqd",
        "outputId": "9213accc-88bf-47fe-df23-4047872a448f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROctHay3Mjiv"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"/content/drive/MyDrive/Neuroscience/DREAMER.mat\"\n",
        "base_path = \"/content/drive/MyDrive/Neuroscience/Arousal1/\"\n",
        "\n",
        "# dataset_path = \"/content/drive/MyDrive/Neuroscience/DREAMER.mat\"\n",
        "# base_path = \"/content/drive/MyDrive/Neuroscience/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeS8rzjgMjiv",
        "outputId": "dbcf4a59-2af4-41e1-ce13-2703235de1c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The target folder already exists, if you need to regenerate the database IO, please delete the path /content/drive/MyDrive/Neuroscience/Arousal1/dreamer8sec.\n"
          ]
        }
      ],
      "source": [
        "dataset = DREAMERDataset(\n",
        "    io_path=base_path + 'dreamer8sec',\n",
        "    mat_path=dataset_path,\n",
        "    offline_transform=transforms.Compose([\n",
        "        transforms.BaselineRemoval(),\n",
        "        transforms.MeanStdNormalize(),\n",
        "        transforms.To2d()\n",
        "    ]),\n",
        "    # online_transform=transforms.ToTensor(),\n",
        "    label_transform=transforms.Compose(\n",
        "        [transforms.Select('arousal'),\n",
        "         transforms.Binary(3.0)]),\n",
        "    chunk_size=976,\n",
        "    baseline_chunk_size=976,\n",
        "    num_baseline=8\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYg8kdfcMjix"
      },
      "outputs": [],
      "source": [
        "def get_tf_feature(eeg, sr, n_channels = 14):\n",
        "    WinLength = int(0.5*sr) # 500 points (0.5 sec, 500 ms)\n",
        "    step = int(0.025*sr) # 25 points (or 25 ms)\n",
        "    final_features = None\n",
        "    for i in range(n_channels):\n",
        "        eeg_single = eeg[i].squeeze()\n",
        "        myparams = dict(nperseg = WinLength, noverlap = WinLength-step, return_onesided=True, mode='magnitude')\n",
        "        f, nseg, Sxx = signal.spectrogram(x = eeg_single, fs = sr, **myparams)\n",
        "        if(isinstance(final_features, np.ndarray)):\n",
        "            final_features = np.concatenate((final_features, Sxx), axis=0)\n",
        "        else:\n",
        "            final_features = Sxx\n",
        "    return final_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxRp3C3nMjiy",
        "outputId": "147f02d9-980d-45f1-84f5-3cce9764f56b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# device = \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1a8bHcFMjiy"
      },
      "outputs": [],
      "source": [
        "def convert_data_to_tensor(data):\n",
        "    data = data.astype(\"float32\")\n",
        "    data = data.reshape(1, data.shape[0], data.shape[1])\n",
        "    return torch.from_numpy(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_xdabRlMjiz"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv2D_1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 1024, 11, stride=3),\n",
        "            nn.Conv2d(1024, 512, 7, stride=3),\n",
        "            nn.Conv2d(512, 128, 7, stride=3),\n",
        "        )\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            # nn.Linear(14550, 2048),\n",
        "            # nn.ReLU(),\n",
        "            nn.Linear(17280, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv2D_1(x)\n",
        "        # x = self.flatten(x)\n",
        "        x = x.view(1, -1)\n",
        "        # print(x.shape)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQi1-d9WMjiz"
      },
      "outputs": [],
      "source": [
        "random.seed(42)\n",
        "\n",
        "test_size = 2000\n",
        "test_index = random.sample(range(0, 11000), test_size)\n",
        "train_index = []\n",
        "\n",
        "for i in range(11040):\n",
        "    if i not in test_index:\n",
        "        train_index.append(i)\n",
        "random.shuffle(train_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2H8L58PHMjiz"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataset,  model, loss_fn, optimizer):\n",
        "    # size = len(dataset)\n",
        "    model.train()\n",
        "    sample_size = len(train_index)\n",
        "    j=0\n",
        "    correct = 0\n",
        "    for i in train_index:\n",
        "        # Compute prediction and loss\n",
        "        # print(i)\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        X, y = dataset[i][0][0], dataset[i][1]\n",
        "        X = get_tf_feature(X, sr=128)\n",
        "        X = convert_data_to_tensor(X)\n",
        "        if y == 0:\n",
        "            y = [0]\n",
        "        else:\n",
        "            y = [1]\n",
        "        y = torch.tensor(y)\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        pred = model(X)\n",
        "        # print(y.shape, pred.shape)\n",
        "        loss = loss_fn(pred, y)\n",
        "        \n",
        "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if j % 100 == 0:\n",
        "            loss, current = loss.item(), j + 1\n",
        "            print(f\"loss: {loss}  [{current:>5d}/{sample_size:>5d}]\")\n",
        "            # if j%1000 == 0:\n",
        "              # torch.save(model.state_dict(), \"eeg_model_1000.pth\")\n",
        "        j=j+1\n",
        "    correct /= sample_size\n",
        "    str = (f\"Train Accuracy: {(100*correct):>0.1f}\\n\")\n",
        "    print(str)\n",
        "    with open(base_path + \"log.txt\", \"a\") as f:\n",
        "        f.write(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0Yj50GzMji0"
      },
      "outputs": [],
      "source": [
        "\n",
        "val_error = 999999999.9\n",
        "best_model_parameter = None\n",
        "\n",
        "def test_loop(dataset, model, loss_fn):\n",
        "    global val_error\n",
        "    global best_model_parameter\n",
        "    # size = len(dataset)\n",
        "    test_loss, correct = 0, 0\n",
        "    sample_size = len(test_index)\n",
        "    # l = random.sample(range(0, 11000), 1)\n",
        "    # j=0\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for i in test_index:\n",
        "            X, y = dataset[i][0][0], dataset[i][1]\n",
        "            X = get_tf_feature(X, sr=128)\n",
        "            X = convert_data_to_tensor(X)\n",
        "            if y == 0:\n",
        "                y = [0]\n",
        "            else:\n",
        "                y = [1]\n",
        "            y = torch.tensor(y)\n",
        "            \n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= sample_size\n",
        "    correct /= sample_size\n",
        "\n",
        "    if val_error > test_loss:\n",
        "        val_error = test_loss\n",
        "        best_model_parameter = model.state_dict()\n",
        "\n",
        "    str = (f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    print(str)\n",
        "    with open(base_path + \"log.txt\", \"a\") as f:\n",
        "        f.write(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9Rdio0rMji1"
      },
      "outputs": [],
      "source": [
        "learning_rate = 3e-6"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_epoch = 9\n",
        "model = NeuralNetwork().to(device)\n",
        "if last_epoch >= 0:\n",
        "  model.load_state_dict(torch.load(base_path + f'eeg_model_{last_epoch}.pth', map_location=torch.device('cpu')))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZT3mi6dj5Dn5",
        "outputId": "0fe31c82-0cde-4a87-c876-4761fe4e52ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNetwork(\n",
              "  (conv2D_1): Sequential(\n",
              "    (0): Conv2d(1, 1024, kernel_size=(11, 11), stride=(3, 3))\n",
              "    (1): Conv2d(1024, 512, kernel_size=(7, 7), stride=(3, 3))\n",
              "    (2): Conv2d(512, 128, kernel_size=(7, 7), stride=(3, 3))\n",
              "  )\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (linear_relu_stack): Sequential(\n",
              "    (0): Linear(in_features=17280, out_features=1024, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=512, out_features=128, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=128, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wBQGnn7TMji1",
        "outputId": "00f5b6a3-b4e1-4e38-fbee-a6eae3357c3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11\n",
            "-------------------------------\n",
            "\n",
            "loss: 4.768370445162873e-07  [    1/ 9040]\n",
            "loss: 1.1920928244535389e-07  [  101/ 9040]\n",
            "loss: 9.16677454370074e-05  [  201/ 9040]\n",
            "loss: 0.003986389376223087  [  301/ 9040]\n",
            "loss: 1.1920928244535389e-07  [  401/ 9040]\n",
            "loss: 0.00010179955279454589  [  501/ 9040]\n",
            "loss: 0.0  [  601/ 9040]\n",
            "loss: 0.022461412474513054  [  701/ 9040]\n",
            "loss: 0.014150167815387249  [  801/ 9040]\n",
            "loss: 0.022915199398994446  [  901/ 9040]\n",
            "loss: 0.002562693553045392  [ 1001/ 9040]\n",
            "loss: 7.152555099310121e-07  [ 1101/ 9040]\n",
            "loss: 0.053099375218153  [ 1201/ 9040]\n",
            "loss: 0.04856870695948601  [ 1301/ 9040]\n",
            "loss: 0.012437872588634491  [ 1401/ 9040]\n",
            "loss: 0.03686638921499252  [ 1501/ 9040]\n",
            "loss: 0.0012317459331825376  [ 1601/ 9040]\n",
            "loss: 3.576278118089249e-07  [ 1701/ 9040]\n",
            "loss: 0.004210892133414745  [ 1801/ 9040]\n",
            "loss: 0.15342797338962555  [ 1901/ 9040]\n",
            "loss: 0.09003865718841553  [ 2001/ 9040]\n",
            "loss: 1.0251946150674485e-05  [ 2101/ 9040]\n",
            "loss: 0.0  [ 2201/ 9040]\n",
            "loss: 0.00025948495022021234  [ 2301/ 9040]\n",
            "loss: 2.3841855067985307e-07  [ 2401/ 9040]\n",
            "loss: 0.0020146328024566174  [ 2501/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 2601/ 9040]\n",
            "loss: 2.2053474822314456e-05  [ 2701/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 2801/ 9040]\n",
            "loss: 0.0024906350299715996  [ 2901/ 9040]\n",
            "loss: 0.0  [ 3001/ 9040]\n",
            "loss: 0.0012072187382727861  [ 3101/ 9040]\n",
            "loss: 2.0265558760002023e-06  [ 3201/ 9040]\n",
            "loss: 0.0021946171764284372  [ 3301/ 9040]\n",
            "loss: 0.0  [ 3401/ 9040]\n",
            "loss: 0.0  [ 3501/ 9040]\n",
            "loss: 0.0001961992384167388  [ 3601/ 9040]\n",
            "loss: 0.0034661947283893824  [ 3701/ 9040]\n",
            "loss: 0.0013374679256230593  [ 3801/ 9040]\n",
            "loss: 6.198863957251888e-06  [ 3901/ 9040]\n",
            "loss: 0.00012230125139467418  [ 4001/ 9040]\n",
            "loss: 1.2636104656849056e-05  [ 4101/ 9040]\n",
            "loss: 1.4781842764932662e-05  [ 4201/ 9040]\n",
            "loss: 0.0005932478234171867  [ 4301/ 9040]\n",
            "loss: 0.0030342750251293182  [ 4401/ 9040]\n",
            "loss: 0.007125560659915209  [ 4501/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 4601/ 9040]\n",
            "loss: 0.005592533387243748  [ 4701/ 9040]\n",
            "loss: 0.283753365278244  [ 4801/ 9040]\n",
            "loss: 9.810443589231e-05  [ 4901/ 9040]\n",
            "loss: 1.7881377516459906e-06  [ 5001/ 9040]\n",
            "loss: 0.020148372277617455  [ 5101/ 9040]\n",
            "loss: 0.0013048476539552212  [ 5201/ 9040]\n",
            "loss: 0.0  [ 5301/ 9040]\n",
            "loss: 4.768370445162873e-07  [ 5401/ 9040]\n",
            "loss: 5.638440416078083e-05  [ 5501/ 9040]\n",
            "loss: 0.0  [ 5601/ 9040]\n",
            "loss: 1.261828899383545  [ 5701/ 9040]\n",
            "loss: 0.038896579295396805  [ 5801/ 9040]\n",
            "loss: 2.2411095415009186e-05  [ 5901/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 6001/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 6101/ 9040]\n",
            "loss: 2.50339189733495e-06  [ 6201/ 9040]\n",
            "loss: 0.0007933806627988815  [ 6301/ 9040]\n",
            "loss: 0.0018952994141727686  [ 6401/ 9040]\n",
            "loss: 8.046303264563903e-05  [ 6501/ 9040]\n",
            "loss: 0.00012134769349358976  [ 6601/ 9040]\n",
            "loss: 0.0014293702552095056  [ 6701/ 9040]\n",
            "loss: 1.0728830375228426e-06  [ 6801/ 9040]\n",
            "loss: 0.0003830652858596295  [ 6901/ 9040]\n",
            "loss: 0.00013147920253686607  [ 7001/ 9040]\n",
            "loss: 0.0003564914222806692  [ 7101/ 9040]\n",
            "loss: 0.00985034555196762  [ 7201/ 9040]\n",
            "loss: 0.0  [ 7301/ 9040]\n",
            "loss: 0.0006611545104533434  [ 7401/ 9040]\n",
            "loss: 6.981983661651611  [ 7501/ 9040]\n",
            "loss: 0.22139117121696472  [ 7601/ 9040]\n",
            "loss: 0.0020260538440197706  [ 7701/ 9040]\n",
            "loss: 2.586808113846928e-05  [ 7801/ 9040]\n",
            "loss: 5.960462772236497e-07  [ 7901/ 9040]\n",
            "loss: 0.00017617580306250602  [ 8001/ 9040]\n",
            "loss: 2.9802276912960224e-06  [ 8101/ 9040]\n",
            "loss: 3.3378546504536644e-06  [ 8201/ 9040]\n",
            "loss: 1.5497195136049413e-06  [ 8301/ 9040]\n",
            "loss: 0.004270956851541996  [ 8401/ 9040]\n",
            "loss: 7.271740287251305e-06  [ 8501/ 9040]\n",
            "loss: 0.028567109256982803  [ 8601/ 9040]\n",
            "loss: 0.004614538047462702  [ 8701/ 9040]\n",
            "loss: 9.536738616588991e-07  [ 8801/ 9040]\n",
            "loss: 0.047173015773296356  [ 8901/ 9040]\n",
            "loss: 0.0  [ 9001/ 9040]\n",
            "Train Accuracy: 98.1\n",
            "\n",
            "Test Error: \n",
            " Accuracy: 89.3%, Avg loss: 0.443244 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "\n",
            "loss: 8.344646857949556e-07  [    1/ 9040]\n",
            "loss: 1.1920928244535389e-07  [  101/ 9040]\n",
            "loss: 7.30726242181845e-05  [  201/ 9040]\n",
            "loss: 0.004792631138116121  [  301/ 9040]\n",
            "loss: 2.098061486321967e-05  [  401/ 9040]\n",
            "loss: 2.8609820219571702e-05  [  501/ 9040]\n",
            "loss: 0.0  [  601/ 9040]\n",
            "loss: 0.007427813485264778  [  701/ 9040]\n",
            "loss: 0.006035791710019112  [  801/ 9040]\n",
            "loss: 0.020971694961190224  [  901/ 9040]\n",
            "loss: 0.0006102845072746277  [ 1001/ 9040]\n",
            "loss: 4.0531076592742465e-06  [ 1101/ 9040]\n",
            "loss: 0.010312840342521667  [ 1201/ 9040]\n",
            "loss: 0.0011308948742225766  [ 1301/ 9040]\n",
            "loss: 0.0073556313291192055  [ 1401/ 9040]\n",
            "loss: 0.018164008855819702  [ 1501/ 9040]\n",
            "loss: 0.0008571050129830837  [ 1601/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 1701/ 9040]\n",
            "loss: 0.004682290833443403  [ 1801/ 9040]\n",
            "loss: 0.07025431096553802  [ 1901/ 9040]\n",
            "loss: 0.11461947113275528  [ 2001/ 9040]\n",
            "loss: 5.23315102327615e-05  [ 2101/ 9040]\n",
            "loss: 0.0  [ 2201/ 9040]\n",
            "loss: 4.8993817472364753e-05  [ 2301/ 9040]\n",
            "loss: 0.0  [ 2401/ 9040]\n",
            "loss: 0.014778309501707554  [ 2501/ 9040]\n",
            "loss: 0.0  [ 2601/ 9040]\n",
            "loss: 0.0  [ 2701/ 9040]\n",
            "loss: 0.0  [ 2801/ 9040]\n",
            "loss: 0.012601865455508232  [ 2901/ 9040]\n",
            "loss: 0.0  [ 3001/ 9040]\n",
            "loss: 0.0005650115781463683  [ 3101/ 9040]\n",
            "loss: 8.34461570775602e-06  [ 3201/ 9040]\n",
            "loss: 5.364403477869928e-06  [ 3301/ 9040]\n",
            "loss: 9.536738616588991e-07  [ 3401/ 9040]\n",
            "loss: 3.576278118089249e-07  [ 3501/ 9040]\n",
            "loss: 0.00010179955279454589  [ 3601/ 9040]\n",
            "loss: 0.00037543877260759473  [ 3701/ 9040]\n",
            "loss: 0.9789763689041138  [ 3801/ 9040]\n",
            "loss: 1.9073468138230965e-06  [ 3901/ 9040]\n",
            "loss: 0.000803505361545831  [ 4001/ 9040]\n",
            "loss: 1.4066597032069694e-05  [ 4101/ 9040]\n",
            "loss: 0.0001431601122021675  [ 4201/ 9040]\n",
            "loss: 0.00015698630886618048  [ 4301/ 9040]\n",
            "loss: 0.005136626306921244  [ 4401/ 9040]\n",
            "loss: 0.014334914274513721  [ 4501/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 4601/ 9040]\n",
            "loss: 0.0029970749747008085  [ 4701/ 9040]\n",
            "loss: 1.7724217176437378  [ 4801/ 9040]\n",
            "loss: 3.0278701160568744e-05  [ 4901/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 5001/ 9040]\n",
            "loss: 0.04613993689417839  [ 5101/ 9040]\n",
            "loss: 0.004532777238637209  [ 5201/ 9040]\n",
            "loss: 0.0  [ 5301/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 5401/ 9040]\n",
            "loss: 9.500529267825186e-05  [ 5501/ 9040]\n",
            "loss: 0.0  [ 5601/ 9040]\n",
            "loss: 0.0008927173912525177  [ 5701/ 9040]\n",
            "loss: 0.09170902520418167  [ 5801/ 9040]\n",
            "loss: 2.3841855067985307e-07  [ 5901/ 9040]\n",
            "loss: 0.0  [ 6001/ 9040]\n",
            "loss: 9.119095193454996e-05  [ 6101/ 9040]\n",
            "loss: 0.0  [ 6201/ 9040]\n",
            "loss: 2.8967437174287625e-05  [ 6301/ 9040]\n",
            "loss: 0.06027046591043472  [ 6401/ 9040]\n",
            "loss: 5.006777428206988e-06  [ 6501/ 9040]\n",
            "loss: 0.00010573305189609528  [ 6601/ 9040]\n",
            "loss: 0.0007503792876377702  [ 6701/ 9040]\n",
            "loss: 8.34461570775602e-06  [ 6801/ 9040]\n",
            "loss: 0.0001454247540095821  [ 6901/ 9040]\n",
            "loss: 3.576278118089249e-07  [ 7001/ 9040]\n",
            "loss: 2.753696753643453e-05  [ 7101/ 9040]\n",
            "loss: 0.2777126133441925  [ 7201/ 9040]\n",
            "loss: 3.576278118089249e-07  [ 7301/ 9040]\n",
            "loss: 0.0015588762471452355  [ 7401/ 9040]\n",
            "loss: 0.8963577747344971  [ 7501/ 9040]\n",
            "loss: 0.8352268934249878  [ 7601/ 9040]\n",
            "loss: 0.0001512651506345719  [ 7701/ 9040]\n",
            "loss: 5.8410845667822286e-05  [ 7801/ 9040]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-f07b9845afa0>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"log.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mtest_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf\"eeg_model_{t}.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-33b2056f7a2d>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(dataset, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# print(y.shape, pred.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "epochs = 100\n",
        "for t in range(epochs):\n",
        "    if t <= last_epoch:\n",
        "      continue\n",
        "    str = (f\"Epoch {t+1}\\n-------------------------------\\n\")\n",
        "    print(str)\n",
        "    with open(base_path + \"log.txt\", \"a\") as f:\n",
        "        f.write(str)\n",
        "    train_loop(dataset, model, loss_fn, optimizer)\n",
        "    test_loop(dataset, model, loss_fn)\n",
        "    torch.save(model.state_dict(), base_path + f\"eeg_model_{t}.pth\")\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49ySsevVMji2"
      },
      "outputs": [],
      "source": [
        "assert best_model_parameter is not None, \"No best model\"\n",
        "best_model = NeuralNetwork().to(device)\n",
        "best_model.load_state_dict(best_model_parameter)\n",
        "torch.save(best_model.state_dict(), \"eeg_model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usegr5dqMji2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HynMGZX3Mji2"
      },
      "outputs": [],
      "source": [
        "!cp ./log.txt ./drive/MyDrive/Neuroscience"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hPFI0QXMji2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}