{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQQ2QmmVMyJa",
        "outputId": "79e876be-d773-49f0-8dee-ec4822650644"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torcheeg\n",
            "  Downloading torcheeg-1.0.11.tar.gz (161 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.1/161.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from torcheeg) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.21.5 in /usr/local/lib/python3.10/dist-packages (from torcheeg) (1.22.4)\n",
            "Requirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.10/dist-packages (from torcheeg) (1.5.3)\n",
            "Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.10/dist-packages (from torcheeg) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from torcheeg) (1.2.2)\n",
            "Collecting lmdb>=1.3.0\n",
            "  Downloading lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops>=0.4.1\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m819.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mne>=1.0.3\n",
            "  Downloading mne-1.3.1-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xmltodict>=0.13.0\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: networkx>=2.6.3 in /usr/local/lib/python3.10/dist-packages (from torcheeg) (3.1)\n",
            "Requirement already satisfied: PyWavelets>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from torcheeg) (1.4.1)\n",
            "Collecting spectrum>=0.8.1\n",
            "  Downloading spectrum-0.8.1.tar.gz (230 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.8/230.8 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchmetrics>=0.8.2\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mne_connectivity>=0.4.0\n",
            "  Downloading mne_connectivity-0.5.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mne>=1.0.3->torcheeg) (3.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne>=1.0.3->torcheeg) (23.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne>=1.0.3->torcheeg) (3.1.2)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne>=1.0.3->torcheeg) (1.6.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne>=1.0.3->torcheeg) (4.4.2)\n",
            "Collecting netCDF4\n",
            "  Downloading netCDF4-1.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xarray in /usr/local/lib/python3.10/dist-packages (from mne_connectivity>=0.4.0->torcheeg) (2022.12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->torcheeg) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->torcheeg) (2022.7.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->torcheeg) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->torcheeg) (1.2.0)\n",
            "Collecting easydev\n",
            "  Downloading easydev-0.12.1.tar.gz (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics>=0.8.2->torcheeg) (2.0.0+cu118)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne>=1.0.3->torcheeg) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne>=1.0.3->torcheeg) (2.27.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.3.5->torcheeg) (1.16.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics>=0.8.2->torcheeg) (1.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics>=0.8.2->torcheeg) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics>=0.8.2->torcheeg) (4.5.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics>=0.8.2->torcheeg) (2.0.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics>=0.8.2->torcheeg) (16.0.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics>=0.8.2->torcheeg) (3.25.2)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.10/dist-packages (from easydev->spectrum>=0.8.1->torcheeg) (4.8.0)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne>=1.0.3->torcheeg) (2.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mne>=1.0.3->torcheeg) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mne>=1.0.3->torcheeg) (1.4.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mne>=1.0.3->torcheeg) (1.0.7)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mne>=1.0.3->torcheeg) (4.39.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mne>=1.0.3->torcheeg) (8.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mne>=1.0.3->torcheeg) (0.11.0)\n",
            "Collecting cftime\n",
            "  Downloading cftime-1.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne>=1.0.3->torcheeg) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne>=1.0.3->torcheeg) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne>=1.0.3->torcheeg) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne>=1.0.3->torcheeg) (2022.12.7)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect->easydev->spectrum>=0.8.1->torcheeg) (0.7.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics>=0.8.2->torcheeg) (1.3.0)\n",
            "Building wheels for collected packages: torcheeg, spectrum, easydev\n",
            "  Building wheel for torcheeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torcheeg: filename=torcheeg-1.0.11-py3-none-any.whl size=345121 sha256=41b14d4a9ad833c1215feaa81d6de7566a16edc0800fdd32305084226bbd5ab9\n",
            "  Stored in directory: /root/.cache/pip/wheels/24/94/6a/d4ca5521962f9c4ea6f468b1404ba02a2462a5e63e2ba2b0a7\n",
            "  Building wheel for spectrum (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spectrum: filename=spectrum-0.8.1-cp310-cp310-linux_x86_64.whl size=237783 sha256=7234608ec293b41f376ff7370442a1ee370bc51845449eb1977dc53f9f4988ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/5a/09/ffc6afdf8a5a6f58e9851292108df32bb11374e11b8705cabd\n",
            "  Building wheel for easydev (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for easydev: filename=easydev-0.12.1-py3-none-any.whl size=64214 sha256=24b5fce38d4576105a5f35d9db8554eb64dd37d27bc025de3a3f6258add669fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/a3/df/e8e19f6f1674c2b0574ccc1a156292b599709eaa4feeea0fcf\n",
            "Successfully built torcheeg spectrum easydev\n",
            "Installing collected packages: lmdb, xmltodict, einops, colorlog, colorama, cftime, netCDF4, easydev, spectrum, mne, mne_connectivity, torchmetrics, torcheeg\n",
            "Successfully installed cftime-1.6.2 colorama-0.4.6 colorlog-6.7.0 easydev-0.12.1 einops-0.6.1 lmdb-1.4.1 mne-1.3.1 mne_connectivity-0.5.0 netCDF4-1.6.3 spectrum-0.8.1 torcheeg-1.0.11 torchmetrics-0.11.4 xmltodict-0.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torcheeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MwikNtDMjis"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import signal\n",
        "from rich.pretty import pprint\n",
        "from torcheeg.datasets import DREAMERDataset\n",
        "from torcheeg.datasets.constants.emotion_recognition.dreamer import DREAMER_CHANNEL_LOCATION_DICT\n",
        "from torcheeg import transforms\n",
        "from torch import nn\n",
        "import torch\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "He4HfZ9INBqd",
        "outputId": "1ca5a947-b822-4d45-90c8-1c44b41a5630"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROctHay3Mjiv"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"/content/drive/MyDrive/Neuroscience/DREAMER.mat\"\n",
        "base_path = \"/content/drive/MyDrive/Neuroscience/Valence/\"\n",
        "\n",
        "# dataset_path = \"/content/drive/MyDrive/Neuroscience/DREAMER.mat\"\n",
        "# base_path = \"/content/drive/MyDrive/Neuroscience/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeS8rzjgMjiv",
        "outputId": "72f96ac5-1eeb-4147-b47e-5dd4314930c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The target folder already exists, if you need to regenerate the database IO, please delete the path /content/drive/MyDrive/Neuroscience/Valence/dreamer8sec.\n"
          ]
        }
      ],
      "source": [
        "dataset = DREAMERDataset(\n",
        "    io_path=base_path + 'dreamer8sec',\n",
        "    mat_path=dataset_path,\n",
        "    offline_transform=transforms.Compose([\n",
        "        transforms.BaselineRemoval(),\n",
        "        transforms.MeanStdNormalize(),\n",
        "        transforms.To2d()\n",
        "    ]),\n",
        "    # online_transform=transforms.ToTensor(),\n",
        "    label_transform=transforms.Compose(\n",
        "        [transforms.Select('valence'),\n",
        "         transforms.Binary(2.0)]),\n",
        "    chunk_size=976,\n",
        "    baseline_chunk_size=976,\n",
        "    num_baseline=8\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYg8kdfcMjix"
      },
      "outputs": [],
      "source": [
        "def get_tf_feature(eeg, sr, n_channels = 14):\n",
        "    WinLength = int(0.5*sr) # 500 points (0.5 sec, 500 ms)\n",
        "    step = int(0.025*sr) # 25 points (or 25 ms)\n",
        "    final_features = None\n",
        "    for i in range(n_channels):\n",
        "        eeg_single = eeg[i].squeeze()\n",
        "        myparams = dict(nperseg = WinLength, noverlap = WinLength-step, return_onesided=True, mode='magnitude')\n",
        "        f, nseg, Sxx = signal.spectrogram(x = eeg_single, fs = sr, **myparams)\n",
        "        if(isinstance(final_features, np.ndarray)):\n",
        "            final_features = np.concatenate((final_features, Sxx), axis=0)\n",
        "        else:\n",
        "            final_features = Sxx\n",
        "    return final_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxRp3C3nMjiy",
        "outputId": "1fa3ba77-f59f-46fc-cec5-1be83a371e5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# device = \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1a8bHcFMjiy"
      },
      "outputs": [],
      "source": [
        "def convert_data_to_tensor(data):\n",
        "    data = data.astype(\"float32\")\n",
        "    data = data.reshape(1, data.shape[0], data.shape[1])\n",
        "    return torch.from_numpy(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_xdabRlMjiz"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv2D_1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 1024, 11, stride=3),\n",
        "            nn.Conv2d(1024, 512, 7, stride=3),\n",
        "            nn.Conv2d(512, 128, 7, stride=3),\n",
        "        )\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            # nn.Linear(14550, 2048),\n",
        "            # nn.ReLU(),\n",
        "            nn.Linear(17280, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv2D_1(x)\n",
        "        print(x.shape)\n",
        "        # x = self.flatten(x)\n",
        "        x = x.view(1, -1)\n",
        "        # print(x.shape)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQi1-d9WMjiz"
      },
      "outputs": [],
      "source": [
        "random.seed(42)\n",
        "\n",
        "test_size = 2000\n",
        "test_index = random.sample(range(0, 11000), test_size)\n",
        "train_index = []\n",
        "\n",
        "for i in range(11040):\n",
        "    if i not in test_index:\n",
        "        train_index.append(i)\n",
        "random.shuffle(train_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2H8L58PHMjiz"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataset,  model, loss_fn, optimizer):\n",
        "    # size = len(dataset)\n",
        "    model.train()\n",
        "    sample_size = len(train_index)\n",
        "    j=0\n",
        "    for i in train_index:\n",
        "        # Compute prediction and loss\n",
        "        # print(i)\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        X, y = dataset[i][0][0], dataset[i][1]\n",
        "        X = get_tf_feature(X, sr=128)\n",
        "        X = convert_data_to_tensor(X)\n",
        "        if y == 0:\n",
        "            y = [0]\n",
        "        else:\n",
        "            y = [1]\n",
        "        y = torch.tensor(y)\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        pred = model(X)\n",
        "        # print(y.shape, pred.shape)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if j % 100 == 0:\n",
        "            loss, current = loss.item(), j + 1\n",
        "            print(f\"loss: {loss}  [{current:>5d}/{sample_size:>5d}]\")\n",
        "            # if j%1000 == 0:\n",
        "              # torch.save(model.state_dict(), \"eeg_model_1000.pth\")\n",
        "        j=j+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0Yj50GzMji0"
      },
      "outputs": [],
      "source": [
        "\n",
        "val_error = 999999999.9\n",
        "best_model_parameter = None\n",
        "\n",
        "def test_loop(dataset, model, loss_fn):\n",
        "    global val_error\n",
        "    global best_model_parameter\n",
        "    # size = len(dataset)\n",
        "    test_loss, correct = 0, 0\n",
        "    sample_size = len(test_index)\n",
        "    # l = random.sample(range(0, 11000), 1)\n",
        "    # j=0\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for i in test_index:\n",
        "            X, y = dataset[i][0][0], dataset[i][1]\n",
        "            X = get_tf_feature(X, sr=128)\n",
        "            X = convert_data_to_tensor(X)\n",
        "            if y == 0:\n",
        "                y = [0]\n",
        "            else:\n",
        "                y = [1]\n",
        "            y = torch.tensor(y)\n",
        "            \n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= sample_size\n",
        "    correct /= sample_size\n",
        "\n",
        "    if val_error > test_loss:\n",
        "        val_error = test_loss\n",
        "        best_model_parameter = model.state_dict()\n",
        "\n",
        "    str = (f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    print(str)\n",
        "    with open(\"log.txt\", \"a\") as f:\n",
        "        f.write(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9Rdio0rMji1"
      },
      "outputs": [],
      "source": [
        "learning_rate = 3e-6"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_epoch = 5\n",
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(base_path + f'eeg_model_{last_epoch}.pth', map_location=torch.device('cpu')))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZT3mi6dj5Dn5",
        "outputId": "a1fd4b66-7834-4ca6-883a-e8ec6bb15f11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNetwork(\n",
              "  (conv2D_1): Sequential(\n",
              "    (0): Conv2d(1, 1024, kernel_size=(11, 11), stride=(3, 3))\n",
              "    (1): Conv2d(1024, 512, kernel_size=(7, 7), stride=(3, 3))\n",
              "    (2): Conv2d(512, 128, kernel_size=(7, 7), stride=(3, 3))\n",
              "  )\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (linear_relu_stack): Sequential(\n",
              "    (0): Linear(in_features=17280, out_features=1024, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=512, out_features=128, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=128, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wBQGnn7TMji1",
        "outputId": "47fc324d-9b6a-44fb-cd90-01c943f69a73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7\n",
            "-------------------------------\n",
            "\n",
            "loss: 6.675497570540756e-05  [    1/ 9040]\n",
            "loss: 9.417090768693015e-05  [  101/ 9040]\n",
            "loss: 0.009558388032019138  [  201/ 9040]\n",
            "loss: 4.410734163684538e-06  [  301/ 9040]\n",
            "loss: 0.005291978362947702  [  401/ 9040]\n",
            "loss: 0.01889948360621929  [  501/ 9040]\n",
            "loss: 0.0028077249880880117  [  601/ 9040]\n",
            "loss: 0.21185214817523956  [  701/ 9040]\n",
            "loss: 0.040372904390096664  [  801/ 9040]\n",
            "loss: 0.13620908558368683  [  901/ 9040]\n",
            "loss: 0.0007788485381752253  [ 1001/ 9040]\n",
            "loss: 0.006116955541074276  [ 1101/ 9040]\n",
            "loss: 0.0010399178136140108  [ 1201/ 9040]\n",
            "loss: 0.2269279956817627  [ 1301/ 9040]\n",
            "loss: 0.01227679755538702  [ 1401/ 9040]\n",
            "loss: 0.0  [ 1501/ 9040]\n",
            "loss: 0.07805125415325165  [ 1601/ 9040]\n",
            "loss: 0.0  [ 1701/ 9040]\n",
            "loss: 1.5175142288208008  [ 1801/ 9040]\n",
            "loss: 0.06420323997735977  [ 1901/ 9040]\n",
            "loss: 0.15917076170444489  [ 2001/ 9040]\n",
            "loss: 0.014367230236530304  [ 2101/ 9040]\n",
            "loss: 4.529942543740617e-06  [ 2201/ 9040]\n",
            "loss: 0.00285836448892951  [ 2301/ 9040]\n",
            "loss: 0.1214248389005661  [ 2401/ 9040]\n",
            "loss: 0.0006600823253393173  [ 2501/ 9040]\n",
            "loss: 5.960462772236497e-07  [ 2601/ 9040]\n",
            "loss: 0.0  [ 2701/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 2801/ 9040]\n",
            "loss: 4.768370445162873e-07  [ 2901/ 9040]\n",
            "loss: 0.0  [ 3001/ 9040]\n",
            "loss: 0.022365709766745567  [ 3101/ 9040]\n",
            "loss: 0.042930252850055695  [ 3201/ 9040]\n",
            "loss: 0.0036064840387552977  [ 3301/ 9040]\n",
            "loss: 0.014552172273397446  [ 3401/ 9040]\n",
            "loss: 1.156323378381785e-05  [ 3501/ 9040]\n",
            "loss: 0.0031225753482431173  [ 3601/ 9040]\n",
            "loss: 0.0012324602575972676  [ 3701/ 9040]\n",
            "loss: 0.003246634267270565  [ 3801/ 9040]\n",
            "loss: 0.0004967409186065197  [ 3901/ 9040]\n",
            "loss: 0.15429092943668365  [ 4001/ 9040]\n",
            "loss: 0.2902108132839203  [ 4101/ 9040]\n",
            "loss: 0.0007465674425475299  [ 4201/ 9040]\n",
            "loss: 0.1410781592130661  [ 4301/ 9040]\n",
            "loss: 0.008039141073822975  [ 4401/ 9040]\n",
            "loss: 0.0004234609368722886  [ 4501/ 9040]\n",
            "loss: 0.0  [ 4601/ 9040]\n",
            "loss: 0.02212134376168251  [ 4701/ 9040]\n",
            "loss: 0.0007814691052772105  [ 4801/ 9040]\n",
            "loss: 0.0  [ 4901/ 9040]\n",
            "loss: 0.00013422065239865333  [ 5001/ 9040]\n",
            "loss: 0.013446830213069916  [ 5101/ 9040]\n",
            "loss: 0.00010525626566959545  [ 5201/ 9040]\n",
            "loss: 0.8112117648124695  [ 5301/ 9040]\n",
            "loss: 7.152555099310121e-07  [ 5401/ 9040]\n",
            "loss: 1.6689160474925302e-05  [ 5501/ 9040]\n",
            "loss: 0.1275574266910553  [ 5601/ 9040]\n",
            "loss: 0.0023082061670720577  [ 5701/ 9040]\n",
            "loss: 0.004276060964912176  [ 5801/ 9040]\n",
            "loss: 0.013056382536888123  [ 5901/ 9040]\n",
            "loss: 0.758082389831543  [ 6001/ 9040]\n",
            "loss: 0.0  [ 6101/ 9040]\n",
            "loss: 0.0031177031341940165  [ 6201/ 9040]\n",
            "loss: 3.3550350666046143  [ 6301/ 9040]\n",
            "loss: 1.6569954823353328e-05  [ 6401/ 9040]\n",
            "loss: 0.02958712913095951  [ 6501/ 9040]\n",
            "loss: 0.0025623366236686707  [ 6601/ 9040]\n",
            "loss: 0.18661482632160187  [ 6701/ 9040]\n",
            "loss: 0.001821169862523675  [ 6801/ 9040]\n",
            "loss: 0.0006006343755871058  [ 6901/ 9040]\n",
            "loss: 0.005767252761870623  [ 7001/ 9040]\n",
            "loss: 5.507317473529838e-05  [ 7101/ 9040]\n",
            "loss: 0.0009577454766258597  [ 7201/ 9040]\n",
            "loss: 1.597391747054644e-05  [ 7301/ 9040]\n",
            "loss: 0.029897017404437065  [ 7401/ 9040]\n",
            "loss: 0.006260782480239868  [ 7501/ 9040]\n",
            "loss: 0.001050635357387364  [ 7601/ 9040]\n",
            "loss: 8.344646857949556e-07  [ 7701/ 9040]\n",
            "loss: 0.015526135452091694  [ 7801/ 9040]\n",
            "loss: 0.03647475317120552  [ 7901/ 9040]\n",
            "loss: 0.010254436172544956  [ 8001/ 9040]\n",
            "loss: 0.009199020452797413  [ 8101/ 9040]\n",
            "loss: 0.0005571481888182461  [ 8201/ 9040]\n",
            "loss: 0.017200347036123276  [ 8301/ 9040]\n",
            "loss: 0.05156192183494568  [ 8401/ 9040]\n",
            "loss: 0.0005210472736507654  [ 8501/ 9040]\n",
            "loss: 7.629365427419543e-06  [ 8601/ 9040]\n",
            "loss: 0.0031680890824645758  [ 8701/ 9040]\n",
            "loss: 0.004072468727827072  [ 8801/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 8901/ 9040]\n",
            "loss: 5.4238757002167404e-05  [ 9001/ 9040]\n",
            "Test Error: \n",
            " Accuracy: 92.7%, Avg loss: 0.246778 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "\n",
            "loss: 2.3841855067985307e-07  [    1/ 9040]\n",
            "loss: 4.60137271147687e-05  [  101/ 9040]\n",
            "loss: 0.002248261356726289  [  201/ 9040]\n",
            "loss: 1.4305104514278355e-06  [  301/ 9040]\n",
            "loss: 0.0026106107980012894  [  401/ 9040]\n",
            "loss: 0.01178151648491621  [  501/ 9040]\n",
            "loss: 0.0007005859515629709  [  601/ 9040]\n",
            "loss: 0.1826571226119995  [  701/ 9040]\n",
            "loss: 0.030221382156014442  [  801/ 9040]\n",
            "loss: 0.13586188852787018  [  901/ 9040]\n",
            "loss: 0.00035494225448928773  [ 1001/ 9040]\n",
            "loss: 0.0009972843108698726  [ 1101/ 9040]\n",
            "loss: 0.00037424711626954377  [ 1201/ 9040]\n",
            "loss: 0.09608790278434753  [ 1301/ 9040]\n",
            "loss: 0.007665267679840326  [ 1401/ 9040]\n",
            "loss: 0.0  [ 1501/ 9040]\n",
            "loss: 0.08625045418739319  [ 1601/ 9040]\n",
            "loss: 0.0  [ 1701/ 9040]\n",
            "loss: 0.821282148361206  [ 1801/ 9040]\n",
            "loss: 0.015073326416313648  [ 1901/ 9040]\n",
            "loss: 0.12024926394224167  [ 2001/ 9040]\n",
            "loss: 0.007061642594635487  [ 2101/ 9040]\n",
            "loss: 5.960462772236497e-07  [ 2201/ 9040]\n",
            "loss: 0.0014527016319334507  [ 2301/ 9040]\n",
            "loss: 0.07353778183460236  [ 2401/ 9040]\n",
            "loss: 0.00019131260341964662  [ 2501/ 9040]\n",
            "loss: 0.0  [ 2601/ 9040]\n",
            "loss: 2.3841855067985307e-07  [ 2701/ 9040]\n",
            "loss: 0.0  [ 2801/ 9040]\n",
            "loss: 0.0  [ 2901/ 9040]\n",
            "loss: 0.0  [ 3001/ 9040]\n",
            "loss: 0.0035197706893086433  [ 3101/ 9040]\n",
            "loss: 0.0218846146017313  [ 3201/ 9040]\n",
            "loss: 0.004701512400060892  [ 3301/ 9040]\n",
            "loss: 0.0014363934751600027  [ 3401/ 9040]\n",
            "loss: 7.152555099310121e-07  [ 3501/ 9040]\n",
            "loss: 0.0010340826120227575  [ 3601/ 9040]\n",
            "loss: 0.00022063204960431904  [ 3701/ 9040]\n",
            "loss: 0.006521253846585751  [ 3801/ 9040]\n",
            "loss: 4.708655978902243e-05  [ 3901/ 9040]\n",
            "loss: 0.05108572170138359  [ 4001/ 9040]\n",
            "loss: 0.13734111189842224  [ 4101/ 9040]\n",
            "loss: 0.0004917366313748062  [ 4201/ 9040]\n",
            "loss: 0.05905364081263542  [ 4301/ 9040]\n",
            "loss: 0.0014362744987010956  [ 4401/ 9040]\n",
            "loss: 2.7417760065873154e-05  [ 4501/ 9040]\n",
            "loss: 0.0  [ 4601/ 9040]\n",
            "loss: 0.015808142721652985  [ 4701/ 9040]\n",
            "loss: 0.00023326536756940186  [ 4801/ 9040]\n",
            "loss: 0.0  [ 4901/ 9040]\n",
            "loss: 5.972207145532593e-05  [ 5001/ 9040]\n",
            "loss: 0.005964338313788176  [ 5101/ 9040]\n",
            "loss: 1.5735502529423684e-05  [ 5201/ 9040]\n",
            "loss: 0.07759004086256027  [ 5301/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 5401/ 9040]\n",
            "loss: 1.311301275563892e-06  [ 5501/ 9040]\n",
            "loss: 0.04975150525569916  [ 5601/ 9040]\n",
            "loss: 0.0029389543924480677  [ 5701/ 9040]\n",
            "loss: 0.0008152975351549685  [ 5801/ 9040]\n",
            "loss: 0.004453740082681179  [ 5901/ 9040]\n",
            "loss: 0.9073678255081177  [ 6001/ 9040]\n",
            "loss: 0.0  [ 6101/ 9040]\n",
            "loss: 0.0007658647373318672  [ 6201/ 9040]\n",
            "loss: 3.5007781982421875  [ 6301/ 9040]\n",
            "loss: 1.4305104514278355e-06  [ 6401/ 9040]\n",
            "loss: 0.015514984726905823  [ 6501/ 9040]\n",
            "loss: 0.000771939754486084  [ 6601/ 9040]\n",
            "loss: 0.41513872146606445  [ 6701/ 9040]\n",
            "loss: 0.000694153131917119  [ 6801/ 9040]\n",
            "loss: 9.655486064730212e-05  [ 6901/ 9040]\n",
            "loss: 0.000720956246368587  [ 7001/ 9040]\n",
            "loss: 1.537788011773955e-05  [ 7101/ 9040]\n",
            "loss: 0.00016199229867197573  [ 7201/ 9040]\n",
            "loss: 1.311301275563892e-06  [ 7301/ 9040]\n",
            "loss: 0.008934048004448414  [ 7401/ 9040]\n",
            "loss: 0.0039800964295864105  [ 7501/ 9040]\n",
            "loss: 0.00029380773776210845  [ 7601/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 7701/ 9040]\n",
            "loss: 0.054446976631879807  [ 7801/ 9040]\n",
            "loss: 0.06243138015270233  [ 7901/ 9040]\n",
            "loss: 0.0013178244698792696  [ 8001/ 9040]\n",
            "loss: 0.015470381826162338  [ 8101/ 9040]\n",
            "loss: 7.247662142617628e-05  [ 8201/ 9040]\n",
            "loss: 0.012328843586146832  [ 8301/ 9040]\n",
            "loss: 0.03467847406864166  [ 8401/ 9040]\n",
            "loss: 7.998623186722398e-05  [ 8501/ 9040]\n",
            "loss: 7.152555099310121e-07  [ 8601/ 9040]\n",
            "loss: 0.0030370086897164583  [ 8701/ 9040]\n",
            "loss: 0.005293756723403931  [ 8801/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 8901/ 9040]\n",
            "loss: 2.145764938177308e-06  [ 9001/ 9040]\n",
            "Test Error: \n",
            " Accuracy: 91.8%, Avg loss: 0.280989 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "\n",
            "loss: 0.0  [    1/ 9040]\n",
            "loss: 1.9073468138230965e-06  [  101/ 9040]\n",
            "loss: 0.0014194899704307318  [  201/ 9040]\n",
            "loss: 2.3841855067985307e-07  [  301/ 9040]\n",
            "loss: 0.00033182359766215086  [  401/ 9040]\n",
            "loss: 0.0041035739704966545  [  501/ 9040]\n",
            "loss: 0.0006989181856624782  [  601/ 9040]\n",
            "loss: 0.10297150909900665  [  701/ 9040]\n",
            "loss: 0.05573740229010582  [  801/ 9040]\n",
            "loss: 0.034222621470689774  [  901/ 9040]\n",
            "loss: 4.994744449504651e-05  [ 1001/ 9040]\n",
            "loss: 0.0014522254932671785  [ 1101/ 9040]\n",
            "loss: 0.00012289722508285195  [ 1201/ 9040]\n",
            "loss: 0.05340590700507164  [ 1301/ 9040]\n",
            "loss: 0.00349304242990911  [ 1401/ 9040]\n",
            "loss: 0.0  [ 1501/ 9040]\n",
            "loss: 0.08881969749927521  [ 1601/ 9040]\n",
            "loss: 0.0  [ 1701/ 9040]\n",
            "loss: 0.557938814163208  [ 1801/ 9040]\n",
            "loss: 0.005304547492414713  [ 1901/ 9040]\n",
            "loss: 0.10389586538076401  [ 2001/ 9040]\n",
            "loss: 0.003201718209311366  [ 2101/ 9040]\n",
            "loss: 0.0  [ 2201/ 9040]\n",
            "loss: 0.0004297763225622475  [ 2301/ 9040]\n",
            "loss: 0.02855726145207882  [ 2401/ 9040]\n",
            "loss: 0.0005646541831083596  [ 2501/ 9040]\n",
            "loss: 0.0  [ 2601/ 9040]\n",
            "loss: 0.0  [ 2701/ 9040]\n",
            "loss: 0.0  [ 2801/ 9040]\n",
            "loss: 0.0  [ 2901/ 9040]\n",
            "loss: 0.0  [ 3001/ 9040]\n",
            "loss: 0.0010126468259841204  [ 3101/ 9040]\n",
            "loss: 0.045393478125333786  [ 3201/ 9040]\n",
            "loss: 0.0023028540890663862  [ 3301/ 9040]\n",
            "loss: 0.000699156429618597  [ 3401/ 9040]\n",
            "loss: 3.933898824470816e-06  [ 3501/ 9040]\n",
            "loss: 0.0020247451029717922  [ 3601/ 9040]\n",
            "loss: 5.2569914259947836e-05  [ 3701/ 9040]\n",
            "loss: 0.016300143674016  [ 3801/ 9040]\n",
            "loss: 4.95898348162882e-05  [ 3901/ 9040]\n",
            "loss: 0.021939778700470924  [ 4001/ 9040]\n",
            "loss: 0.04447634890675545  [ 4101/ 9040]\n",
            "loss: 6.937739817658439e-05  [ 4201/ 9040]\n",
            "loss: 0.10951097309589386  [ 4301/ 9040]\n",
            "loss: 0.0008198237628675997  [ 4401/ 9040]\n",
            "loss: 9.536738616588991e-07  [ 4501/ 9040]\n",
            "loss: 0.0  [ 4601/ 9040]\n",
            "loss: 0.0022664591670036316  [ 4701/ 9040]\n",
            "loss: 5.8053239627042785e-05  [ 4801/ 9040]\n",
            "loss: 0.0  [ 4901/ 9040]\n",
            "loss: 9.059865078597795e-06  [ 5001/ 9040]\n",
            "loss: 0.001802487880922854  [ 5101/ 9040]\n",
            "loss: 3.3378546504536644e-06  [ 5201/ 9040]\n",
            "loss: 0.03650153428316116  [ 5301/ 9040]\n",
            "loss: 0.0  [ 5401/ 9040]\n",
            "loss: 2.3841830625315197e-06  [ 5501/ 9040]\n",
            "loss: 0.027084844186902046  [ 5601/ 9040]\n",
            "loss: 0.001471032970584929  [ 5701/ 9040]\n",
            "loss: 0.0004847066884394735  [ 5801/ 9040]\n",
            "loss: 0.001427346607670188  [ 5901/ 9040]\n",
            "loss: 0.06504672020673752  [ 6001/ 9040]\n",
            "loss: 0.0  [ 6101/ 9040]\n",
            "loss: 0.0002057340752799064  [ 6201/ 9040]\n",
            "loss: 0.06102340295910835  [ 6301/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 6401/ 9040]\n",
            "loss: 0.00978801865130663  [ 6501/ 9040]\n",
            "loss: 0.00010644822759786621  [ 6601/ 9040]\n",
            "loss: 0.04374450817704201  [ 6701/ 9040]\n",
            "loss: 0.0002731903805397451  [ 6801/ 9040]\n",
            "loss: 9.298280929215252e-06  [ 6901/ 9040]\n",
            "loss: 4.5536911784438416e-05  [ 7001/ 9040]\n",
            "loss: 4.768370445162873e-07  [ 7101/ 9040]\n",
            "loss: 5.674201020156033e-05  [ 7201/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 7301/ 9040]\n",
            "loss: 0.006268601398915052  [ 7401/ 9040]\n",
            "loss: 0.10928058624267578  [ 7501/ 9040]\n",
            "loss: 2.312633478140924e-05  [ 7601/ 9040]\n",
            "loss: 0.0  [ 7701/ 9040]\n",
            "loss: 0.11427924782037735  [ 7801/ 9040]\n",
            "loss: 0.04649162292480469  [ 7901/ 9040]\n",
            "loss: 0.0004969792207702994  [ 8001/ 9040]\n",
            "loss: 0.0024730355944484472  [ 8101/ 9040]\n",
            "loss: 0.00017152745567727834  [ 8201/ 9040]\n",
            "loss: 0.009856365621089935  [ 8301/ 9040]\n",
            "loss: 0.024708056822419167  [ 8401/ 9040]\n",
            "loss: 5.3165931603871286e-05  [ 8501/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 8601/ 9040]\n",
            "loss: 0.001722401357255876  [ 8701/ 9040]\n",
            "loss: 6.460934673668817e-05  [ 8801/ 9040]\n",
            "loss: 0.0  [ 8901/ 9040]\n",
            "loss: 2.3841855067985307e-07  [ 9001/ 9040]\n",
            "Test Error: \n",
            " Accuracy: 92.9%, Avg loss: 0.281344 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "\n",
            "loss: 0.0  [    1/ 9040]\n",
            "loss: 2.3841855067985307e-07  [  101/ 9040]\n",
            "loss: 0.00010311071673640981  [  201/ 9040]\n",
            "loss: 2.50339189733495e-06  [  301/ 9040]\n",
            "loss: 0.0013869914691895247  [  401/ 9040]\n",
            "loss: 0.011961047537624836  [  501/ 9040]\n",
            "loss: 0.0005306981038302183  [  601/ 9040]\n",
            "loss: 0.03116738423705101  [  701/ 9040]\n",
            "loss: 0.004763920325785875  [  801/ 9040]\n",
            "loss: 0.23339828848838806  [  901/ 9040]\n",
            "loss: 1.9430925021879375e-05  [ 1001/ 9040]\n",
            "loss: 0.0008492438937537372  [ 1101/ 9040]\n",
            "loss: 2.992108420585282e-05  [ 1201/ 9040]\n",
            "loss: 0.040909841656684875  [ 1301/ 9040]\n",
            "loss: 0.003129230346530676  [ 1401/ 9040]\n",
            "loss: 0.0  [ 1501/ 9040]\n",
            "loss: 0.08602668344974518  [ 1601/ 9040]\n",
            "loss: 0.0  [ 1701/ 9040]\n",
            "loss: 0.23756100237369537  [ 1801/ 9040]\n",
            "loss: 0.00441908510401845  [ 1901/ 9040]\n",
            "loss: 0.007206162437796593  [ 2001/ 9040]\n",
            "loss: 0.0011066034203395247  [ 2101/ 9040]\n",
            "loss: 0.0  [ 2201/ 9040]\n",
            "loss: 9.452849917579442e-05  [ 2301/ 9040]\n",
            "loss: 0.061720408499240875  [ 2401/ 9040]\n",
            "loss: 4.660974445869215e-05  [ 2501/ 9040]\n",
            "loss: 0.0  [ 2601/ 9040]\n",
            "loss: 0.0  [ 2701/ 9040]\n",
            "loss: 0.0  [ 2801/ 9040]\n",
            "loss: 0.0  [ 2901/ 9040]\n",
            "loss: 0.0  [ 3001/ 9040]\n",
            "loss: 0.0006189814303070307  [ 3101/ 9040]\n",
            "loss: 0.015604419633746147  [ 3201/ 9040]\n",
            "loss: 9.190614218823612e-05  [ 3301/ 9040]\n",
            "loss: 0.0008741371566429734  [ 3401/ 9040]\n",
            "loss: 0.0  [ 3501/ 9040]\n",
            "loss: 2.5152843591058627e-05  [ 3601/ 9040]\n",
            "loss: 5.960462772236497e-07  [ 3701/ 9040]\n",
            "loss: 0.0007065422250889242  [ 3801/ 9040]\n",
            "loss: 2.8729025871143676e-05  [ 3901/ 9040]\n",
            "loss: 0.029471851885318756  [ 4001/ 9040]\n",
            "loss: 0.1034957617521286  [ 4101/ 9040]\n",
            "loss: 1.5497195136049413e-06  [ 4201/ 9040]\n",
            "loss: 0.10815869271755219  [ 4301/ 9040]\n",
            "loss: 0.00024423000286333263  [ 4401/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 4501/ 9040]\n",
            "loss: 0.0  [ 4601/ 9040]\n",
            "loss: 0.00127877457998693  [ 4701/ 9040]\n",
            "loss: 3.576272320060525e-06  [ 4801/ 9040]\n",
            "loss: 0.0  [ 4901/ 9040]\n",
            "loss: 5.006777428206988e-06  [ 5001/ 9040]\n",
            "loss: 0.000880568812135607  [ 5101/ 9040]\n",
            "loss: 7.152555099310121e-07  [ 5201/ 9040]\n",
            "loss: 0.015790540724992752  [ 5301/ 9040]\n",
            "loss: 0.0  [ 5401/ 9040]\n",
            "loss: 0.0  [ 5501/ 9040]\n",
            "loss: 0.0023689798545092344  [ 5601/ 9040]\n",
            "loss: 0.00013040646445006132  [ 5701/ 9040]\n",
            "loss: 0.00028546550311148167  [ 5801/ 9040]\n",
            "loss: 0.00019131260341964662  [ 5901/ 9040]\n",
            "loss: 0.12310539931058884  [ 6001/ 9040]\n",
            "loss: 0.0  [ 6101/ 9040]\n",
            "loss: 1.3351351299206726e-05  [ 6201/ 9040]\n",
            "loss: 0.03385968133807182  [ 6301/ 9040]\n",
            "loss: 0.0  [ 6401/ 9040]\n",
            "loss: 0.0013777059502899647  [ 6501/ 9040]\n",
            "loss: 8.189342770492658e-05  [ 6601/ 9040]\n",
            "loss: 0.013942345045506954  [ 6701/ 9040]\n",
            "loss: 0.00012289722508285195  [ 6801/ 9040]\n",
            "loss: 1.5497195136049413e-06  [ 6901/ 9040]\n",
            "loss: 3.099436753473128e-06  [ 7001/ 9040]\n",
            "loss: 1.311301275563892e-06  [ 7101/ 9040]\n",
            "loss: 1.311301275563892e-06  [ 7201/ 9040]\n",
            "loss: 0.0  [ 7301/ 9040]\n",
            "loss: 0.002198066795244813  [ 7401/ 9040]\n",
            "loss: 0.16359145939350128  [ 7501/ 9040]\n",
            "loss: 2.3841830625315197e-06  [ 7601/ 9040]\n",
            "loss: 0.0  [ 7701/ 9040]\n",
            "loss: 0.001057184999808669  [ 7801/ 9040]\n",
            "loss: 0.07527483254671097  [ 7901/ 9040]\n",
            "loss: 5.447716102935374e-05  [ 8001/ 9040]\n",
            "loss: 0.0020553194917738438  [ 8101/ 9040]\n",
            "loss: 2.9802276912960224e-06  [ 8201/ 9040]\n",
            "loss: 0.009707505814731121  [ 8301/ 9040]\n",
            "loss: 0.021312620490789413  [ 8401/ 9040]\n",
            "loss: 1.4185804502631072e-05  [ 8501/ 9040]\n",
            "loss: 0.0  [ 8601/ 9040]\n",
            "loss: 0.0007811117684468627  [ 8701/ 9040]\n",
            "loss: 0.002984357764944434  [ 8801/ 9040]\n",
            "loss: 0.0  [ 8901/ 9040]\n",
            "loss: 0.0  [ 9001/ 9040]\n",
            "Test Error: \n",
            " Accuracy: 92.5%, Avg loss: 0.324358 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "\n",
            "loss: 0.0  [    1/ 9040]\n",
            "loss: 0.0  [  101/ 9040]\n",
            "loss: 0.0006043276516720653  [  201/ 9040]\n",
            "loss: 2.3841855067985307e-07  [  301/ 9040]\n",
            "loss: 0.0013153243344277143  [  401/ 9040]\n",
            "loss: 0.0026020498480647802  [  501/ 9040]\n",
            "loss: 0.000596107158344239  [  601/ 9040]\n",
            "loss: 0.013024378567934036  [  701/ 9040]\n",
            "loss: 0.005607232917100191  [  801/ 9040]\n",
            "loss: 0.002617269055917859  [  901/ 9040]\n",
            "loss: 7.152555099310121e-07  [ 1001/ 9040]\n",
            "loss: 0.0006756883230991662  [ 1101/ 9040]\n",
            "loss: 5.590759246842936e-05  [ 1201/ 9040]\n",
            "loss: 0.00023993951617740095  [ 1301/ 9040]\n",
            "loss: 0.0018447301117703319  [ 1401/ 9040]\n",
            "loss: 0.0  [ 1501/ 9040]\n",
            "loss: 0.2527967095375061  [ 1601/ 9040]\n",
            "loss: 0.0  [ 1701/ 9040]\n",
            "loss: 0.07607003301382065  [ 1801/ 9040]\n",
            "loss: 0.005395255982875824  [ 1901/ 9040]\n",
            "loss: 0.0029604677110910416  [ 2001/ 9040]\n",
            "loss: 0.00019178935326635838  [ 2101/ 9040]\n",
            "loss: 0.0  [ 2201/ 9040]\n",
            "loss: 5.030505417380482e-05  [ 2301/ 9040]\n",
            "loss: 0.054649483412504196  [ 2401/ 9040]\n",
            "loss: 6.222531374078244e-05  [ 2501/ 9040]\n",
            "loss: 0.0  [ 2601/ 9040]\n",
            "loss: 0.0  [ 2701/ 9040]\n",
            "loss: 0.0  [ 2801/ 9040]\n",
            "loss: 0.0  [ 2901/ 9040]\n",
            "loss: 0.0  [ 3001/ 9040]\n",
            "loss: 0.0002653246629051864  [ 3101/ 9040]\n",
            "loss: 0.08585099875926971  [ 3201/ 9040]\n",
            "loss: 0.0012990139657631516  [ 3301/ 9040]\n",
            "loss: 0.00021789084712509066  [ 3401/ 9040]\n",
            "loss: 0.0  [ 3501/ 9040]\n",
            "loss: 0.00570170721039176  [ 3601/ 9040]\n",
            "loss: 2.884823152271565e-05  [ 3701/ 9040]\n",
            "loss: 0.003164405468851328  [ 3801/ 9040]\n",
            "loss: 3.218599158572033e-05  [ 3901/ 9040]\n",
            "loss: 0.004574429709464312  [ 4001/ 9040]\n",
            "loss: 0.007943586446344852  [ 4101/ 9040]\n",
            "loss: 8.344646857949556e-07  [ 4201/ 9040]\n",
            "loss: 0.5790212750434875  [ 4301/ 9040]\n",
            "loss: 5.2927523938706145e-05  [ 4401/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 4501/ 9040]\n",
            "loss: 0.0  [ 4601/ 9040]\n",
            "loss: 0.0001110968878492713  [ 4701/ 9040]\n",
            "loss: 6.318072337307967e-06  [ 4801/ 9040]\n",
            "loss: 0.0  [ 4901/ 9040]\n",
            "loss: 4.291525328881107e-06  [ 5001/ 9040]\n",
            "loss: 0.00047100416850298643  [ 5101/ 9040]\n",
            "loss: 8.344646857949556e-07  [ 5201/ 9040]\n",
            "loss: 0.03825381025671959  [ 5301/ 9040]\n",
            "loss: 0.0  [ 5401/ 9040]\n",
            "loss: 0.0  [ 5501/ 9040]\n",
            "loss: 0.006547190714627504  [ 5601/ 9040]\n",
            "loss: 7.629103492945433e-05  [ 5701/ 9040]\n",
            "loss: 0.00011419598013162613  [ 5801/ 9040]\n",
            "loss: 1.2159273865108844e-05  [ 5901/ 9040]\n",
            "loss: 0.17199601233005524  [ 6001/ 9040]\n",
            "loss: 0.0  [ 6101/ 9040]\n",
            "loss: 4.291525328881107e-06  [ 6201/ 9040]\n",
            "loss: 0.3886808753013611  [ 6301/ 9040]\n",
            "loss: 0.0  [ 6401/ 9040]\n",
            "loss: 0.0003083468764089048  [ 6501/ 9040]\n",
            "loss: 5.6980417866725475e-05  [ 6601/ 9040]\n",
            "loss: 0.01806180737912655  [ 6701/ 9040]\n",
            "loss: 0.001148874987848103  [ 6801/ 9040]\n",
            "loss: 1.1920922133867862e-06  [ 6901/ 9040]\n",
            "loss: 1.0728830375228426e-06  [ 7001/ 9040]\n",
            "loss: 4.768370445162873e-07  [ 7101/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 7201/ 9040]\n",
            "loss: 0.0  [ 7301/ 9040]\n",
            "loss: 0.0009174905135296285  [ 7401/ 9040]\n",
            "loss: 0.07513142377138138  [ 7501/ 9040]\n",
            "loss: 1.2516897186287679e-05  [ 7601/ 9040]\n",
            "loss: 0.0  [ 7701/ 9040]\n",
            "loss: 0.0032036192715168  [ 7801/ 9040]\n",
            "loss: 0.09334402531385422  [ 7901/ 9040]\n",
            "loss: 0.0001255195093108341  [ 8001/ 9040]\n",
            "loss: 3.480850500636734e-05  [ 8101/ 9040]\n",
            "loss: 1.0728830375228426e-06  [ 8201/ 9040]\n",
            "loss: 0.00014161060971673578  [ 8301/ 9040]\n",
            "loss: 0.005387430544942617  [ 8401/ 9040]\n",
            "loss: 0.00024053541710600257  [ 8501/ 9040]\n",
            "loss: 0.0  [ 8601/ 9040]\n",
            "loss: 0.0002602000313345343  [ 8701/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 8801/ 9040]\n",
            "loss: 0.0  [ 8901/ 9040]\n",
            "loss: 0.0  [ 9001/ 9040]\n",
            "Test Error: \n",
            " Accuracy: 92.6%, Avg loss: 0.306604 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "\n",
            "loss: 0.0  [    1/ 9040]\n",
            "loss: 0.0  [  101/ 9040]\n",
            "loss: 0.0018487757770344615  [  201/ 9040]\n",
            "loss: 0.0  [  301/ 9040]\n",
            "loss: 0.000387831823900342  [  401/ 9040]\n",
            "loss: 0.0010448002722114325  [  501/ 9040]\n",
            "loss: 0.0004957877099514008  [  601/ 9040]\n",
            "loss: 0.019122065976262093  [  701/ 9040]\n",
            "loss: 0.1615368276834488  [  801/ 9040]\n",
            "loss: 0.0024733925238251686  [  901/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 1001/ 9040]\n",
            "loss: 2.47952248173533e-05  [ 1101/ 9040]\n",
            "loss: 6.318072337307967e-06  [ 1201/ 9040]\n",
            "loss: 0.0004435985756572336  [ 1301/ 9040]\n",
            "loss: 0.0017459639348089695  [ 1401/ 9040]\n",
            "loss: 0.0  [ 1501/ 9040]\n",
            "loss: 0.2726259231567383  [ 1601/ 9040]\n",
            "loss: 0.0  [ 1701/ 9040]\n",
            "loss: 0.02896660380065441  [ 1801/ 9040]\n",
            "loss: 0.11839193105697632  [ 1901/ 9040]\n",
            "loss: 0.012384772300720215  [ 2001/ 9040]\n",
            "loss: 0.0003156163729727268  [ 2101/ 9040]\n",
            "loss: 0.0  [ 2201/ 9040]\n",
            "loss: 3.6477376852417365e-05  [ 2301/ 9040]\n",
            "loss: 0.01607411541044712  [ 2401/ 9040]\n",
            "loss: 0.00012516192509792745  [ 2501/ 9040]\n",
            "loss: 0.0  [ 2601/ 9040]\n",
            "loss: 0.0  [ 2701/ 9040]\n",
            "loss: 0.0  [ 2801/ 9040]\n",
            "loss: 0.0  [ 2901/ 9040]\n",
            "loss: 0.0  [ 3001/ 9040]\n",
            "loss: 9.047575440490618e-05  [ 3101/ 9040]\n",
            "loss: 0.03086482547223568  [ 3201/ 9040]\n",
            "loss: 8.940656698541716e-06  [ 3301/ 9040]\n",
            "loss: 0.0003601856005843729  [ 3401/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 3501/ 9040]\n",
            "loss: 0.00013016807497479022  [ 3601/ 9040]\n",
            "loss: 0.0  [ 3701/ 9040]\n",
            "loss: 2.682172998902388e-05  [ 3801/ 9040]\n",
            "loss: 4.768360213347478e-06  [ 3901/ 9040]\n",
            "loss: 0.0039456626400351524  [ 4001/ 9040]\n",
            "loss: 0.08154860138893127  [ 4101/ 9040]\n",
            "loss: 4.768370445162873e-07  [ 4201/ 9040]\n",
            "loss: 0.0012191252317279577  [ 4301/ 9040]\n",
            "loss: 5.8410845667822286e-05  [ 4401/ 9040]\n",
            "loss: 0.0  [ 4501/ 9040]\n",
            "loss: 0.0  [ 4601/ 9040]\n",
            "loss: 0.0003411188081372529  [ 4701/ 9040]\n",
            "loss: 7.152555099310121e-07  [ 4801/ 9040]\n",
            "loss: 0.0  [ 4901/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 5001/ 9040]\n",
            "loss: 0.00029118589009158313  [ 5101/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 5201/ 9040]\n",
            "loss: 0.00036090059438720345  [ 5301/ 9040]\n",
            "loss: 0.0  [ 5401/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 5501/ 9040]\n",
            "loss: 0.005685705225914717  [ 5601/ 9040]\n",
            "loss: 0.0007072569569572806  [ 5701/ 9040]\n",
            "loss: 0.00012432756193447858  [ 5801/ 9040]\n",
            "loss: 0.00015686711412854493  [ 5901/ 9040]\n",
            "loss: 0.006917930208146572  [ 6001/ 9040]\n",
            "loss: 0.0  [ 6101/ 9040]\n",
            "loss: 2.884823152271565e-05  [ 6201/ 9040]\n",
            "loss: 7.509902934543788e-05  [ 6301/ 9040]\n",
            "loss: 0.0  [ 6401/ 9040]\n",
            "loss: 0.0007794441189616919  [ 6501/ 9040]\n",
            "loss: 1.0728830375228426e-06  [ 6601/ 9040]\n",
            "loss: 0.003585697151720524  [ 6701/ 9040]\n",
            "loss: 1.847726889536716e-05  [ 6801/ 9040]\n",
            "loss: 2.3841855067985307e-07  [ 6901/ 9040]\n",
            "loss: 2.7418097943154862e-06  [ 7001/ 9040]\n",
            "loss: 5.960462772236497e-07  [ 7101/ 9040]\n",
            "loss: 0.0  [ 7201/ 9040]\n",
            "loss: 0.0  [ 7301/ 9040]\n",
            "loss: 0.003865747479721904  [ 7401/ 9040]\n",
            "loss: 1.0371154530730564e-05  [ 7501/ 9040]\n",
            "loss: 1.0728830375228426e-06  [ 7601/ 9040]\n",
            "loss: 0.0  [ 7701/ 9040]\n",
            "loss: 0.0009596510208211839  [ 7801/ 9040]\n",
            "loss: 0.0064537436701357365  [ 7901/ 9040]\n",
            "loss: 0.01722448505461216  [ 8001/ 9040]\n",
            "loss: 3.7788631743751466e-05  [ 8101/ 9040]\n",
            "loss: 2.3841855067985307e-07  [ 8201/ 9040]\n",
            "loss: 0.00030727434204891324  [ 8301/ 9040]\n",
            "loss: 0.007194682024419308  [ 8401/ 9040]\n",
            "loss: 2.3841855067985307e-07  [ 8501/ 9040]\n",
            "loss: 0.0  [ 8601/ 9040]\n",
            "loss: 0.0004481264913920313  [ 8701/ 9040]\n",
            "loss: 7.033323527139146e-06  [ 8801/ 9040]\n",
            "loss: 0.0  [ 8901/ 9040]\n",
            "loss: 0.0  [ 9001/ 9040]\n",
            "Test Error: \n",
            " Accuracy: 92.3%, Avg loss: 0.367314 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "\n",
            "loss: 0.0  [    1/ 9040]\n",
            "loss: 0.0  [  101/ 9040]\n",
            "loss: 1.9907753085135482e-05  [  201/ 9040]\n",
            "loss: 1.1920928244535389e-07  [  301/ 9040]\n",
            "loss: 4.410734163684538e-06  [  401/ 9040]\n",
            "loss: 0.003336460329592228  [  501/ 9040]\n",
            "loss: 0.0001250427303602919  [  601/ 9040]\n",
            "loss: 0.008529895916581154  [  701/ 9040]\n",
            "loss: 0.00035565727739594877  [  801/ 9040]\n",
            "loss: 0.02439190447330475  [  901/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 1001/ 9040]\n",
            "loss: 0.0001486429391661659  [ 1101/ 9040]\n",
            "loss: 1.7881377516459906e-06  [ 1201/ 9040]\n",
            "loss: 0.0003736513026524335  [ 1301/ 9040]\n",
            "loss: 0.00033468366018496454  [ 1401/ 9040]\n",
            "loss: 0.0  [ 1501/ 9040]\n",
            "loss: 1.7888758182525635  [ 1601/ 9040]\n",
            "loss: 0.0  [ 1701/ 9040]\n",
            "loss: 0.028037874028086662  [ 1801/ 9040]\n",
            "loss: 0.00014649749209638685  [ 1901/ 9040]\n",
            "loss: 7.080780778778717e-05  [ 2001/ 9040]\n",
            "loss: 0.0002864189154934138  [ 2101/ 9040]\n",
            "loss: 0.0  [ 2201/ 9040]\n",
            "loss: 2.8729025871143676e-05  [ 2301/ 9040]\n",
            "loss: 0.10230106860399246  [ 2401/ 9040]\n",
            "loss: 1.823885577323381e-05  [ 2501/ 9040]\n",
            "loss: 0.0  [ 2601/ 9040]\n",
            "loss: 0.0  [ 2701/ 9040]\n",
            "loss: 0.0  [ 2801/ 9040]\n",
            "loss: 0.0  [ 2901/ 9040]\n",
            "loss: 0.0  [ 3001/ 9040]\n",
            "loss: 8.427741704508662e-05  [ 3101/ 9040]\n",
            "loss: 0.03281182795763016  [ 3201/ 9040]\n",
            "loss: 4.529942543740617e-06  [ 3301/ 9040]\n",
            "loss: 0.0006949870148673654  [ 3401/ 9040]\n",
            "loss: 0.0  [ 3501/ 9040]\n",
            "loss: 2.9205850296420977e-05  [ 3601/ 9040]\n",
            "loss: 0.0  [ 3701/ 9040]\n",
            "loss: 0.00014888131408952177  [ 3801/ 9040]\n",
            "loss: 2.3841855067985307e-07  [ 3901/ 9040]\n",
            "loss: 0.00836133398115635  [ 4001/ 9040]\n",
            "loss: 0.014595993794500828  [ 4101/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 4201/ 9040]\n",
            "loss: 0.0033538066782057285  [ 4301/ 9040]\n",
            "loss: 5.543078441405669e-05  [ 4401/ 9040]\n",
            "loss: 0.0  [ 4501/ 9040]\n",
            "loss: 0.0  [ 4601/ 9040]\n",
            "loss: 0.00012373158824630082  [ 4701/ 9040]\n",
            "loss: 5.960462772236497e-07  [ 4801/ 9040]\n",
            "loss: 0.0  [ 4901/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 5001/ 9040]\n",
            "loss: 0.0008049347088672221  [ 5101/ 9040]\n",
            "loss: 0.0  [ 5201/ 9040]\n",
            "loss: 0.000680691737215966  [ 5301/ 9040]\n",
            "loss: 0.0  [ 5401/ 9040]\n",
            "loss: 0.0  [ 5501/ 9040]\n",
            "loss: 0.0007855190197005868  [ 5601/ 9040]\n",
            "loss: 4.768370445162873e-07  [ 5701/ 9040]\n",
            "loss: 6.23445157543756e-05  [ 5801/ 9040]\n",
            "loss: 5.364403477869928e-06  [ 5901/ 9040]\n",
            "loss: 0.11388891935348511  [ 6001/ 9040]\n",
            "loss: 0.0  [ 6101/ 9040]\n",
            "loss: 1.311301275563892e-06  [ 6201/ 9040]\n",
            "loss: 0.00025614796322770417  [ 6301/ 9040]\n",
            "loss: 0.0  [ 6401/ 9040]\n",
            "loss: 0.00020096666412428021  [ 6501/ 9040]\n",
            "loss: 2.264974000354414e-06  [ 6601/ 9040]\n",
            "loss: 0.012500152923166752  [ 6701/ 9040]\n",
            "loss: 3.2186455882765586e-06  [ 6801/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 6901/ 9040]\n",
            "loss: 0.0  [ 7001/ 9040]\n",
            "loss: 2.3841855067985307e-07  [ 7101/ 9040]\n",
            "loss: 0.0  [ 7201/ 9040]\n",
            "loss: 0.0  [ 7301/ 9040]\n",
            "loss: 0.0037549480330199003  [ 7401/ 9040]\n",
            "loss: 1.1086402082582936e-05  [ 7501/ 9040]\n",
            "loss: 4.768370445162873e-07  [ 7601/ 9040]\n",
            "loss: 0.0  [ 7701/ 9040]\n",
            "loss: 3.7431014789035544e-05  [ 7801/ 9040]\n",
            "loss: 0.0034138041082769632  [ 7901/ 9040]\n",
            "loss: 6.913899414939806e-05  [ 8001/ 9040]\n",
            "loss: 4.172316494077677e-06  [ 8101/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 8201/ 9040]\n",
            "loss: 1.7046782886609435e-05  [ 8301/ 9040]\n",
            "loss: 0.0013679441763088107  [ 8401/ 9040]\n",
            "loss: 0.0  [ 8501/ 9040]\n",
            "loss: 0.0  [ 8601/ 9040]\n",
            "loss: 0.00013851160474587232  [ 8701/ 9040]\n",
            "loss: 0.00013040646445006132  [ 8801/ 9040]\n",
            "loss: 0.0  [ 8901/ 9040]\n",
            "loss: 0.0  [ 9001/ 9040]\n",
            "Test Error: \n",
            " Accuracy: 93.2%, Avg loss: 0.369991 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "\n",
            "loss: 0.0  [    1/ 9040]\n",
            "loss: 0.0  [  101/ 9040]\n",
            "loss: 8.463501580990851e-05  [  201/ 9040]\n",
            "loss: 2.3841855067985307e-07  [  301/ 9040]\n",
            "loss: 1.2755313036905136e-05  [  401/ 9040]\n",
            "loss: 0.0008306628442369401  [  501/ 9040]\n",
            "loss: 1.823885577323381e-05  [  601/ 9040]\n",
            "loss: 0.012548420578241348  [  701/ 9040]\n",
            "loss: 0.00015138434537220746  [  801/ 9040]\n",
            "loss: 0.01224782969802618  [  901/ 9040]\n",
            "loss: 0.0  [ 1001/ 9040]\n",
            "loss: 0.0001433984871255234  [ 1101/ 9040]\n",
            "loss: 5.960462772236497e-07  [ 1201/ 9040]\n",
            "loss: 0.00025376438861712813  [ 1301/ 9040]\n",
            "loss: 0.000508417550008744  [ 1401/ 9040]\n",
            "loss: 0.0  [ 1501/ 9040]\n",
            "loss: 0.3384563624858856  [ 1601/ 9040]\n",
            "loss: 0.0  [ 1701/ 9040]\n",
            "loss: 0.025549016892910004  [ 1801/ 9040]\n",
            "loss: 0.0006276782951317728  [ 1901/ 9040]\n",
            "loss: 0.0022431467659771442  [ 2001/ 9040]\n",
            "loss: 1.680836794548668e-05  [ 2101/ 9040]\n",
            "loss: 0.0  [ 2201/ 9040]\n",
            "loss: 5.722029527532868e-06  [ 2301/ 9040]\n",
            "loss: 0.005217032972723246  [ 2401/ 9040]\n",
            "loss: 7.510157047363464e-06  [ 2501/ 9040]\n",
            "loss: 0.0  [ 2601/ 9040]\n",
            "loss: 0.0  [ 2701/ 9040]\n",
            "loss: 0.0  [ 2801/ 9040]\n",
            "loss: 0.0  [ 2901/ 9040]\n",
            "loss: 0.0  [ 3001/ 9040]\n",
            "loss: 0.0005596501869149506  [ 3101/ 9040]\n",
            "loss: 0.0058169132098555565  [ 3201/ 9040]\n",
            "loss: 3.576278118089249e-07  [ 3301/ 9040]\n",
            "loss: 0.00021991695393808186  [ 3401/ 9040]\n",
            "loss: 0.0  [ 3501/ 9040]\n",
            "loss: 2.622600959512056e-06  [ 3601/ 9040]\n",
            "loss: 0.0  [ 3701/ 9040]\n",
            "loss: 0.0002946419408544898  [ 3801/ 9040]\n",
            "loss: 1.311301275563892e-06  [ 3901/ 9040]\n",
            "loss: 0.0027042983565479517  [ 4001/ 9040]\n",
            "loss: 0.027057230472564697  [ 4101/ 9040]\n",
            "loss: 0.0  [ 4201/ 9040]\n",
            "loss: 0.0007658647373318672  [ 4301/ 9040]\n",
            "loss: 9.65590606938349e-06  [ 4401/ 9040]\n",
            "loss: 0.0  [ 4501/ 9040]\n",
            "loss: 0.0  [ 4601/ 9040]\n",
            "loss: 7.962863310240209e-05  [ 4701/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 4801/ 9040]\n",
            "loss: 0.0  [ 4901/ 9040]\n",
            "loss: 8.344646857949556e-07  [ 5001/ 9040]\n",
            "loss: 0.000285227142740041  [ 5101/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 5201/ 9040]\n",
            "loss: 0.008491954766213894  [ 5301/ 9040]\n",
            "loss: 0.0  [ 5401/ 9040]\n",
            "loss: 0.0  [ 5501/ 9040]\n",
            "loss: 0.00045563330058939755  [ 5601/ 9040]\n",
            "loss: 2.3841855067985307e-07  [ 5701/ 9040]\n",
            "loss: 2.109982233378105e-05  [ 5801/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 5901/ 9040]\n",
            "loss: 0.02114013023674488  [ 6001/ 9040]\n",
            "loss: 0.0  [ 6101/ 9040]\n",
            "loss: 7.152555099310121e-07  [ 6201/ 9040]\n",
            "loss: 2.0265373677830212e-05  [ 6301/ 9040]\n",
            "loss: 0.0  [ 6401/ 9040]\n",
            "loss: 0.0002574589161667973  [ 6501/ 9040]\n",
            "loss: 2.3841855067985307e-07  [ 6601/ 9040]\n",
            "loss: 0.0006272017490118742  [ 6701/ 9040]\n",
            "loss: 2.0265558760002023e-06  [ 6801/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 6901/ 9040]\n",
            "loss: 8.344646857949556e-07  [ 7001/ 9040]\n",
            "loss: 8.844937838148326e-05  [ 7101/ 9040]\n",
            "loss: 0.0  [ 7201/ 9040]\n",
            "loss: 0.0  [ 7301/ 9040]\n",
            "loss: 0.0008917645900510252  [ 7401/ 9040]\n",
            "loss: 7.271502545336261e-05  [ 7501/ 9040]\n",
            "loss: 3.6954811548639555e-06  [ 7601/ 9040]\n",
            "loss: 0.0  [ 7701/ 9040]\n",
            "loss: 9.536697689327411e-06  [ 7801/ 9040]\n",
            "loss: 0.004483765456825495  [ 7901/ 9040]\n",
            "loss: 8.4638240878121e-06  [ 8001/ 9040]\n",
            "loss: 3.576272320060525e-06  [ 8101/ 9040]\n",
            "loss: 0.0  [ 8201/ 9040]\n",
            "loss: 1.6689160474925302e-05  [ 8301/ 9040]\n",
            "loss: 0.0009257083875127137  [ 8401/ 9040]\n",
            "loss: 2.3841855067985307e-07  [ 8501/ 9040]\n",
            "loss: 0.0  [ 8601/ 9040]\n",
            "loss: 0.00014911970356479287  [ 8701/ 9040]\n",
            "loss: 3.576272320060525e-06  [ 8801/ 9040]\n",
            "loss: 0.0  [ 8901/ 9040]\n",
            "loss: 0.0  [ 9001/ 9040]\n",
            "Test Error: \n",
            " Accuracy: 93.8%, Avg loss: 0.344636 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "\n",
            "loss: 0.0  [    1/ 9040]\n",
            "loss: 0.0  [  101/ 9040]\n",
            "loss: 0.04027317464351654  [  201/ 9040]\n",
            "loss: 0.0  [  301/ 9040]\n",
            "loss: 0.0  [  401/ 9040]\n",
            "loss: 0.0008038626983761787  [  501/ 9040]\n",
            "loss: 0.0002252801787108183  [  601/ 9040]\n",
            "loss: 0.012033368460834026  [  701/ 9040]\n",
            "loss: 2.729855441430118e-05  [  801/ 9040]\n",
            "loss: 0.0018167671514675021  [  901/ 9040]\n",
            "loss: 0.0  [ 1001/ 9040]\n",
            "loss: 0.00011550712952157483  [ 1101/ 9040]\n",
            "loss: 2.3841855067985307e-07  [ 1201/ 9040]\n",
            "loss: 0.0002919009421020746  [ 1301/ 9040]\n",
            "loss: 0.0006195771275088191  [ 1401/ 9040]\n",
            "loss: 0.0  [ 1501/ 9040]\n",
            "loss: 2.3255412578582764  [ 1601/ 9040]\n",
            "loss: 0.0  [ 1701/ 9040]\n",
            "loss: 0.04155033454298973  [ 1801/ 9040]\n",
            "loss: 0.0001333863037871197  [ 1901/ 9040]\n",
            "loss: 0.0015332859475165606  [ 2001/ 9040]\n",
            "loss: 7.390948667307384e-06  [ 2101/ 9040]\n",
            "loss: 0.0  [ 2201/ 9040]\n",
            "loss: 2.0265558760002023e-06  [ 2301/ 9040]\n",
            "loss: 0.0009083197801373899  [ 2401/ 9040]\n",
            "loss: 0.00023231192608363926  [ 2501/ 9040]\n",
            "loss: 0.0  [ 2601/ 9040]\n",
            "loss: 0.0  [ 2701/ 9040]\n",
            "loss: 0.0  [ 2801/ 9040]\n",
            "loss: 0.0  [ 2901/ 9040]\n",
            "loss: 0.0  [ 3001/ 9040]\n",
            "loss: 1.4185804502631072e-05  [ 3101/ 9040]\n",
            "loss: 0.015541746281087399  [ 3201/ 9040]\n",
            "loss: 0.0  [ 3301/ 9040]\n",
            "loss: 0.0012882990995422006  [ 3401/ 9040]\n",
            "loss: 0.0  [ 3501/ 9040]\n",
            "loss: 3.71926071238704e-05  [ 3601/ 9040]\n",
            "loss: 0.0  [ 3701/ 9040]\n",
            "loss: 5.960462772236497e-07  [ 3801/ 9040]\n",
            "loss: 9.536738616588991e-07  [ 3901/ 9040]\n",
            "loss: 0.003114256775006652  [ 4001/ 9040]\n",
            "loss: 0.014543713070452213  [ 4101/ 9040]\n",
            "loss: 0.0  [ 4201/ 9040]\n",
            "loss: 0.0004332319076638669  [ 4301/ 9040]\n",
            "loss: 4.410646579344757e-05  [ 4401/ 9040]\n",
            "loss: 0.0  [ 4501/ 9040]\n",
            "loss: 0.0  [ 4601/ 9040]\n",
            "loss: 5.936446541454643e-05  [ 4701/ 9040]\n",
            "loss: 2.3841855067985307e-07  [ 4801/ 9040]\n",
            "loss: 0.0  [ 4901/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 5001/ 9040]\n",
            "loss: 0.00022885564249008894  [ 5101/ 9040]\n",
            "loss: 0.0  [ 5201/ 9040]\n",
            "loss: 0.00043394684325903654  [ 5301/ 9040]\n",
            "loss: 0.0  [ 5401/ 9040]\n",
            "loss: 0.0  [ 5501/ 9040]\n",
            "loss: 0.00023135847004596144  [ 5601/ 9040]\n",
            "loss: 3.2186455882765586e-06  [ 5701/ 9040]\n",
            "loss: 3.576214658096433e-05  [ 5801/ 9040]\n",
            "loss: 1.8715683836489916e-05  [ 5901/ 9040]\n",
            "loss: 0.43947717547416687  [ 6001/ 9040]\n",
            "loss: 0.0  [ 6101/ 9040]\n",
            "loss: 5.364403477869928e-06  [ 6201/ 9040]\n",
            "loss: 0.0006459057331085205  [ 6301/ 9040]\n",
            "loss: 0.0  [ 6401/ 9040]\n",
            "loss: 0.0017886845162138343  [ 6501/ 9040]\n",
            "loss: 5.960462772236497e-07  [ 6601/ 9040]\n",
            "loss: 0.002532015787437558  [ 6701/ 9040]\n",
            "loss: 2.0503786799963564e-05  [ 6801/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 6901/ 9040]\n",
            "loss: 7.795983401592821e-05  [ 7001/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 7101/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 7201/ 9040]\n",
            "loss: 0.0  [ 7301/ 9040]\n",
            "loss: 0.0004021312633994967  [ 7401/ 9040]\n",
            "loss: 0.02953065000474453  [ 7501/ 9040]\n",
            "loss: 1.8000440832111053e-05  [ 7601/ 9040]\n",
            "loss: 0.0  [ 7701/ 9040]\n",
            "loss: 3.838465272565372e-05  [ 7801/ 9040]\n",
            "loss: 0.0015338810626417398  [ 7901/ 9040]\n",
            "loss: 1.966933996300213e-05  [ 8001/ 9040]\n",
            "loss: 5.960462772236497e-07  [ 8101/ 9040]\n",
            "loss: 0.0  [ 8201/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 8301/ 9040]\n",
            "loss: 0.0006198153714649379  [ 8401/ 9040]\n",
            "loss: 2.7418097943154862e-06  [ 8501/ 9040]\n",
            "loss: 0.0  [ 8601/ 9040]\n",
            "loss: 4.327203714638017e-05  [ 8701/ 9040]\n",
            "loss: 7.152555099310121e-07  [ 8801/ 9040]\n",
            "loss: 0.0  [ 8901/ 9040]\n",
            "loss: 0.0  [ 9001/ 9040]\n",
            "Test Error: \n",
            " Accuracy: 93.8%, Avg loss: 0.367548 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "\n",
            "loss: 0.0  [    1/ 9040]\n",
            "loss: 0.0  [  101/ 9040]\n",
            "loss: 5.781483559985645e-05  [  201/ 9040]\n",
            "loss: 0.0  [  301/ 9040]\n",
            "loss: 4.768370445162873e-07  [  401/ 9040]\n",
            "loss: 0.00270263385027647  [  501/ 9040]\n",
            "loss: 1.0847986231965479e-05  [  601/ 9040]\n",
            "loss: 0.03152945637702942  [  701/ 9040]\n",
            "loss: 7.629365427419543e-06  [  801/ 9040]\n",
            "loss: 0.0004936429904773831  [  901/ 9040]\n",
            "loss: 0.0  [ 1001/ 9040]\n",
            "loss: 0.00017712931730784476  [ 1101/ 9040]\n",
            "loss: 2.0265558760002023e-06  [ 1201/ 9040]\n",
            "loss: 0.00020358874462544918  [ 1301/ 9040]\n",
            "loss: 0.00010692501382436603  [ 1401/ 9040]\n",
            "loss: 0.0  [ 1501/ 9040]\n",
            "loss: 0.4591171145439148  [ 1601/ 9040]\n",
            "loss: 0.0  [ 1701/ 9040]\n",
            "loss: 0.04167909547686577  [ 1801/ 9040]\n",
            "loss: 0.0007869484252296388  [ 1901/ 9040]\n",
            "loss: 0.0001003691868390888  [ 2001/ 9040]\n",
            "loss: 0.00010084597306558862  [ 2101/ 9040]\n",
            "loss: 0.0  [ 2201/ 9040]\n",
            "loss: 1.1920922133867862e-06  [ 2301/ 9040]\n",
            "loss: 0.001993456156924367  [ 2401/ 9040]\n",
            "loss: 6.842378934379667e-05  [ 2501/ 9040]\n",
            "loss: 0.0  [ 2601/ 9040]\n",
            "loss: 0.0  [ 2701/ 9040]\n",
            "loss: 0.0  [ 2801/ 9040]\n",
            "loss: 0.0  [ 2901/ 9040]\n",
            "loss: 0.0  [ 3001/ 9040]\n",
            "loss: 0.010475884191691875  [ 3101/ 9040]\n",
            "loss: 0.012832563370466232  [ 3201/ 9040]\n",
            "loss: 0.0  [ 3301/ 9040]\n",
            "loss: 8.940656698541716e-06  [ 3401/ 9040]\n",
            "loss: 0.0  [ 3501/ 9040]\n",
            "loss: 1.645074735279195e-05  [ 3601/ 9040]\n",
            "loss: 0.0  [ 3701/ 9040]\n",
            "loss: 0.013473764061927795  [ 3801/ 9040]\n",
            "loss: 0.0  [ 3901/ 9040]\n",
            "loss: 0.05204988643527031  [ 4001/ 9040]\n",
            "loss: 0.00037091050762683153  [ 4101/ 9040]\n",
            "loss: 0.0  [ 4201/ 9040]\n",
            "loss: 0.019765909761190414  [ 4301/ 9040]\n",
            "loss: 3.433168603805825e-05  [ 4401/ 9040]\n",
            "loss: 0.0  [ 4501/ 9040]\n",
            "loss: 0.0  [ 4601/ 9040]\n",
            "loss: 0.00010764019680209458  [ 4701/ 9040]\n",
            "loss: 0.0  [ 4801/ 9040]\n",
            "loss: 0.0  [ 4901/ 9040]\n",
            "loss: 4.0649541915627196e-05  [ 5001/ 9040]\n",
            "loss: 0.0001731960946926847  [ 5101/ 9040]\n",
            "loss: 0.0  [ 5201/ 9040]\n",
            "loss: 0.0002015625941567123  [ 5301/ 9040]\n",
            "loss: 0.0  [ 5401/ 9040]\n",
            "loss: 0.0  [ 5501/ 9040]\n",
            "loss: 0.0002348147245356813  [ 5601/ 9040]\n",
            "loss: 1.1920922133867862e-06  [ 5701/ 9040]\n",
            "loss: 1.9192511899746023e-05  [ 5801/ 9040]\n",
            "loss: 7.986703712958843e-05  [ 5901/ 9040]\n",
            "loss: 0.0186726376414299  [ 6001/ 9040]\n",
            "loss: 0.0  [ 6101/ 9040]\n",
            "loss: 4.768370445162873e-07  [ 6201/ 9040]\n",
            "loss: 0.001401276676915586  [ 6301/ 9040]\n",
            "loss: 0.0  [ 6401/ 9040]\n",
            "loss: 0.00468454509973526  [ 6501/ 9040]\n",
            "loss: 0.0  [ 6601/ 9040]\n",
            "loss: 0.00553906848654151  [ 6701/ 9040]\n",
            "loss: 2.50339189733495e-06  [ 6801/ 9040]\n",
            "loss: 2.3841855067985307e-07  [ 6901/ 9040]\n",
            "loss: 0.0007688426994718611  [ 7001/ 9040]\n",
            "loss: 0.0  [ 7101/ 9040]\n",
            "loss: 0.0  [ 7201/ 9040]\n",
            "loss: 0.0  [ 7301/ 9040]\n",
            "loss: 0.00013720047718379647  [ 7401/ 9040]\n",
            "loss: 0.0001389883691444993  [ 7501/ 9040]\n",
            "loss: 1.9550132492440753e-05  [ 7601/ 9040]\n",
            "loss: 0.0  [ 7701/ 9040]\n",
            "loss: 1.311301275563892e-06  [ 7801/ 9040]\n",
            "loss: 0.003187577472999692  [ 7901/ 9040]\n",
            "loss: 7.152555099310121e-07  [ 8001/ 9040]\n",
            "loss: 3.6000557884108275e-05  [ 8101/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 8201/ 9040]\n",
            "loss: 1.0132738680113107e-05  [ 8301/ 9040]\n",
            "loss: 0.001013480476103723  [ 8401/ 9040]\n",
            "loss: 0.0  [ 8501/ 9040]\n",
            "loss: 0.0  [ 8601/ 9040]\n",
            "loss: 4.386805812828243e-05  [ 8701/ 9040]\n",
            "loss: 0.0  [ 8801/ 9040]\n",
            "loss: 0.0  [ 8901/ 9040]\n",
            "loss: 1.1920928244535389e-07  [ 9001/ 9040]\n",
            "Test Error: \n",
            " Accuracy: 93.3%, Avg loss: 0.370092 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "\n",
            "loss: 0.0  [    1/ 9040]\n",
            "loss: 0.0  [  101/ 9040]\n",
            "loss: 1.7046782886609435e-05  [  201/ 9040]\n",
            "loss: 0.0  [  301/ 9040]\n",
            "loss: 3.4570634852570947e-06  [  401/ 9040]\n",
            "loss: 0.0023084438871592283  [  501/ 9040]\n",
            "loss: 6.103329360485077e-05  [  601/ 9040]\n",
            "loss: 0.004822172224521637  [  701/ 9040]\n",
            "loss: 1.1086402082582936e-05  [  801/ 9040]\n",
            "loss: 0.003099282970651984  [  901/ 9040]\n",
            "loss: 0.0  [ 1001/ 9040]\n",
            "loss: 0.00027366707217879593  [ 1101/ 9040]\n",
            "loss: 1.9073468138230965e-06  [ 1201/ 9040]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-b7f159d4269c>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"log.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mtest_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf\"eeg_model_{t}.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-d0d4d8d0fc4e>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(dataset, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# print(y.shape, pred.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "epochs = 100\n",
        "for t in range(epochs):\n",
        "    if t <= last_epoch:\n",
        "      continue\n",
        "    str = (f\"Epoch {t+1}\\n-------------------------------\\n\")\n",
        "    print(str)\n",
        "    with open(\"log.txt\", \"a\") as f:\n",
        "        f.write(str)\n",
        "    train_loop(dataset, model, loss_fn, optimizer)\n",
        "    test_loop(dataset, model, loss_fn)\n",
        "    torch.save(model.state_dict(), base_path + f\"eeg_model_{t}.pth\")\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49ySsevVMji2"
      },
      "outputs": [],
      "source": [
        "assert best_model_parameter is not None, \"No best model\"\n",
        "best_model = NeuralNetwork().to(device)\n",
        "best_model.load_state_dict(best_model_parameter)\n",
        "torch.save(best_model.state_dict(), \"eeg_model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usegr5dqMji2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HynMGZX3Mji2"
      },
      "outputs": [],
      "source": [
        "!cp ./log.txt ./drive/MyDrive/Neuroscience"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hPFI0QXMji2"
      },
      "outputs": [],
      "source": [
        "def eval_loop(dataset, model, loss_fn, data_cat):\n",
        "    if data_cat == \"Train\":\n",
        "      index_list = train_index\n",
        "    else:\n",
        "      index_list = test_index\n",
        "    # size = len(dataset)\n",
        "    test_loss, correct = 0, 0\n",
        "    sample_size = len(index_list)\n",
        "    # l = random.sample(range(0, 11000), 1)\n",
        "    j=0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for i in index_list:\n",
        "            X, y = dataset[i][0][0], dataset[i][1]\n",
        "            X = get_tf_feature(X, sr=128)\n",
        "            X = convert_data_to_tensor(X)\n",
        "            if y == 0:\n",
        "                y = [0]\n",
        "            else:\n",
        "                y = [1]\n",
        "            y = torch.tensor(y)\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "            if j % 100 == 0 :\n",
        "              print(j)\n",
        "            j+=1\n",
        "\n",
        "    test_loss /= sample_size\n",
        "    correct /= sample_size\n",
        "\n",
        "    str = (f\"{data_cat} Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    print(str)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_epoch = 13\n",
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(base_path + f'eeg_model_{last_epoch}.pth', map_location=torch.device('cpu')))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2780zjJ6rzFt",
        "outputId": "345a6969-5b05-4e01-9851-8b2d39c3b129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNetwork(\n",
              "  (conv2D_1): Sequential(\n",
              "    (0): Conv2d(1, 1024, kernel_size=(11, 11), stride=(3, 3))\n",
              "    (1): Conv2d(1024, 512, kernel_size=(7, 7), stride=(3, 3))\n",
              "    (2): Conv2d(512, 128, kernel_size=(7, 7), stride=(3, 3))\n",
              "  )\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (linear_relu_stack): Sequential(\n",
              "    (0): Linear(in_features=17280, out_features=1024, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=512, out_features=128, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=128, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "eval_loop(dataset, model, loss_fn, \"Train\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zDzDf8br9lr",
        "outputId": "35381305-cf9f-4c9d-effa-f9d74822ed72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "1000\n",
            "1100\n",
            "1200\n",
            "1300\n",
            "1400\n",
            "1500\n",
            "1600\n",
            "1700\n",
            "1800\n",
            "1900\n",
            "2000\n",
            "2100\n",
            "2200\n",
            "2300\n",
            "2400\n",
            "2500\n",
            "2600\n",
            "2700\n",
            "2800\n",
            "2900\n",
            "3000\n",
            "3100\n",
            "3200\n",
            "3300\n",
            "3400\n",
            "3500\n",
            "3600\n",
            "3700\n",
            "3800\n",
            "3900\n",
            "4000\n",
            "4100\n",
            "4200\n",
            "4300\n",
            "4400\n",
            "4500\n",
            "4600\n",
            "4700\n",
            "4800\n",
            "4900\n",
            "5000\n",
            "5100\n",
            "5200\n",
            "5300\n",
            "5400\n",
            "5500\n",
            "5600\n",
            "5700\n",
            "5800\n",
            "5900\n",
            "6000\n",
            "6100\n",
            "6200\n",
            "6300\n",
            "6400\n",
            "6500\n",
            "6600\n",
            "6700\n",
            "6800\n",
            "6900\n",
            "7000\n",
            "7100\n",
            "7200\n",
            "7300\n",
            "7400\n",
            "7500\n",
            "7600\n",
            "7700\n",
            "7800\n",
            "7900\n",
            "8000\n",
            "8100\n",
            "8200\n",
            "8300\n",
            "8400\n",
            "8500\n",
            "8600\n",
            "8700\n",
            "8800\n",
            "8900\n",
            "9000\n",
            "Train Error: \n",
            " Accuracy: 99.5%, Avg loss: 0.013710 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_loop(dataset, model, loss_fn, \"Test\")"
      ],
      "metadata": {
        "id": "wjzuXJeasdxM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8832e719-8fe4-4982-d6f8-1f12d7cd807e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "1000\n",
            "1100\n",
            "1200\n",
            "1300\n",
            "1400\n",
            "1500\n",
            "1600\n",
            "1700\n",
            "1800\n",
            "1900\n",
            "Test Error: \n",
            " Accuracy: 93.8%, Avg loss: 0.344636 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K49Ws6QOshHJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}